Mon Feb 24 10:11:35 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:44:00.0 Off |                    0 |
| N/A   24C    P0             62W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/huang717/CS673-AI-Scientist/templates/fold_and_cut_nanoGPT/experiment.py:594: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == "float16"))
hellow
tokens per iteration will be: 16,384
found vocab_size = 65 (inside ../../data/shakespeare_char/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.66M
num decayed parameter tensors: 26, with 10,740,096 parameters
num non-decayed parameter tensors: 31, with 14,220 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 4.2795, val loss 4.2697
iter 0: loss 4.2699, time 62007.41ms
iter 10: loss 3.1875, time 10.03ms
iter 20: loss 2.7494, time 10.12ms
iter 30: loss 2.6235, time 10.04ms
iter 40: loss 2.5493, time 10.40ms
iter 50: loss 2.4979, time 10.01ms
iter 60: loss 2.5036, time 10.11ms
iter 70: loss 2.5169, time 10.84ms
iter 80: loss 2.4797, time 10.39ms
iter 90: loss 2.4681, time 10.92ms
iter 100: loss 2.4634, time 10.98ms
iter 110: loss 2.4532, time 11.90ms
iter 120: loss 2.4478, time 10.37ms
iter 130: loss 2.4168, time 10.59ms
iter 140: loss 2.4215, time 13.15ms
iter 150: loss 2.3815, time 10.47ms
iter 160: loss 2.3792, time 10.31ms
iter 170: loss 2.3732, time 10.29ms
iter 180: loss 2.3034, time 11.66ms
iter 190: loss 2.2730, time 10.00ms
iter 200: loss 2.2242, time 10.01ms
iter 210: loss 2.1794, time 10.16ms
iter 220: loss 2.1350, time 10.37ms
iter 230: loss 2.0904, time 10.57ms
iter 240: loss 2.0427, time 10.29ms
step 250: train loss 1.9802, val loss 2.0722
iter 250: loss 2.0223, time 3584.88ms
iter 260: loss 2.0180, time 11.23ms
iter 270: loss 1.9746, time 10.31ms
iter 280: loss 1.9518, time 11.84ms
iter 290: loss 1.8984, time 11.51ms
iter 300: loss 1.9010, time 10.19ms
iter 310: loss 1.8962, time 10.35ms
iter 320: loss 1.8489, time 10.28ms
iter 330: loss 1.8510, time 10.08ms
iter 340: loss 1.8336, time 10.09ms
iter 350: loss 1.8406, time 10.49ms
iter 360: loss 1.8108, time 12.73ms
iter 370: loss 1.7615, time 11.64ms
iter 380: loss 1.7754, time 13.67ms
iter 390: loss 1.7325, time 12.30ms
iter 400: loss 1.7228, time 13.27ms
iter 410: loss 1.7121, time 10.31ms
iter 420: loss 1.7197, time 10.27ms
iter 430: loss 1.6493, time 10.16ms
iter 440: loss 1.6597, time 10.53ms
iter 450: loss 1.6496, time 11.28ms
iter 460: loss 1.6440, time 10.94ms
iter 470: loss 1.6572, time 11.80ms
iter 480: loss 1.6529, time 10.98ms
iter 490: loss 1.6338, time 10.37ms
step 500: train loss 1.5296, val loss 1.7318
iter 500: loss 1.6027, time 3595.96ms
iter 510: loss 1.5891, time 10.99ms
iter 520: loss 1.5602, time 10.64ms
iter 530: loss 1.5677, time 10.77ms
iter 540: loss 1.5841, time 10.57ms
iter 550: loss 1.5767, time 10.29ms
iter 560: loss 1.5707, time 12.79ms
iter 570: loss 1.5438, time 10.69ms
iter 580: loss 1.5398, time 10.49ms
iter 590: loss 1.4937, time 12.00ms
iter 600: loss 1.5084, time 10.67ms
iter 610: loss 1.4925, time 10.87ms
iter 620: loss 1.5235, time 11.37ms
iter 630: loss 1.4744, time 10.79ms
iter 640: loss 1.5177, time 10.69ms
iter 650: loss 1.4845, time 14.08ms
iter 660: loss 1.4666, time 10.55ms
iter 670: loss 1.4580, time 10.83ms
iter 680: loss 1.4796, time 10.86ms
iter 690: loss 1.4690, time 10.82ms
iter 700: loss 1.4424, time 10.50ms
iter 710: loss 1.4740, time 10.72ms
iter 720: loss 1.4410, time 10.94ms
iter 730: loss 1.4675, time 12.18ms
iter 740: loss 1.4381, time 10.33ms
step 750: train loss 1.3529, val loss 1.5810
iter 750: loss 1.4389, time 3524.73ms
iter 760: loss 1.4255, time 10.81ms
iter 770: loss 1.4114, time 10.58ms
iter 780: loss 1.4136, time 11.07ms
iter 790: loss 1.4192, time 10.66ms
iter 800: loss 1.4253, time 10.46ms
iter 810: loss 1.4165, time 10.45ms
iter 820: loss 1.4380, time 10.60ms
iter 830: loss 1.3962, time 11.48ms
iter 840: loss 1.4044, time 10.38ms
iter 850: loss 1.3734, time 10.57ms
iter 860: loss 1.4221, time 10.55ms
iter 870: loss 1.3982, time 12.91ms
iter 880: loss 1.4072, time 10.42ms
iter 890: loss 1.4000, time 10.63ms
iter 900: loss 1.4240, time 10.86ms
iter 910: loss 1.3795, time 10.40ms
iter 920: loss 1.3434, time 10.32ms
iter 930: loss 1.3595, time 10.46ms
iter 940: loss 1.3430, time 10.66ms
iter 950: loss 1.3490, time 10.30ms
iter 960: loss 1.3876, time 10.24ms
iter 970: loss 1.3404, time 10.38ms
iter 980: loss 1.3638, time 10.25ms
iter 990: loss 1.3288, time 10.59ms
step 1000: train loss 1.2644, val loss 1.5180
iter 1000: loss 1.3483, time 3640.51ms
iter 1010: loss 1.3464, time 10.31ms
iter 1020: loss 1.3709, time 10.47ms
iter 1030: loss 1.3205, time 10.52ms
iter 1040: loss 1.3176, time 11.07ms
iter 1050: loss 1.3358, time 10.71ms
iter 1060: loss 1.3066, time 10.36ms
iter 1070: loss 1.3127, time 10.27ms
iter 1080: loss 1.3455, time 10.23ms
iter 1090: loss 1.2782, time 12.90ms
iter 1100: loss 1.2765, time 11.82ms
iter 1110: loss 1.2793, time 10.54ms
iter 1120: loss 1.3136, time 16.67ms
iter 1130: loss 1.2973, time 10.64ms
iter 1140: loss 1.2970, time 11.07ms
iter 1150: loss 1.2661, time 10.85ms
iter 1160: loss 1.2902, time 11.85ms
iter 1170: loss 1.3060, time 10.91ms
iter 1180: loss 1.2953, time 11.28ms
iter 1190: loss 1.2819, time 10.74ms
iter 1200: loss 1.2704, time 10.42ms
iter 1210: loss 1.2949, time 11.39ms
iter 1220: loss 1.2699, time 10.85ms
iter 1230: loss 1.2931, time 10.51ms
iter 1240: loss 1.2754, time 10.81ms
step 1250: train loss 1.2013, val loss 1.4802
iter 1250: loss 1.2997, time 3649.85ms
iter 1260: loss 1.2810, time 10.63ms
iter 1270: loss 1.2861, time 10.19ms
iter 1280: loss 1.2835, time 10.32ms
iter 1290: loss 1.2518, time 10.46ms
iter 1300: loss 1.2814, time 10.63ms
iter 1310: loss 1.2531, time 10.48ms
iter 1320: loss 1.2671, time 10.14ms
iter 1330: loss 1.2661, time 10.23ms
iter 1340: loss 1.2506, time 10.34ms
iter 1350: loss 1.2646, time 10.95ms
iter 1360: loss 1.2217, time 10.34ms
iter 1370: loss 1.2442, time 12.74ms
iter 1380: loss 1.2518, time 12.74ms
iter 1390: loss 1.2304, time 10.36ms
iter 1400: loss 1.2256, time 13.95ms
iter 1410: loss 1.2395, time 10.70ms
iter 1420: loss 1.2440, time 10.55ms
iter 1430: loss 1.2373, time 14.08ms
iter 1440: loss 1.2152, time 10.16ms
iter 1450: loss 1.2287, time 10.52ms
iter 1460: loss 1.2404, time 10.39ms
iter 1470: loss 1.2533, time 10.85ms
iter 1480: loss 1.2235, time 10.22ms
iter 1490: loss 1.2112, time 10.31ms
step 1500: train loss 1.1465, val loss 1.4782
iter 1500: loss 1.2437, time 3520.36ms
iter 1510: loss 1.2234, time 10.63ms
iter 1520: loss 1.2046, time 10.84ms
iter 1530: loss 1.2333, time 10.44ms
iter 1540: loss 1.2429, time 10.95ms
iter 1550: loss 1.2190, time 11.09ms
iter 1560: loss 1.2276, time 10.74ms
iter 1570: loss 1.2195, time 15.26ms
iter 1580: loss 1.2200, time 20.55ms
iter 1590: loss 1.1992, time 10.39ms
iter 1600: loss 1.2035, time 10.33ms
iter 1610: loss 1.2000, time 10.77ms
iter 1620: loss 1.2307, time 10.39ms
iter 1630: loss 1.2350, time 10.35ms
iter 1640: loss 1.2085, time 12.27ms
iter 1650: loss 1.1890, time 11.13ms
iter 1660: loss 1.2135, time 13.22ms
iter 1670: loss 1.1567, time 12.19ms
iter 1680: loss 1.1698, time 10.23ms
iter 1690: loss 1.2081, time 10.44ms
iter 1700: loss 1.1571, time 10.47ms
iter 1710: loss 1.1525, time 10.31ms
iter 1720: loss 1.1692, time 10.86ms
iter 1730: loss 1.1844, time 10.57ms
iter 1740: loss 1.1954, time 10.79ms
step 1750: train loss 1.0981, val loss 1.4557
iter 1750: loss 1.1597, time 3907.21ms
iter 1760: loss 1.2073, time 15.13ms
iter 1770: loss 1.1684, time 10.14ms
iter 1780: loss 1.1722, time 19.61ms
iter 1790: loss 1.1603, time 11.03ms
iter 1800: loss 1.1941, time 12.59ms
iter 1810: loss 1.1865, time 9.99ms
iter 1820: loss 1.1634, time 10.55ms
iter 1830: loss 1.1571, time 10.44ms
iter 1840: loss 1.1605, time 10.44ms
iter 1850: loss 1.1783, time 10.74ms
iter 1860: loss 1.1738, time 10.64ms
iter 1870: loss 1.1446, time 11.36ms
iter 1880: loss 1.1457, time 11.07ms
iter 1890: loss 1.1319, time 10.36ms
iter 1900: loss 1.1576, time 10.44ms
iter 1910: loss 1.1291, time 10.52ms
iter 1920: loss 1.1762, time 14.14ms
iter 1930: loss 1.1390, time 12.38ms
iter 1940: loss 1.1536, time 14.50ms
iter 1950: loss 1.1393, time 10.93ms
iter 1960: loss 1.1576, time 13.70ms
iter 1970: loss 1.1328, time 12.27ms
iter 1980: loss 1.1407, time 10.63ms
iter 1990: loss 1.1358, time 11.10ms
step 2000: train loss 1.0509, val loss 1.4663
iter 2000: loss 1.1650, time 3574.43ms
iter 2010: loss 1.1421, time 10.97ms
iter 2020: loss 1.1549, time 10.20ms
iter 2030: loss 1.1777, time 12.72ms
iter 2040: loss 1.1240, time 10.55ms
iter 2050: loss 1.1363, time 10.48ms
iter 2060: loss 1.1405, time 11.73ms
iter 2070: loss 1.1190, time 10.81ms
iter 2080: loss 1.1658, time 10.51ms
iter 2090: loss 1.1100, time 11.59ms
iter 2100: loss 1.1075, time 14.41ms
iter 2110: loss 1.1197, time 10.97ms
iter 2120: loss 1.1360, time 11.90ms
iter 2130: loss 1.1150, time 11.30ms
iter 2140: loss 1.1209, time 10.74ms
iter 2150: loss 1.1078, time 10.64ms
iter 2160: loss 1.1336, time 10.35ms
iter 2170: loss 1.1146, time 10.34ms
iter 2180: loss 1.1075, time 13.79ms
iter 2190: loss 1.1095, time 11.63ms
iter 2200: loss 1.1179, time 11.40ms
iter 2210: loss 1.1222, time 11.07ms
iter 2220: loss 1.1170, time 10.34ms
iter 2230: loss 1.1131, time 13.07ms
iter 2240: loss 1.0852, time 10.19ms
step 2250: train loss 1.0042, val loss 1.4769
iter 2250: loss 1.0989, time 3547.40ms
iter 2260: loss 1.0835, time 10.82ms
iter 2270: loss 1.1160, time 10.56ms
iter 2280: loss 1.1068, time 10.22ms
iter 2290: loss 1.1073, time 10.59ms
iter 2300: loss 1.1023, time 10.20ms
iter 2310: loss 1.0829, time 10.13ms
iter 2320: loss 1.0916, time 10.05ms
iter 2330: loss 1.1092, time 10.34ms
iter 2340: loss 1.0849, time 10.30ms
iter 2350: loss 1.1075, time 13.08ms
iter 2360: loss 1.1275, time 10.68ms
iter 2370: loss 1.0819, time 10.91ms
iter 2380: loss 1.1154, time 10.34ms
iter 2390: loss 1.0970, time 10.33ms
iter 2400: loss 1.0934, time 10.26ms
iter 2410: loss 1.0564, time 11.87ms
iter 2420: loss 1.0832, time 11.29ms
iter 2430: loss 1.0629, time 10.12ms
iter 2440: loss 1.0689, time 10.39ms
iter 2450: loss 1.0654, time 10.26ms
iter 2460: loss 1.0985, time 10.49ms
iter 2470: loss 1.0488, time 10.47ms
iter 2480: loss 1.0340, time 10.28ms
iter 2490: loss 1.0711, time 10.33ms
step 2500: train loss 0.9505, val loss 1.4907
iter 2500: loss 1.0553, time 3567.62ms
iter 2510: loss 1.0592, time 10.52ms
iter 2520: loss 1.0518, time 10.23ms
iter 2530: loss 1.0650, time 10.43ms
iter 2540: loss 1.0678, time 12.04ms
iter 2550: loss 1.0563, time 10.36ms
iter 2560: loss 1.0373, time 11.54ms
iter 2570: loss 1.0758, time 12.30ms
iter 2580: loss 1.0732, time 12.60ms
iter 2590: loss 1.0334, time 11.04ms
iter 2600: loss 1.0560, time 11.07ms
iter 2610: loss 1.0284, time 10.74ms
iter 2620: loss 1.0093, time 10.68ms
iter 2630: loss 1.0344, time 10.79ms
iter 2640: loss 1.0330, time 10.40ms
iter 2650: loss 1.0272, time 11.46ms
iter 2660: loss 1.0143, time 11.24ms
iter 2670: loss 1.0321, time 11.03ms
iter 2680: loss 1.0374, time 10.98ms
iter 2690: loss 1.0197, time 14.10ms
iter 2700: loss 1.0204, time 13.45ms
iter 2710: loss 1.0452, time 12.56ms
iter 2720: loss 1.0364, time 13.25ms
iter 2730: loss 1.0286, time 11.59ms
iter 2740: loss 1.0181, time 10.49ms
step 2750: train loss 0.9052, val loss 1.5169
iter 2750: loss 1.0687, time 3631.09ms
iter 2760: loss 1.0342, time 13.06ms
iter 2770: loss 1.0319, time 11.37ms
iter 2780: loss 1.0199, time 10.73ms
iter 2790: loss 1.0151, time 10.79ms
iter 2800: loss 1.0226, time 10.62ms
iter 2810: loss 1.0272, time 10.89ms
iter 2820: loss 0.9884, time 11.28ms
iter 2830: loss 1.0028, time 10.75ms
iter 2840: loss 1.0078, time 10.32ms
iter 2850: loss 1.0346, time 13.01ms
iter 2860: loss 1.0084, time 11.78ms
iter 2870: loss 1.0272, time 12.07ms
iter 2880: loss 1.0021, time 12.81ms
iter 2890: loss 1.0066, time 10.37ms
iter 2900: loss 0.9982, time 11.12ms
iter 2910: loss 1.0145, time 12.05ms
iter 2920: loss 0.9891, time 10.16ms
iter 2930: loss 1.0016, time 10.20ms
iter 2940: loss 1.0107, time 11.02ms
iter 2950: loss 1.0155, time 10.76ms
iter 2960: loss 0.9572, time 10.78ms
iter 2970: loss 0.9997, time 10.39ms
iter 2980: loss 0.9955, time 10.96ms
iter 2990: loss 0.9967, time 11.92ms
step 3000: train loss 0.8554, val loss 1.5264
iter 3000: loss 0.9790, time 3563.71ms
iter 3010: loss 0.9748, time 11.33ms
iter 3020: loss 0.9966, time 10.77ms
iter 3030: loss 0.9985, time 10.05ms
iter 3040: loss 0.9849, time 9.97ms
iter 3050: loss 0.9544, time 11.24ms
iter 3060: loss 0.9927, time 10.78ms
iter 3070: loss 0.9898, time 10.37ms
iter 3080: loss 0.9713, time 12.00ms
iter 3090: loss 0.9648, time 10.09ms
iter 3100: loss 0.9939, time 10.30ms
iter 3110: loss 0.9805, time 10.31ms
iter 3120: loss 0.9791, time 15.42ms
iter 3130: loss 0.9698, time 10.91ms
iter 3140: loss 0.9441, time 10.90ms
iter 3150: loss 0.9799, time 10.32ms
iter 3160: loss 0.9561, time 10.64ms
iter 3170: loss 0.9613, time 10.25ms
iter 3180: loss 0.9553, time 11.47ms
iter 3190: loss 0.9866, time 18.47ms
iter 3200: loss 0.9213, time 10.51ms
iter 3210: loss 0.9507, time 10.90ms
iter 3220: loss 0.9785, time 10.60ms
iter 3230: loss 0.9606, time 10.85ms
iter 3240: loss 0.9743, time 10.94ms
step 3250: train loss 0.8115, val loss 1.5571
iter 3250: loss 0.9816, time 3604.20ms
iter 3260: loss 0.9539, time 10.23ms
iter 3270: loss 0.9770, time 10.92ms
iter 3280: loss 0.9686, time 10.32ms
iter 3290: loss 0.9358, time 10.37ms
iter 3300: loss 0.9531, time 10.46ms
iter 3310: loss 0.9327, time 11.40ms
iter 3320: loss 0.9397, time 11.18ms
iter 3330: loss 0.9513, time 10.78ms
iter 3340: loss 0.9285, time 10.55ms
iter 3350: loss 0.9430, time 10.59ms
iter 3360: loss 0.9393, time 11.14ms
iter 3370: loss 0.9433, time 14.53ms
iter 3380: loss 0.9498, time 12.38ms
iter 3390: loss 0.9220, time 12.35ms
iter 3400: loss 0.9514, time 10.95ms
iter 3410: loss 0.9190, time 12.86ms
iter 3420: loss 0.9293, time 10.40ms
iter 3430: loss 0.9309, time 10.44ms
iter 3440: loss 0.9074, time 11.15ms
iter 3450: loss 0.9065, time 11.28ms
iter 3460: loss 0.9115, time 10.86ms
iter 3470: loss 0.9278, time 10.51ms
iter 3480: loss 0.9170, time 10.75ms
iter 3490: loss 0.9193, time 11.46ms
step 3500: train loss 0.7658, val loss 1.5866
iter 3500: loss 0.9050, time 3615.50ms
iter 3510: loss 0.9145, time 10.59ms
iter 3520: loss 0.9260, time 10.59ms
iter 3530: loss 0.9387, time 10.84ms
iter 3540: loss 0.9210, time 11.50ms
iter 3550: loss 0.9167, time 12.91ms
iter 3560: loss 0.9257, time 10.80ms
iter 3570: loss 0.9267, time 10.63ms
iter 3580: loss 0.9342, time 11.08ms
iter 3590: loss 0.9180, time 10.44ms
iter 3600: loss 0.8957, time 11.65ms
iter 3610: loss 0.8928, time 10.73ms
iter 3620: loss 0.9268, time 10.31ms
iter 3630: loss 0.9318, time 11.03ms
iter 3640: loss 0.9282, time 10.26ms
iter 3650: loss 0.9041, time 10.37ms
iter 3660: loss 0.9098, time 10.64ms
iter 3670: loss 0.9186, time 11.03ms
iter 3680: loss 0.8959, time 11.65ms
iter 3690: loss 0.8963, time 13.29ms
iter 3700: loss 0.8992, time 11.53ms
iter 3710: loss 0.8906, time 12.74ms
iter 3720: loss 0.8839, time 10.69ms
iter 3730: loss 0.9113, time 14.03ms
iter 3740: loss 0.9102, time 14.70ms
step 3750: train loss 0.7307, val loss 1.6028
iter 3750: loss 0.8853, time 4305.08ms
iter 3760: loss 0.8903, time 10.39ms
iter 3770: loss 0.8806, time 12.16ms
iter 3780: loss 0.8666, time 16.38ms
iter 3790: loss 0.9116, time 12.07ms
iter 3800: loss 0.8961, time 13.38ms
iter 3810: loss 0.8966, time 16.70ms
iter 3820: loss 0.8730, time 13.46ms
iter 3830: loss 0.8939, time 11.68ms
iter 3840: loss 0.8946, time 10.34ms
iter 3850: loss 0.8992, time 10.47ms
iter 3860: loss 0.9013, time 10.73ms
iter 3870: loss 0.8666, time 12.37ms
iter 3880: loss 0.9076, time 10.38ms
iter 3890: loss 0.8924, time 11.38ms
iter 3900: loss 0.8744, time 10.48ms
iter 3910: loss 0.8763, time 10.57ms
iter 3920: loss 0.8585, time 10.49ms
iter 3930: loss 0.8800, time 10.19ms
iter 3940: loss 0.8739, time 11.47ms
iter 3950: loss 0.8801, time 10.67ms
iter 3960: loss 0.8614, time 16.76ms
iter 3970: loss 0.8852, time 24.33ms
iter 3980: loss 0.8519, time 21.21ms
iter 3990: loss 0.8660, time 13.03ms
step 4000: train loss 0.6967, val loss 1.6319
iter 4000: loss 0.9059, time 3667.31ms
iter 4010: loss 0.8807, time 10.29ms
iter 4020: loss 0.8800, time 10.74ms
iter 4030: loss 0.8751, time 12.38ms
iter 4040: loss 0.8855, time 10.73ms
iter 4050: loss 0.8643, time 11.54ms
iter 4060: loss 0.8697, time 15.35ms
iter 4070: loss 0.8706, time 10.67ms
iter 4080: loss 0.8687, time 13.21ms
iter 4090: loss 0.8251, time 10.84ms
iter 4100: loss 0.8500, time 11.89ms
iter 4110: loss 0.8643, time 11.33ms
iter 4120: loss 0.8553, time 16.58ms
iter 4130: loss 0.8769, time 10.89ms
iter 4140: loss 0.8304, time 11.10ms
iter 4150: loss 0.8601, time 11.06ms
iter 4160: loss 0.8835, time 12.31ms
iter 4170: loss 0.8436, time 12.49ms
iter 4180: loss 0.8533, time 11.44ms
iter 4190: loss 0.8494, time 10.24ms
iter 4200: loss 0.8450, time 12.92ms
iter 4210: loss 0.8854, time 11.55ms
iter 4220: loss 0.8338, time 10.69ms
iter 4230: loss 0.8770, time 10.79ms
iter 4240: loss 0.8182, time 15.31ms
step 4250: train loss 0.6656, val loss 1.6378
iter 4250: loss 0.8848, time 3642.70ms
iter 4260: loss 0.8545, time 10.44ms
iter 4270: loss 0.8587, time 11.12ms
iter 4280: loss 0.8469, time 10.68ms
iter 4290: loss 0.8246, time 10.35ms
iter 4300: loss 0.8369, time 10.55ms
iter 4310: loss 0.8388, time 10.55ms
iter 4320: loss 0.8357, time 10.48ms
iter 4330: loss 0.8395, time 10.26ms
iter 4340: loss 0.8358, time 10.67ms
iter 4350: loss 0.8615, time 11.09ms
iter 4360: loss 0.8519, time 10.30ms
iter 4370: loss 0.8500, time 10.28ms
iter 4380: loss 0.8388, time 11.42ms
iter 4390: loss 0.8538, time 11.88ms
iter 4400: loss 0.8473, time 11.62ms
iter 4410: loss 0.8355, time 11.20ms
iter 4420: loss 0.8281, time 11.63ms
iter 4430: loss 0.8253, time 12.23ms
iter 4440: loss 0.8480, time 10.52ms
iter 4450: loss 0.8479, time 10.47ms
iter 4460: loss 0.8401, time 14.73ms
iter 4470: loss 0.8458, time 10.26ms
iter 4480: loss 0.8374, time 10.52ms
iter 4490: loss 0.8455, time 10.39ms
step 4500: train loss 0.6427, val loss 1.6690
iter 4500: loss 0.8373, time 3648.05ms
iter 4510: loss 0.8616, time 10.55ms
iter 4520: loss 0.8504, time 11.10ms
iter 4530: loss 0.8297, time 11.12ms
iter 4540: loss 0.8210, time 20.61ms
iter 4550: loss 0.8322, time 10.46ms
iter 4560: loss 0.8289, time 10.75ms
iter 4570: loss 0.8329, time 11.39ms
iter 4580: loss 0.8250, time 10.41ms
iter 4590: loss 0.8232, time 10.77ms
iter 4600: loss 0.7992, time 10.44ms
iter 4610: loss 0.8279, time 10.76ms
iter 4620: loss 0.8255, time 10.24ms
iter 4630: loss 0.8164, time 10.83ms
iter 4640: loss 0.8204, time 10.82ms
iter 4650: loss 0.8453, time 10.67ms
iter 4660: loss 0.8228, time 10.67ms
iter 4670: loss 0.8274, time 11.24ms
iter 4680: loss 0.8271, time 10.30ms
iter 4690: loss 0.8129, time 11.03ms
iter 4700: loss 0.8078, time 20.12ms
iter 4710: loss 0.8371, time 10.77ms
iter 4720: loss 0.8219, time 11.83ms
iter 4730: loss 0.8366, time 10.43ms
iter 4740: loss 0.8216, time 10.40ms
step 4750: train loss 0.6243, val loss 1.6850
iter 4750: loss 0.8280, time 3902.53ms
iter 4760: loss 0.8070, time 12.00ms
iter 4770: loss 0.8152, time 11.07ms
iter 4780: loss 0.8169, time 12.27ms
iter 4790: loss 0.8128, time 11.66ms
iter 4800: loss 0.8195, time 11.70ms
iter 4810: loss 0.7954, time 12.87ms
iter 4820: loss 0.8477, time 10.63ms
iter 4830: loss 0.8191, time 11.50ms
iter 4840: loss 0.8212, time 11.38ms
iter 4850: loss 0.8026, time 11.22ms
iter 4860: loss 0.7941, time 11.04ms
iter 4870: loss 0.7862, time 10.36ms
iter 4880: loss 0.8300, time 10.10ms
iter 4890: loss 0.8026, time 13.07ms
iter 4900: loss 0.8290, time 10.15ms
iter 4910: loss 0.8132, time 12.55ms
iter 4920: loss 0.8141, time 11.87ms
iter 4930: loss 0.7992, time 12.76ms
iter 4940: loss 0.8125, time 12.49ms
iter 4950: loss 0.8095, time 11.80ms
iter 4960: loss 0.8093, time 10.71ms
iter 4970: loss 0.7892, time 15.58ms
iter 4980: loss 0.8208, time 10.00ms
iter 4990: loss 0.8036, time 10.19ms
step 5000: train loss 0.6084, val loss 1.6966
iter 5000: loss 0.8191, time 3859.67ms
training done
Best validation loss: 1.455723524093628
Total train time: 3.41 mins
Loading meta from ../../data/shakespeare_char/meta.pkl...
Sample 1:
 beauty;
And yet therefore hear the world this night
To be punish'd with blood: in this book,
Mutually seduced by his belly, the law,
Which many days for the earth's love did not see.
This letter she make a murderer of heaven,
Lies the clouds that you may turn the change;
And let her bring her love as many lies
As you are a man that hath spent his life
So many more consequence and in his friends.

BISHOP OF CARLISLE:
To thee here, to that indirection fear
Is expressing not in thy consent thoughts
Inference time: 2.74 seconds
Tokens per second: 182.52
---------------
Sample 2:
 such ever
By gay supposed her trial!

PAULINA:
What is the cause?

ISABELLA:
I talk'd your brother,
You could not speak to know your brother's son,
Which he hath got it enough. I must speak
Of your voices in love of himself, none, so fare you
To be contented to a man of fourscore him. They this
Must be enough; or if if he seem you, must have
Been called in their silence and parts
Of what they are eyes give spring, set to the place
Of the golden complexion. If you do feel your treasure,
I do bese
Inference time: 1.88 seconds
Tokens per second: 266.26
---------------
Sample 3:
 take on thee about thee.

PARIS:
So:
I thought I had for thee remember'd,
That thou mightst not speak to the north,
But in hand of sparks and sack toads and speak it
What tale with enough for the foresaid bosoms
That, like a bold stair cushion, will see
Like reason as ever as a guest as it,
When thou wouldst see this assistance devise,
To be thy wife and weary garland.

DUKE VINCENTIO:
And shall I do this, so should tear a word or two.

LUCIO:
O, then, I will buy speak with my trickles and
the p
Inference time: 1.88 seconds
Tokens per second: 266.40
---------------
Sample 4:
 the earth.

VOLUMNIA:
I warrant you had the first deputy, and
The present his good words: but he calls ever
A reporting friends, to o'er-perfect his pilgrimage,
And time hath the world to send him to his captain.

VIRGILIA:
Live your cares safely and his children:
And painted her the heart takes. Virtue is he
And not prevail'd, I pray heard her me. Fare ye, farewell.

VOLUMNIA:
And now I will.

VIRGILIA:
In brief, thou shalt not be married
With words of an old thoughts, there I stand in move
Tha
Inference time: 1.87 seconds
Tokens per second: 267.54
---------------
Sample 5:
 will remain the world of the haughty sea,
Which let him come with the greater heart,
As that the widow like a cur, the heart
Will plant cost to his name passagement.
Ah, would you not have my father did sleep?
Under your heart have sworn to tell the officer.

KING HENRY VI:
What man mischief have the world been met?
Or that is the world will weddom or no?
If she were a courtier to the earth,
When every peril departure in the contrary.
Perhaps the duke we learn the princes should be.

EDWARD:
She
Inference time: 1.87 seconds
Tokens per second: 267.58
---------------
Sample 6:
 my father's son and lost.

GLOUCESTER:
Curse not thy gracious soul to his chamber:
I am hush'd to comfort that should be done;
And being so much for me and long to me.

PRINCE EDWARD:
Gaunt, let us surely leave to resign.

GLOUCESTER:
By the holy rood, I should not suck him.

LADY GREY:
But yet I will have it suffer'd me to the crown.

GLOUCESTER:
Farewell.

LADY GREY:
That's not my fault will fly to the world:
Yea, and much more in my true services withal.

LADY ANNE:
I was by heaven, and those
Inference time: 1.87 seconds
Tokens per second: 267.59
---------------
Sample 7:
 will act your husband.

HENRY BOLINGBROKE:
My gracious uncle--

KING RICHARD II:
Ay, ay, ay.

BUCKINGHAM:
Why do you suppose this attendance?

KING RICHARD II:
My lord?

BUCKINGHAM:
My lord,
My lord, why means this least were soldiers?

BUCKINGHAM:
Why, here poison the consul dried up in our gage
Our city last now to be slack'd up in government.

KING RICHARD III:
Let me be ill known of this famous lies:
Once more, since I see thy name, I must not see.

BUCKINGHAM:
Why, then I will be gone to El
Inference time: 1.84 seconds
Tokens per second: 271.94
---------------
Sample 8:
 do it know
That you have promised to our side, and with his
As much first gentle and unpossible.

GLOUCESTER:
The crown that your cares amain in your sight;
And so better knows than to wear as death
As you were born to come; and, therefore, let it be done.

LADY ANNE:
I was in our day hand way till it be done.
I am the word to chide the crown and to piece thee.

QUEEN MARGARET:
My Lord of Buckingham, was thy fortune--
Canst thou not hear the sea-sick of the face;
For Bolingbroke, being an ought 
Inference time: 1.87 seconds
Tokens per second: 267.93
---------------
Sample 9:
 slanderous men that know not now what these gates,
That they shall be so sacrificed as secure
Shall point in such a dream of profits,
To put the forfeit of the traitors in the people,
And not deliver'd. Which the love I behold it me,
Which men are present and prayer to France:
If we have fought it straight, our state thereon
Let it be but a glass, you must not stay as ticked
When it doth close the messenger of our country's love
Is pale for which ever I was going.

MENENIUS:
Have you no cause?

/home/huang717/CS673-AI-Scientist/templates/fold_and_cut_nanoGPT/experiment.py:594: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

Inference time: 1.87 seconds
Tokens per second: 267.91
---------------
Sample 10:
 the fire?
Why with a place I sent my father's heirs
With that wounds of gap and night to hold
My mother straight for time I have heard
The solemn like encounters would fain her heart
To seek mine own sweet sovereignty! While I weep
Even in the duke as mother and myself,
Will I do remember it to the father's womb:
And what, in this covent could there was sure,
But that blessed split to shrewd her heart,
Which with her passing stars do light and uneasy
That hand stands the wind.

LEONTES:
O Thursd
Inference time: 1.85 seconds
Tokens per second: 270.11
---------------
Average tokens per second: 259.58
tokens per iteration will be: 16,384
found vocab_size = 65 (inside ../../data/shakespeare_char/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.66M
num decayed parameter tensors: 26, with 10,740,096 parameters
num non-decayed parameter tensors: 31, with 14,220 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 4.2899, val loss 4.2798
iter 0: loss 4.2703, time 3553.44ms
iter 10: loss 3.2228, time 10.77ms
iter 20: loss 2.8130, time 10.44ms
iter 30: loss 2.6274, time 10.39ms
iter 40: loss 2.5761, time 10.70ms
iter 50: loss 2.5146, time 13.51ms
iter 60: loss 2.4977, time 12.96ms
iter 70: loss 2.5054, time 10.72ms
iter 80: loss 2.4922, time 14.09ms
iter 90: loss 2.4723, time 13.06ms
iter 100: loss 2.4655, time 14.21ms
iter 110: loss 2.4550, time 10.42ms
iter 120: loss 2.4415, time 11.85ms
iter 130: loss 2.4374, time 10.49ms
iter 140: loss 2.4037, time 10.28ms
iter 150: loss 2.4011, time 10.26ms
iter 160: loss 2.3786, time 10.94ms
iter 170: loss 2.3388, time 10.59ms
iter 180: loss 2.3087, time 13.55ms
iter 190: loss 2.2350, time 10.93ms
iter 200: loss 2.2258, time 10.49ms
iter 210: loss 2.1742, time 14.23ms
iter 220: loss 2.1258, time 13.39ms
iter 230: loss 2.0931, time 10.02ms
iter 240: loss 2.0527, time 10.41ms
step 250: train loss 1.9663, val loss 2.0821
iter 250: loss 2.0268, time 3570.46ms
iter 260: loss 2.0232, time 10.03ms
iter 270: loss 1.9676, time 10.45ms
iter 280: loss 1.9408, time 11.18ms
iter 290: loss 1.8931, time 10.36ms
iter 300: loss 1.9226, time 10.26ms
iter 310: loss 1.8788, time 10.04ms
iter 320: loss 1.8240, time 10.62ms
iter 330: loss 1.8460, time 10.56ms
iter 340: loss 1.8022, time 10.84ms
iter 350: loss 1.7716, time 10.25ms
iter 360: loss 1.7842, time 10.75ms
iter 370: loss 1.6936, time 12.14ms
iter 380: loss 1.7517, time 10.58ms
iter 390: loss 1.7540, time 11.24ms
iter 400: loss 1.7200, time 10.54ms
iter 410: loss 1.7203, time 10.90ms
iter 420: loss 1.6936, time 10.43ms
iter 430: loss 1.6701, time 10.84ms
iter 440: loss 1.6659, time 10.76ms
iter 450: loss 1.6711, time 10.31ms
iter 460: loss 1.6907, time 10.26ms
iter 470: loss 1.6249, time 10.72ms
iter 480: loss 1.6294, time 10.43ms
iter 490: loss 1.5991, time 10.24ms
step 500: train loss 1.5268, val loss 1.7153
iter 500: loss 1.6323, time 4501.87ms
iter 510: loss 1.5975, time 10.75ms
iter 520: loss 1.5797, time 12.01ms
iter 530: loss 1.5778, time 11.06ms
iter 540: loss 1.5777, time 10.78ms
iter 550: loss 1.5828, time 11.20ms
iter 560: loss 1.5726, time 10.49ms
iter 570: loss 1.5411, time 11.07ms
iter 580: loss 1.5435, time 11.18ms
iter 590: loss 1.5461, time 10.87ms
iter 600: loss 1.5594, time 12.14ms
iter 610: loss 1.4982, time 10.64ms
iter 620: loss 1.5149, time 10.33ms
iter 630: loss 1.5116, time 10.35ms
iter 640: loss 1.5017, time 10.44ms
iter 650: loss 1.4811, time 11.88ms
iter 660: loss 1.4637, time 10.50ms
iter 670: loss 1.4843, time 11.93ms
iter 680: loss 1.4913, time 11.74ms
iter 690: loss 1.4642, time 10.38ms
iter 700: loss 1.4594, time 13.75ms
iter 710: loss 1.4717, time 10.40ms
iter 720: loss 1.4440, time 13.41ms
iter 730: loss 1.4166, time 10.69ms
iter 740: loss 1.4346, time 10.61ms
step 750: train loss 1.3584, val loss 1.5910
iter 750: loss 1.4026, time 3548.89ms
iter 760: loss 1.4549, time 11.20ms
iter 770: loss 1.4189, time 10.12ms
iter 780: loss 1.3940, time 10.06ms
iter 790: loss 1.4255, time 10.01ms
iter 800: loss 1.4207, time 10.08ms
iter 810: loss 1.4140, time 11.83ms
iter 820: loss 1.3854, time 10.81ms
iter 830: loss 1.3790, time 10.45ms
iter 840: loss 1.3822, time 10.23ms
iter 850: loss 1.4234, time 10.27ms
iter 860: loss 1.4000, time 12.15ms
iter 870: loss 1.3687, time 10.32ms
iter 880: loss 1.3921, time 17.12ms
iter 890: loss 1.3805, time 10.79ms
iter 900: loss 1.3722, time 11.71ms
iter 910: loss 1.3937, time 10.13ms
iter 920: loss 1.3384, time 10.91ms
iter 930: loss 1.3418, time 10.07ms
iter 940: loss 1.3797, time 10.12ms
iter 950: loss 1.3385, time 10.89ms
iter 960: loss 1.3376, time 10.30ms
iter 970: loss 1.3829, time 10.29ms
iter 980: loss 1.3383, time 11.55ms
iter 990: loss 1.3384, time 11.83ms
step 1000: train loss 1.2674, val loss 1.5098
iter 1000: loss 1.3188, time 3512.64ms
iter 1010: loss 1.3357, time 10.49ms
iter 1020: loss 1.3399, time 10.59ms
iter 1030: loss 1.3450, time 11.07ms
iter 1040: loss 1.3631, time 10.24ms
iter 1050: loss 1.3071, time 10.48ms
iter 1060: loss 1.3546, time 10.20ms
iter 1070: loss 1.3167, time 10.26ms
iter 1080: loss 1.3195, time 10.41ms
iter 1090: loss 1.3246, time 10.11ms
iter 1100: loss 1.3172, time 10.45ms
iter 1110: loss 1.3221, time 11.75ms
iter 1120: loss 1.3187, time 10.93ms
iter 1130: loss 1.3367, time 10.52ms
iter 1140: loss 1.2935, time 10.88ms
iter 1150: loss 1.3033, time 10.21ms
iter 1160: loss 1.2747, time 10.14ms
iter 1170: loss 1.3065, time 11.44ms
iter 1180: loss 1.3136, time 13.77ms
iter 1190: loss 1.2903, time 12.95ms
iter 1200: loss 1.2769, time 12.00ms
iter 1210: loss 1.2566, time 10.84ms
iter 1220: loss 1.2682, time 10.50ms
iter 1230: loss 1.2617, time 11.78ms
iter 1240: loss 1.2968, time 10.59ms
step 1250: train loss 1.1989, val loss 1.4787
iter 1250: loss 1.2792, time 3625.40ms
iter 1260: loss 1.2632, time 14.86ms
iter 1270: loss 1.2859, time 14.54ms
iter 1280: loss 1.2956, time 14.80ms
iter 1290: loss 1.2809, time 13.62ms
iter 1300: loss 1.2941, time 12.63ms
iter 1310: loss 1.2792, time 13.67ms
iter 1320: loss 1.2654, time 10.27ms
iter 1330: loss 1.2537, time 10.94ms
iter 1340: loss 1.2463, time 10.70ms
iter 1350: loss 1.2590, time 12.76ms
iter 1360: loss 1.2579, time 10.67ms
iter 1370: loss 1.2795, time 10.50ms
iter 1380: loss 1.2335, time 10.58ms
iter 1390: loss 1.2127, time 10.82ms
iter 1400: loss 1.2441, time 10.60ms
iter 1410: loss 1.2564, time 12.25ms
iter 1420: loss 1.2485, time 10.53ms
iter 1430: loss 1.2270, time 11.27ms
iter 1440: loss 1.2435, time 11.87ms
iter 1450: loss 1.2312, time 10.78ms
iter 1460: loss 1.2335, time 10.63ms
iter 1470: loss 1.2363, time 12.51ms
iter 1480: loss 1.2190, time 11.18ms
iter 1490: loss 1.2169, time 10.56ms
step 1500: train loss 1.1476, val loss 1.4679
iter 1500: loss 1.2184, time 4271.76ms
iter 1510: loss 1.2136, time 13.83ms
iter 1520: loss 1.2527, time 12.90ms
iter 1530: loss 1.1822, time 11.59ms
iter 1540: loss 1.2256, time 11.05ms
iter 1550: loss 1.2209, time 11.13ms
iter 1560: loss 1.2423, time 11.14ms
iter 1570: loss 1.1714, time 11.45ms
iter 1580: loss 1.2146, time 11.97ms
iter 1590: loss 1.1980, time 10.74ms
iter 1600: loss 1.2164, time 10.51ms
iter 1610: loss 1.2058, time 11.90ms
iter 1620: loss 1.1873, time 11.05ms
iter 1630: loss 1.1823, time 14.94ms
iter 1640: loss 1.2174, time 14.22ms
iter 1650: loss 1.1842, time 10.91ms
iter 1660: loss 1.2132, time 10.67ms
iter 1670: loss 1.1639, time 10.84ms
iter 1680: loss 1.1975, time 10.94ms
iter 1690: loss 1.1859, time 10.63ms
iter 1700: loss 1.2006, time 11.44ms
iter 1710: loss 1.2104, time 12.17ms
iter 1720: loss 1.1832, time 11.50ms
iter 1730: loss 1.1883, time 10.71ms
iter 1740: loss 1.1856, time 10.82ms
step 1750: train loss 1.0977, val loss 1.4710
iter 1750: loss 1.1670, time 3759.74ms
iter 1760: loss 1.1969, time 12.25ms
iter 1770: loss 1.1730, time 10.72ms
iter 1780: loss 1.1866, time 11.00ms
iter 1790: loss 1.1784, time 10.79ms
iter 1800: loss 1.2044, time 13.87ms
iter 1810: loss 1.1802, time 11.19ms
iter 1820: loss 1.1901, time 10.60ms
iter 1830: loss 1.1738, time 11.18ms
iter 1840: loss 1.1618, time 11.56ms
iter 1850: loss 1.1838, time 10.86ms
iter 1860: loss 1.1600, time 20.65ms
iter 1870: loss 1.1728, time 11.68ms
iter 1880: loss 1.1654, time 11.01ms
iter 1890: loss 1.1542, time 10.83ms
iter 1900: loss 1.1422, time 10.73ms
iter 1910: loss 1.1287, time 10.86ms
iter 1920: loss 1.1638, time 10.55ms
iter 1930: loss 1.1471, time 11.25ms
iter 1940: loss 1.1685, time 10.40ms
iter 1950: loss 1.1568, time 10.73ms
iter 1960: loss 1.1721, time 10.39ms
iter 1970: loss 1.1584, time 10.43ms
iter 1980: loss 1.1585, time 13.85ms
iter 1990: loss 1.1381, time 10.82ms
step 2000: train loss 1.0519, val loss 1.4719
iter 2000: loss 1.1494, time 3496.05ms
iter 2010: loss 1.1233, time 10.58ms
iter 2020: loss 1.1377, time 10.55ms
iter 2030: loss 1.1223, time 10.96ms
iter 2040: loss 1.1374, time 10.53ms
iter 2050: loss 1.1281, time 11.07ms
iter 2060: loss 1.1403, time 10.66ms
iter 2070: loss 1.1410, time 20.70ms
iter 2080: loss 1.1447, time 11.28ms
iter 2090: loss 1.1163, time 11.08ms
iter 2100: loss 1.1289, time 10.29ms
iter 2110: loss 1.1003, time 10.45ms
iter 2120: loss 1.1548, time 11.05ms
iter 2130: loss 1.1350, time 10.99ms
iter 2140: loss 1.1197, time 10.54ms
iter 2150: loss 1.1259, time 10.32ms
iter 2160: loss 1.1471, time 10.50ms
iter 2170: loss 1.1240, time 13.76ms
iter 2180: loss 1.1433, time 10.14ms
iter 2190: loss 1.1434, time 10.63ms
iter 2200: loss 1.1018, time 13.44ms
iter 2210: loss 1.1310, time 10.65ms
iter 2220: loss 1.1133, time 12.12ms
iter 2230: loss 1.0996, time 10.55ms
iter 2240: loss 1.0947, time 11.64ms
step 2250: train loss 1.0037, val loss 1.4691
iter 2250: loss 1.0869, time 3643.50ms
iter 2260: loss 1.0968, time 10.42ms
iter 2270: loss 1.1218, time 11.50ms
iter 2280: loss 1.0973, time 10.32ms
iter 2290: loss 1.0978, time 10.48ms
iter 2300: loss 1.0989, time 10.33ms
iter 2310: loss 1.0734, time 10.62ms
iter 2320: loss 1.1222, time 10.57ms
iter 2330: loss 1.0944, time 11.60ms
iter 2340: loss 1.0999, time 13.59ms
iter 2350: loss 1.1003, time 10.66ms
iter 2360: loss 1.0942, time 10.64ms
iter 2370: loss 1.0810, time 10.42ms
iter 2380: loss 1.0812, time 11.23ms
iter 2390: loss 1.1021, time 10.21ms
iter 2400: loss 1.1110, time 11.03ms
iter 2410: loss 1.0799, time 10.44ms
iter 2420: loss 1.0645, time 10.53ms
iter 2430: loss 1.0591, time 10.61ms
iter 2440: loss 1.0867, time 10.53ms
iter 2450: loss 1.0507, time 11.84ms
iter 2460: loss 1.0861, time 12.91ms
iter 2470: loss 1.0804, time 10.29ms
iter 2480: loss 1.0446, time 10.78ms
iter 2490: loss 1.0438, time 10.22ms
step 2500: train loss 0.9578, val loss 1.4906
iter 2500: loss 1.0834, time 3592.75ms
iter 2510: loss 1.0714, time 10.45ms
iter 2520: loss 1.0487, time 12.80ms
iter 2530: loss 1.0563, time 10.17ms
iter 2540: loss 1.0620, time 10.64ms
iter 2550: loss 1.0523, time 10.89ms
iter 2560: loss 1.0281, time 10.83ms
iter 2570: loss 1.0509, time 10.30ms
iter 2580: loss 1.0520, time 10.85ms
iter 2590: loss 1.0576, time 10.77ms
iter 2600: loss 1.0554, time 10.68ms
iter 2610: loss 1.0439, time 10.84ms
iter 2620: loss 1.0662, time 10.62ms
iter 2630: loss 1.0562, time 11.37ms
iter 2640: loss 1.0460, time 10.97ms
iter 2650: loss 1.0636, time 10.46ms
iter 2660: loss 1.0490, time 10.52ms
iter 2670: loss 1.0483, time 10.49ms
iter 2680: loss 1.0178, time 10.49ms
iter 2690: loss 1.0466, time 13.03ms
iter 2700: loss 1.0275, time 10.63ms
iter 2710: loss 1.0382, time 14.98ms
iter 2720: loss 1.0240, time 11.37ms
iter 2730: loss 1.0569, time 11.27ms
iter 2740: loss 1.0247, time 10.16ms
step 2750: train loss 0.9114, val loss 1.5246
iter 2750: loss 1.0377, time 3713.55ms
iter 2760: loss 1.0505, time 11.06ms
iter 2770: loss 1.0300, time 10.59ms
iter 2780: loss 1.0383, time 13.45ms
iter 2790: loss 1.0254, time 10.63ms
iter 2800: loss 1.0371, time 10.75ms
iter 2810: loss 1.0271, time 10.44ms
iter 2820: loss 1.0217, time 10.17ms
iter 2830: loss 0.9911, time 11.02ms
iter 2840: loss 0.9905, time 10.32ms
iter 2850: loss 1.0131, time 18.67ms
iter 2860: loss 1.0185, time 30.86ms
iter 2870: loss 1.0142, time 11.76ms
iter 2880: loss 1.0205, time 12.25ms
iter 2890: loss 0.9954, time 19.06ms
iter 2900: loss 1.0195, time 24.91ms
iter 2910: loss 0.9876, time 32.42ms
iter 2920: loss 0.9984, time 12.04ms
iter 2930: loss 1.0104, time 10.23ms
iter 2940: loss 1.0094, time 10.96ms
iter 2950: loss 0.9998, time 10.67ms
iter 2960: loss 1.0149, time 10.43ms
iter 2970: loss 1.0261, time 10.19ms
iter 2980: loss 0.9932, time 10.34ms
iter 2990: loss 0.9957, time 11.25ms
step 3000: train loss 0.8637, val loss 1.5354
iter 3000: loss 0.9662, time 3542.33ms
iter 3010: loss 1.0131, time 12.75ms
iter 3020: loss 0.9827, time 10.57ms
iter 3030: loss 1.0126, time 11.08ms
iter 3040: loss 0.9837, time 12.30ms
iter 3050: loss 0.9530, time 11.01ms
iter 3060: loss 0.9776, time 9.96ms
iter 3070: loss 1.0013, time 10.21ms
iter 3080: loss 0.9882, time 10.57ms
iter 3090: loss 0.9739, time 10.53ms
iter 3100: loss 0.9751, time 10.45ms
iter 3110: loss 0.9729, time 10.56ms
iter 3120: loss 0.9669, time 11.51ms
iter 3130: loss 0.9781, time 17.21ms
iter 3140: loss 0.9704, time 12.42ms
iter 3150: loss 0.9867, time 11.56ms
iter 3160: loss 0.9879, time 10.24ms
iter 3170: loss 0.9789, time 15.12ms
iter 3180: loss 0.9395, time 12.25ms
iter 3190: loss 0.9906, time 10.13ms
iter 3200: loss 0.9495, time 10.30ms
iter 3210: loss 0.9542, time 10.19ms
iter 3220: loss 0.9847, time 10.69ms
iter 3230: loss 0.9430, time 10.31ms
iter 3240: loss 0.9393, time 10.18ms
step 3250: train loss 0.8191, val loss 1.5523
iter 3250: loss 0.9648, time 3619.21ms
iter 3260: loss 0.9639, time 10.98ms
iter 3270: loss 0.9574, time 13.37ms
iter 3280: loss 0.9409, time 11.27ms
iter 3290: loss 0.9481, time 10.68ms
iter 3300: loss 0.9327, time 10.34ms
iter 3310: loss 0.9487, time 10.44ms
iter 3320: loss 0.9564, time 10.37ms
iter 3330: loss 0.9539, time 10.74ms
iter 3340: loss 0.9334, time 10.14ms
iter 3350: loss 0.9626, time 11.82ms
iter 3360: loss 0.9270, time 10.16ms
iter 3370: loss 0.9557, time 10.23ms
iter 3380: loss 0.9618, time 13.89ms
iter 3390: loss 0.9412, time 10.36ms
iter 3400: loss 0.9251, time 10.35ms
iter 3410: loss 0.9553, time 10.04ms
iter 3420: loss 0.9490, time 10.35ms
iter 3430: loss 0.9333, time 11.97ms
iter 3440: loss 0.9427, time 11.97ms
iter 3450: loss 0.9382, time 11.04ms
iter 3460: loss 0.9446, time 10.56ms
iter 3470: loss 0.9613, time 11.92ms
iter 3480: loss 0.9428, time 10.60ms
iter 3490: loss 0.8916, time 10.47ms
step 3500: train loss 0.7731, val loss 1.5688
iter 3500: loss 0.9378, time 3438.19ms
iter 3510: loss 0.9035, time 12.99ms
iter 3520: loss 0.9199, time 14.04ms
iter 3530: loss 0.9277, time 14.70ms
iter 3540: loss 0.9177, time 11.58ms
iter 3550: loss 0.9156, time 10.23ms
iter 3560: loss 0.9355, time 10.20ms
iter 3570: loss 0.8909, time 10.16ms
iter 3580: loss 0.9008, time 10.22ms
iter 3590: loss 0.9273, time 11.06ms
iter 3600: loss 0.9440, time 10.15ms
iter 3610: loss 0.9248, time 10.09ms
iter 3620: loss 0.9288, time 9.97ms
iter 3630: loss 0.9125, time 10.14ms
iter 3640: loss 0.9196, time 17.23ms
iter 3650: loss 0.9230, time 10.41ms
iter 3660: loss 0.9148, time 10.10ms
iter 3670: loss 0.8975, time 10.73ms
iter 3680: loss 0.8987, time 10.40ms
iter 3690: loss 0.9042, time 10.92ms
iter 3700: loss 0.9275, time 10.23ms
iter 3710: loss 0.9374, time 10.68ms
iter 3720: loss 0.9256, time 10.34ms
iter 3730: loss 0.9037, time 10.43ms
iter 3740: loss 0.8841, time 10.77ms
step 3750: train loss 0.7353, val loss 1.6027
iter 3750: loss 0.8788, time 3434.65ms
iter 3760: loss 0.9140, time 11.04ms
iter 3770: loss 0.8982, time 11.69ms
iter 3780: loss 0.9260, time 11.48ms
iter 3790: loss 0.8927, time 10.66ms
iter 3800: loss 0.8693, time 10.34ms
iter 3810: loss 0.8988, time 12.56ms
iter 3820: loss 0.9050, time 12.35ms
iter 3830: loss 0.9273, time 10.18ms
iter 3840: loss 0.8800, time 10.54ms
iter 3850: loss 0.8997, time 12.59ms
iter 3860: loss 0.8951, time 14.54ms
iter 3870: loss 0.8804, time 10.79ms
iter 3880: loss 0.8880, time 10.59ms
iter 3890: loss 0.8937, time 10.53ms
iter 3900: loss 0.8896, time 11.30ms
iter 3910: loss 0.8791, time 11.13ms
iter 3920: loss 0.8801, time 11.99ms
iter 3930: loss 0.8958, time 10.46ms
iter 3940: loss 0.8944, time 10.82ms
iter 3950: loss 0.8955, time 10.64ms
iter 3960: loss 0.8970, time 10.22ms
iter 3970: loss 0.8853, time 10.46ms
iter 3980: loss 0.8721, time 11.05ms
iter 3990: loss 0.8636, time 10.99ms
step 4000: train loss 0.7036, val loss 1.6247
iter 4000: loss 0.8753, time 3499.32ms
iter 4010: loss 0.8701, time 11.58ms
iter 4020: loss 0.8669, time 10.71ms
iter 4030: loss 0.8866, time 11.25ms
iter 4040: loss 0.8819, time 11.40ms
iter 4050: loss 0.8678, time 12.61ms
iter 4060: loss 0.8943, time 14.75ms
iter 4070: loss 0.8612, time 10.70ms
iter 4080: loss 0.8784, time 10.53ms
iter 4090: loss 0.8709, time 10.52ms
iter 4100: loss 0.8598, time 10.26ms
iter 4110: loss 0.8688, time 11.93ms
iter 4120: loss 0.8928, time 12.17ms
iter 4130: loss 0.8548, time 10.33ms
iter 4140: loss 0.8563, time 10.25ms
iter 4150: loss 0.8591, time 10.84ms
iter 4160: loss 0.8660, time 10.76ms
iter 4170: loss 0.8626, time 12.92ms
iter 4180: loss 0.8999, time 10.56ms
iter 4190: loss 0.8688, time 10.40ms
iter 4200: loss 0.8546, time 10.27ms
iter 4210: loss 0.8506, time 10.93ms
iter 4220: loss 0.8459, time 10.49ms
iter 4230: loss 0.8614, time 10.88ms
iter 4240: loss 0.8547, time 10.93ms
step 4250: train loss 0.6731, val loss 1.6473
iter 4250: loss 0.8457, time 3780.54ms
iter 4260: loss 0.8390, time 11.21ms
iter 4270: loss 0.8521, time 10.78ms
iter 4280: loss 0.8331, time 11.13ms
iter 4290: loss 0.8314, time 11.88ms
iter 4300: loss 0.8785, time 10.63ms
iter 4310: loss 0.8629, time 11.00ms
iter 4320: loss 0.8729, time 10.74ms
iter 4330: loss 0.8639, time 12.09ms
iter 4340: loss 0.8191, time 10.64ms
iter 4350: loss 0.8422, time 11.07ms
iter 4360: loss 0.8683, time 11.84ms
iter 4370: loss 0.8762, time 10.86ms
iter 4380: loss 0.8411, time 11.13ms
iter 4390: loss 0.8386, time 15.38ms
iter 4400: loss 0.8332, time 13.06ms
iter 4410: loss 0.8376, time 11.22ms
iter 4420: loss 0.8305, time 11.40ms
iter 4430: loss 0.8318, time 10.24ms
iter 4440: loss 0.8586, time 11.56ms
iter 4450: loss 0.8336, time 10.58ms
iter 4460: loss 0.8444, time 10.26ms
iter 4470: loss 0.8358, time 12.10ms
iter 4480: loss 0.8711, time 10.81ms
iter 4490: loss 0.8397, time 12.69ms
step 4500: train loss 0.6508, val loss 1.6667
iter 4500: loss 0.8248, time 3862.89ms
iter 4510: loss 0.8198, time 10.64ms
iter 4520: loss 0.8274, time 10.81ms
iter 4530: loss 0.8345, time 10.59ms
iter 4540: loss 0.8414, time 10.63ms
iter 4550: loss 0.8255, time 11.22ms
iter 4560: loss 0.8446, time 10.70ms
iter 4570: loss 0.8395, time 10.73ms
iter 4580: loss 0.8419, time 10.31ms
iter 4590: loss 0.8272, time 10.53ms
iter 4600: loss 0.8192, time 10.56ms
iter 4610: loss 0.8354, time 10.81ms
iter 4620: loss 0.8309, time 10.56ms
iter 4630: loss 0.8510, time 10.23ms
iter 4640: loss 0.8285, time 10.55ms
iter 4650: loss 0.8274, time 10.33ms
iter 4660: loss 0.8565, time 11.48ms
iter 4670: loss 0.8437, time 11.09ms
iter 4680: loss 0.8313, time 10.97ms
iter 4690: loss 0.8309, time 12.11ms
iter 4700: loss 0.8084, time 11.90ms
iter 4710: loss 0.8296, time 11.74ms
iter 4720: loss 0.8276, time 10.57ms
iter 4730: loss 0.8093, time 10.76ms
iter 4740: loss 0.8135, time 18.50ms
step 4750: train loss 0.6307, val loss 1.6814
iter 4750: loss 0.8346, time 3731.90ms
iter 4760: loss 0.8180, time 11.00ms
iter 4770: loss 0.8378, time 10.37ms
iter 4780: loss 0.8223, time 11.31ms
iter 4790: loss 0.8135, time 10.90ms
iter 4800: loss 0.8179, time 11.25ms
iter 4810: loss 0.8239, time 11.05ms
iter 4820: loss 0.8039, time 11.51ms
iter 4830: loss 0.8299, time 10.99ms
iter 4840: loss 0.8067, time 10.61ms
iter 4850: loss 0.8135, time 11.84ms
iter 4860: loss 0.8402, time 11.79ms
iter 4870: loss 0.8161, time 11.23ms
iter 4880: loss 0.8214, time 11.05ms
iter 4890: loss 0.8332, time 10.62ms
iter 4900: loss 0.8098, time 11.98ms
iter 4910: loss 0.8271, time 13.24ms
iter 4920: loss 0.8009, time 13.17ms
iter 4930: loss 0.8184, time 11.03ms
iter 4940: loss 0.8266, time 11.17ms
iter 4950: loss 0.8200, time 11.60ms
iter 4960: loss 0.8079, time 12.92ms
iter 4970: loss 0.8232, time 15.61ms
iter 4980: loss 0.8276, time 11.12ms
iter 4990: loss 0.8097, time 11.34ms
step 5000: train loss 0.6167, val loss 1.6910
iter 5000: loss 0.8164, time 3819.51ms
training done
Best validation loss: 1.4679335355758667
Total train time: 2.46 mins
Loading meta from ../../data/shakespeare_char/meta.pkl...
Sample 1:
 convert by the hand words of war
Ere he were his inforced by his suit.

QUEEN ELIZABETH:
Then let me have the queen that set this head
Should not sell in her husband's blood
Which the queen is alike.

LADY ANNE:
Why should be mew'd, to see the charge there?

GLOUCESTER:
So proclamation bids us break for us.

LADY ANNE:
What do you do?

GLOUCESTER:
But shall we cont to London entertain?

GLOUCESTER:

LADY ANNE:
To tell thee, ere thou diest.

GLOUCESTER:
Why, this is the duke that he were dead.

L
Inference time: 1.86 seconds
Tokens per second: 268.70
---------------
Sample 2:
 but that
she's difference, like a rain, a as I said, and
did take her aid stain and twenty times and present,
say I begin and drinking, and here it comes.

FRIAR LAURENCE:
Else let him swear, to the market-place;
Which to-morrow thy heavy look growing to flatter,
As long live as dear as if this life
Had spoke of to cannot won with such discontents.

ROMEO:
And for that the devil that hath cause to suffer.

FRIAR LAURENCE:
No, no, my good lord; for this devil
Makes my person should enter call us

Inference time: 1.85 seconds
Tokens per second: 270.71
---------------
Sample 3:
 his eyes forth
A bear for triumphant garland. Let me hence,
Thou art a prophet with a man cold coward.

MARCIUS:
See how I they now govern'd the levels where
They are friends forth and weep.

COMINIUS:
Ye're well met:
They shall not be the head to their pieces,
But as they are the greater of heart
Prefix'd them with them. What they have ended,
I will tempt the fury of the sacrament,
To singing and beggar them with the earth words;
And if they were born to his shame, which elder husband,
Kill in 
Inference time: 1.86 seconds
Tokens per second: 269.51
---------------
Sample 4:
 gentleman, to thy heart, adieu.

KING RICHARD II:
The king is not well; the courage had,
The king is dead, like a divine, if thou call'st;
And, whiles it be, being with the death of kings,
Deposing on the throne mortal far
That thou comest to crush the womb and to us.

KING RICHARD III:
Then, in the very beads through the earth a dearer;
And when the earthly cheek on this parliament,
With all the limits of the dearest gentleman,
And burn the wolf to his desire.
What stuck is this here? say, what
Inference time: 1.86 seconds
Tokens per second: 268.54
---------------
Sample 5:
 and tell the world to thee in the world.

GREEN:

KING RICHARD II:
Why should such a father there?

HENRY BOLINGBROKE:
My gracious lord, this little prince,
Lest, all the traitor live thou sound'st article
Not spoke with her.

HENRY BOLINGBROKE:
O me, I grant me no honey to ours.

KING RICHARD II:
My gracious lord, what a thing is this in all?

NORTHUMBERLAND:
I know it well, then, so good a wife.

KING RICHARD II:
I have overhand they lie stars on my true love.
In them, our right, therefore poo
Inference time: 1.85 seconds
Tokens per second: 269.96
---------------
Sample 6:
 death, to hide the sanctuary.

BUCKINGHAM:
Think you, my lord, noble Lord Grey,
That loving lies by the house of York
I should live to see the bodies of York,
To see the sun to the wish of heaven;
And that happy means to fall from unto:
Therefore the commons may be no behold in Rutland;
But thus I fall, a reverend with the hilt:
And so I will, I'll not see the sword of me.
And say I, when we will be there to jest,
And will to Richard tell him from his son
And he will keep his foot at my thought.
Inference time: 1.86 seconds
Tokens per second: 268.85
---------------
Sample 7:
 desire.

SAMPSON:
Things are all come: the which first for me in man
before yourself the king.

GREGORY:
But sigh'd you so?

SAMPSON:
And if the duke's a bawd, to see you both.

GREGORY:
To see if you think, if you will not build it.

SAMPSON:
No, good sweet lady; but, I have the man leave of
you.

GREGORY:
Gentlewomen, I hope here promised to know you.

BAPTISTA:
If you will be whipt, sir, we'll tell you mother.

GREGORY:
My lord, this goods are as good as it were,
And wear the knees that he pr
Inference time: 1.86 seconds
Tokens per second: 268.82
---------------
Sample 8:
 chamber-d, methinks
thee have to thee that now should strike to thee.

KING RICHARD II:
And what would you do? but what of all?
Sneel thou proclaim a trumpet close,
And with a high ripe death, in peace curses.
Farewell, my lord, this day do I let thee go:
This is strange and leaves in the face of kings.

DUCHESS OF YORK:
I must be mild with my heart; here it is.

DUKE OF YORK:
I will not see the truth of it.

DUCHESS OF YORK:
Why, my husband is our love and heaven.

DUCHESS OF YORK:
What say you
Inference time: 1.85 seconds
Tokens per second: 269.76
---------------
Sample 9:
 Crosby:
I have found a knowledge with grief being left
Blown with that controlling tongue the war
And crown'd away the humorous blood
With grief and trembling witter so fair,
Among the merry of the great alliance,
With a cruel couples elder, in the hair
Which plays the part of perpetual world,
That the son of one skill'd at once untreaties
And fit once for our deadly eyes on the world:
So far be pardon'd, and Bolingbroke,
Who will hap the land with such a more person.
Shall we to Friar Peter too
Inference time: 1.87 seconds
Tokens per second: 267.90
---------------
Sample 10:
 the weakerst.

DUKE VINCENTIO:
And I wish you now, sir, what am I hard to Lord?

ELBOW:
And I cry the lukewise for that baseness
Shall be still and stop of their precious eyes,
Be all the buried from his life too late.

LUCIO:
Believe me, of all the world that I was come forth sin
in the field of the first time to be so.

ESCALUS:
But he, sirrah.

POMPEY:
What, are you like a senator?

ELBOW:
Why then you are so, the woman would be loathsome of
be the world; but know, sir, how against you?

ELBO
Inference time: 1.88 seconds
Tokens per second: 266.27
---------------
Average tokens per second: 268.90
tokens per iteration will be: 16,384
found vocab_size = 65 (inside ../../data/shakespeare_char/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.66M
num decayed parameter tensors: 26, with 10,740,096 parameters
num non-decayed parameter tensors: 31, with 14,220 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 4.2971, val loss 4.3009
iter 0: loss 4.2838, time 4538.36ms
iter 10: loss 3.1929, time 11.64ms
iter 20: loss 2.7739, time 10.80ms
iter 30: loss 2.6273, time 10.93ms
iter 40: loss 2.5550, time 11.14ms
iter 50: loss 2.5188, time 10.96ms
iter 60: loss 2.5177, time 11.04ms
iter 70: loss 2.5001, time 10.96ms
iter 80: loss 2.4921, time 10.85ms
iter 90: loss 2.4570, time 10.78ms
iter 100: loss 2.4697, time 10.46ms
iter 110: loss 2.4418, time 10.34ms
iter 120: loss 2.4549, time 10.35ms
iter 130: loss 2.4088, time 10.84ms
iter 140: loss 2.4229, time 13.06ms
iter 150: loss 2.3992, time 10.04ms
iter 160: loss 2.3788, time 10.33ms
iter 170: loss 2.3303, time 10.35ms
iter 180: loss 2.3243, time 11.06ms
iter 190: loss 2.2700, time 10.45ms
iter 200: loss 2.2265, time 10.47ms
iter 210: loss 2.1203, time 11.88ms
iter 220: loss 2.1237, time 11.24ms
iter 230: loss 2.0895, time 11.01ms
iter 240: loss 2.0400, time 11.46ms
step 250: train loss 1.9556, val loss 2.0582
iter 250: loss 2.0193, time 3653.16ms
iter 260: loss 2.0040, time 10.67ms
iter 270: loss 2.0093, time 10.89ms
iter 280: loss 1.9316, time 10.19ms
iter 290: loss 1.9370, time 13.98ms
iter 300: loss 1.9073, time 16.35ms
iter 310: loss 1.8744, time 10.73ms
iter 320: loss 1.8671, time 10.70ms
iter 330: loss 1.8760, time 10.36ms
iter 340: loss 1.8145, time 10.24ms
iter 350: loss 1.7939, time 10.53ms
iter 360: loss 1.7338, time 10.39ms
iter 370: loss 1.7671, time 10.73ms
iter 380: loss 1.7614, time 10.63ms
iter 390: loss 1.7268, time 10.79ms
iter 400: loss 1.7293, time 14.76ms
iter 410: loss 1.7254, time 10.81ms
iter 420: loss 1.6872, time 10.65ms
iter 430: loss 1.6863, time 10.48ms
iter 440: loss 1.6732, time 11.67ms
iter 450: loss 1.6763, time 10.49ms
iter 460: loss 1.6511, time 10.71ms
iter 470: loss 1.6469, time 10.31ms
iter 480: loss 1.6325, time 11.43ms
iter 490: loss 1.6481, time 10.71ms
step 500: train loss 1.5352, val loss 1.7215
iter 500: loss 1.6102, time 3542.12ms
iter 510: loss 1.5904, time 12.88ms
iter 520: loss 1.5602, time 14.25ms
iter 530: loss 1.5490, time 13.28ms
iter 540: loss 1.5437, time 10.58ms
iter 550: loss 1.5610, time 10.63ms
iter 560: loss 1.5432, time 11.09ms
iter 570: loss 1.5558, time 11.47ms
iter 580: loss 1.5854, time 11.02ms
iter 590: loss 1.5592, time 10.48ms
iter 600: loss 1.5534, time 11.28ms
iter 610: loss 1.5376, time 11.10ms
iter 620: loss 1.5073, time 10.45ms
iter 630: loss 1.5164, time 13.78ms
iter 640: loss 1.4829, time 10.33ms
iter 650: loss 1.4841, time 10.63ms
iter 660: loss 1.4849, time 10.70ms
iter 670: loss 1.4990, time 10.44ms
iter 680: loss 1.4855, time 10.33ms
iter 690: loss 1.5006, time 11.45ms
iter 700: loss 1.4797, time 12.14ms
iter 710: loss 1.4704, time 10.38ms
iter 720: loss 1.4291, time 11.20ms
iter 730: loss 1.4556, time 10.56ms
iter 740: loss 1.4307, time 12.60ms
step 750: train loss 1.3582, val loss 1.5781
iter 750: loss 1.4589, time 3703.45ms
iter 760: loss 1.4366, time 10.98ms
iter 770: loss 1.4256, time 12.01ms
iter 780: loss 1.4104, time 11.91ms
iter 790: loss 1.4320, time 10.99ms
iter 800: loss 1.4197, time 12.44ms
iter 810: loss 1.4107, time 12.54ms
iter 820: loss 1.3907, time 10.91ms
iter 830: loss 1.4036, time 10.81ms
iter 840: loss 1.4063, time 10.86ms
iter 850: loss 1.3979, time 11.19ms
iter 860: loss 1.3630, time 10.71ms
iter 870: loss 1.4047, time 11.36ms
iter 880: loss 1.3893, time 12.70ms
iter 890: loss 1.3690, time 13.22ms
iter 900: loss 1.3704, time 10.86ms
iter 910: loss 1.3226, time 11.32ms
iter 920: loss 1.3528, time 13.56ms
iter 930: loss 1.3314, time 10.67ms
iter 940: loss 1.3340, time 12.91ms
iter 950: loss 1.3428, time 10.94ms
iter 960: loss 1.3861, time 11.64ms
iter 970: loss 1.3425, time 11.50ms
iter 980: loss 1.3191, time 10.87ms
iter 990: loss 1.3462, time 13.50ms
step 1000: train loss 1.2721, val loss 1.5257
iter 1000: loss 1.3521, time 3693.21ms
iter 1010: loss 1.3272, time 10.48ms
iter 1020: loss 1.3481, time 10.45ms
iter 1030: loss 1.3305, time 11.10ms
iter 1040: loss 1.3342, time 10.64ms
iter 1050: loss 1.3719, time 11.05ms
iter 1060: loss 1.3206, time 10.43ms
iter 1070: loss 1.3319, time 10.47ms
iter 1080: loss 1.3280, time 12.38ms
iter 1090: loss 1.3244, time 12.11ms
iter 1100: loss 1.3455, time 10.57ms
iter 1110: loss 1.3119, time 10.63ms
iter 1120: loss 1.3335, time 15.11ms
iter 1130: loss 1.3329, time 11.36ms
iter 1140: loss 1.2979, time 10.59ms
iter 1150: loss 1.2981, time 15.33ms
iter 1160: loss 1.3276, time 12.48ms
iter 1170: loss 1.3083, time 12.30ms
iter 1180: loss 1.2986, time 10.74ms
iter 1190: loss 1.2744, time 10.36ms
iter 1200: loss 1.2748, time 11.16ms
iter 1210: loss 1.3089, time 10.13ms
iter 1220: loss 1.2929, time 10.68ms
iter 1230: loss 1.3017, time 10.44ms
iter 1240: loss 1.2879, time 10.40ms
step 1250: train loss 1.1998, val loss 1.4855
iter 1250: loss 1.2829, time 3536.90ms
iter 1260: loss 1.3011, time 10.58ms
iter 1270: loss 1.2701, time 10.20ms
iter 1280: loss 1.2741, time 10.41ms
iter 1290: loss 1.2868, time 10.46ms
iter 1300: loss 1.2575, time 10.76ms
iter 1310: loss 1.2577, time 10.69ms
iter 1320: loss 1.2554, time 11.13ms
iter 1330: loss 1.2521, time 10.98ms
iter 1340: loss 1.2826, time 11.82ms
iter 1350: loss 1.2226, time 10.88ms
iter 1360: loss 1.2471, time 14.35ms
iter 1370: loss 1.2417, time 10.74ms
iter 1380: loss 1.2432, time 10.31ms
iter 1390: loss 1.2595, time 10.56ms
iter 1400: loss 1.2564, time 10.80ms
iter 1410: loss 1.2321, time 10.81ms
iter 1420: loss 1.2399, time 10.85ms
iter 1430: loss 1.2395, time 10.72ms
iter 1440: loss 1.2481, time 10.77ms
iter 1450: loss 1.2361, time 10.67ms
iter 1460: loss 1.2104, time 10.72ms
iter 1470: loss 1.2395, time 10.94ms
iter 1480: loss 1.2159, time 10.60ms
iter 1490: loss 1.2357, time 10.34ms
step 1500: train loss 1.1464, val loss 1.4778
iter 1500: loss 1.2684, time 3710.95ms
iter 1510: loss 1.2284, time 11.21ms
iter 1520: loss 1.1948, time 12.30ms
iter 1530: loss 1.2519, time 11.24ms
iter 1540: loss 1.2057, time 10.96ms
iter 1550: loss 1.1952, time 15.62ms
iter 1560: loss 1.2096, time 12.54ms
iter 1570: loss 1.2080, time 11.46ms
iter 1580: loss 1.1868, time 12.03ms
iter 1590: loss 1.2251, time 12.18ms
iter 1600: loss 1.2117, time 18.95ms
iter 1610: loss 1.2130, time 10.57ms
iter 1620: loss 1.2146, time 11.34ms
iter 1630: loss 1.2068, time 10.53ms
iter 1640: loss 1.1879, time 10.44ms
iter 1650: loss 1.2038, time 12.21ms
iter 1660: loss 1.2058, time 17.45ms
iter 1670: loss 1.1885, time 10.89ms
iter 1680: loss 1.1858, time 10.73ms
iter 1690: loss 1.1855, time 10.53ms
iter 1700: loss 1.2087, time 11.57ms
iter 1710: loss 1.1717, time 10.86ms
iter 1720: loss 1.1892, time 10.42ms
iter 1730: loss 1.1858, time 11.16ms
iter 1740: loss 1.1966, time 10.40ms
step 1750: train loss 1.0950, val loss 1.4646
iter 1750: loss 1.1825, time 4440.10ms
iter 1760: loss 1.1979, time 12.50ms
iter 1770: loss 1.1687, time 10.56ms
iter 1780: loss 1.1898, time 11.69ms
iter 1790: loss 1.1894, time 17.20ms
iter 1800: loss 1.1684, time 13.96ms
iter 1810: loss 1.1764, time 14.59ms
iter 1820: loss 1.1738, time 12.04ms
iter 1830: loss 1.1892, time 11.82ms
iter 1840: loss 1.1498, time 10.68ms
iter 1850: loss 1.1617, time 11.80ms
iter 1860: loss 1.1751, time 11.70ms
iter 1870: loss 1.1236, time 13.26ms
iter 1880: loss 1.1937, time 11.62ms
iter 1890: loss 1.1700, time 12.64ms
iter 1900: loss 1.1676, time 11.67ms
iter 1910: loss 1.1529, time 13.70ms
iter 1920: loss 1.1503, time 11.80ms
iter 1930: loss 1.1769, time 12.03ms
iter 1940: loss 1.1405, time 12.22ms
iter 1950: loss 1.1371, time 11.95ms
iter 1960: loss 1.1114, time 13.49ms
iter 1970: loss 1.1209, time 11.82ms
iter 1980: loss 1.1582, time 15.96ms
iter 1990: loss 1.1469, time 11.09ms
step 2000: train loss 1.0496, val loss 1.4725
iter 2000: loss 1.1441, time 4174.35ms
iter 2010: loss 1.1502, time 14.97ms
iter 2020: loss 1.1170, time 11.01ms
iter 2030: loss 1.1599, time 12.84ms
iter 2040: loss 1.1247, time 12.41ms
iter 2050: loss 1.1160, time 12.26ms
iter 2060: loss 1.1384, time 12.87ms
iter 2070: loss 1.1800, time 12.15ms
iter 2080: loss 1.1223, time 13.32ms
iter 2090: loss 1.1094, time 11.51ms
iter 2100: loss 1.1110, time 13.11ms
iter 2110: loss 1.1387, time 12.48ms
iter 2120: loss 1.1346, time 14.10ms
iter 2130: loss 1.1080, time 12.11ms
iter 2140: loss 1.1258, time 11.96ms
iter 2150: loss 1.1252, time 11.55ms
iter 2160: loss 1.1201, time 11.82ms
iter 2170: loss 1.1092, time 12.04ms
iter 2180: loss 1.1212, time 13.24ms
iter 2190: loss 1.1208, time 11.70ms
iter 2200: loss 1.1248, time 12.16ms
iter 2210: loss 1.1317, time 12.72ms
iter 2220: loss 1.1349, time 19.78ms
iter 2230: loss 1.0964, time 18.07ms
iter 2240: loss 1.0690, time 12.80ms
step 2250: train loss 1.0017, val loss 1.4857
iter 2250: loss 1.0737, time 4545.03ms
iter 2260: loss 1.0833, time 12.07ms
iter 2270: loss 1.1080, time 12.78ms
iter 2280: loss 1.0740, time 11.20ms
iter 2290: loss 1.1159, time 12.48ms
iter 2300: loss 1.0964, time 12.38ms
iter 2310: loss 1.1063, time 12.22ms
iter 2320: loss 1.1227, time 16.86ms
iter 2330: loss 1.0858, time 12.46ms
iter 2340: loss 1.0910, time 20.24ms
iter 2350: loss 1.1206, time 12.77ms
iter 2360: loss 1.0824, time 13.83ms
iter 2370: loss 1.0872, time 11.92ms
iter 2380: loss 1.0989, time 11.29ms
iter 2390: loss 1.0798, time 16.78ms
iter 2400: loss 1.0761, time 12.82ms
iter 2410: loss 1.0530, time 16.04ms
iter 2420: loss 1.0823, time 12.19ms
iter 2430: loss 1.0703, time 13.23ms
iter 2440: loss 1.0723, time 13.84ms
iter 2450: loss 1.0688, time 13.10ms
iter 2460: loss 1.1016, time 11.31ms
iter 2470: loss 1.0610, time 12.63ms
iter 2480: loss 1.0477, time 13.88ms
iter 2490: loss 1.0464, time 15.27ms
step 2500: train loss 0.9527, val loss 1.4932
iter 2500: loss 1.0501, time 4334.46ms
iter 2510: loss 1.0583, time 13.54ms
iter 2520: loss 1.0952, time 15.07ms
iter 2530: loss 1.1071, time 11.26ms
iter 2540: loss 1.0610, time 11.38ms
iter 2550: loss 1.0736, time 14.36ms
iter 2560: loss 1.0605, time 21.34ms
iter 2570: loss 1.0740, time 16.32ms
iter 2580: loss 1.0406, time 13.75ms
iter 2590: loss 1.0629, time 13.59ms
iter 2600: loss 1.0747, time 11.69ms
iter 2610: loss 1.0221, time 16.05ms
iter 2620: loss 1.0356, time 13.71ms
iter 2630: loss 1.0343, time 13.05ms
iter 2640: loss 1.0609, time 17.12ms
iter 2650: loss 1.0460, time 15.21ms
iter 2660: loss 1.0324, time 10.96ms
iter 2670: loss 1.0619, time 13.74ms
iter 2680: loss 1.0277, time 12.04ms
iter 2690: loss 1.0128, time 11.00ms
iter 2700: loss 1.0341, time 14.01ms
iter 2710: loss 1.0337, time 11.67ms
iter 2720: loss 1.0304, time 20.48ms
iter 2730: loss 1.0371, time 13.26ms
iter 2740: loss 1.0311, time 12.64ms
step 2750: train loss 0.9105, val loss 1.5143
iter 2750: loss 1.0236, time 4375.20ms
iter 2760: loss 1.0154, time 11.34ms
iter 2770: loss 1.0414, time 15.77ms
iter 2780: loss 1.0296, time 18.71ms
iter 2790: loss 1.0071, time 11.97ms
iter 2800: loss 1.0520, time 12.02ms
iter 2810: loss 1.0286, time 13.71ms
iter 2820: loss 1.0018, time 13.62ms
iter 2830: loss 0.9855, time 12.56ms
iter 2840: loss 1.0183, time 12.86ms
iter 2850: loss 1.0164, time 10.43ms
iter 2860: loss 1.0177, time 14.74ms
iter 2870: loss 1.0036, time 13.51ms
iter 2880: loss 1.0145, time 16.53ms
iter 2890: loss 0.9742, time 12.88ms
iter 2900: loss 1.0314, time 11.77ms
iter 2910: loss 1.0319, time 11.57ms
iter 2920: loss 1.0106, time 13.27ms
iter 2930: loss 1.0220, time 11.41ms
iter 2940: loss 0.9919, time 12.18ms
iter 2950: loss 0.9962, time 12.48ms
iter 2960: loss 0.9894, time 13.66ms
iter 2970: loss 0.9944, time 12.10ms
iter 2980: loss 1.0104, time 18.66ms
iter 2990: loss 0.9927, time 13.14ms
step 3000: train loss 0.8594, val loss 1.5310
iter 3000: loss 0.9862, time 5689.43ms
iter 3010: loss 0.9763, time 20.51ms
iter 3020: loss 0.9602, time 15.38ms
iter 3030: loss 1.0034, time 17.79ms
iter 3040: loss 0.9816, time 15.87ms
iter 3050: loss 1.0206, time 14.06ms
iter 3060: loss 0.9914, time 16.19ms
iter 3070: loss 0.9719, time 16.75ms
iter 3080: loss 0.9733, time 13.89ms
iter 3090: loss 0.9705, time 16.65ms
iter 3100: loss 0.9711, time 13.19ms
iter 3110: loss 0.9776, time 13.07ms
iter 3120: loss 0.9626, time 15.14ms
iter 3130: loss 0.9776, time 15.20ms
iter 3140: loss 1.0132, time 12.30ms
iter 3150: loss 0.9903, time 11.40ms
iter 3160: loss 0.9815, time 16.31ms
iter 3170: loss 0.9610, time 12.50ms
iter 3180: loss 0.9750, time 12.05ms
iter 3190: loss 0.9510, time 11.35ms
iter 3200: loss 0.9735, time 16.46ms
iter 3210: loss 0.9526, time 13.66ms
iter 3220: loss 0.9551, time 11.57ms
iter 3230: loss 0.9353, time 12.79ms
iter 3240: loss 0.9487, time 14.82ms
step 3250: train loss 0.8119, val loss 1.5559
iter 3250: loss 0.9605, time 4346.98ms
iter 3260: loss 0.9575, time 14.57ms
iter 3270: loss 0.9429, time 11.55ms
iter 3280: loss 0.9429, time 11.15ms
iter 3290: loss 0.9542, time 12.59ms
iter 3300: loss 0.9615, time 12.74ms
iter 3310: loss 0.9365, time 16.04ms
iter 3320: loss 0.9629, time 12.87ms
iter 3330: loss 0.9493, time 14.60ms
iter 3340: loss 0.9295, time 14.16ms
iter 3350: loss 0.9401, time 12.77ms
iter 3360: loss 0.9411, time 11.85ms
iter 3370: loss 0.9444, time 12.28ms
iter 3380: loss 0.9430, time 11.08ms
iter 3390: loss 0.9545, time 12.34ms
iter 3400: loss 0.9034, time 12.72ms
iter 3410: loss 0.9178, time 12.73ms
iter 3420: loss 0.9313, time 13.22ms
iter 3430: loss 0.9289, time 11.48ms
iter 3440: loss 0.9650, time 14.31ms
iter 3450: loss 0.9244, time 12.26ms
iter 3460: loss 0.8919, time 13.21ms
iter 3470: loss 0.9099, time 11.46ms
iter 3480: loss 0.9346, time 14.68ms
iter 3490: loss 0.9389, time 16.19ms
step 3500: train loss 0.7704, val loss 1.5742
iter 3500: loss 0.9130, time 6031.55ms
iter 3510: loss 0.9373, time 11.15ms
iter 3520: loss 0.9299, time 11.33ms
iter 3530: loss 0.9338, time 13.06ms
iter 3540: loss 0.9195, time 11.00ms
iter 3550: loss 0.9005, time 10.93ms
iter 3560: loss 0.9113, time 11.48ms
iter 3570: loss 0.9157, time 13.37ms
iter 3580: loss 0.9230, time 12.88ms
iter 3590: loss 0.9207, time 13.95ms
iter 3600: loss 0.9276, time 12.10ms
iter 3610: loss 0.9216, time 13.35ms
iter 3620: loss 0.8951, time 16.11ms
iter 3630: loss 0.9176, time 12.40ms
iter 3640: loss 0.9179, time 14.60ms
iter 3650: loss 0.9109, time 18.02ms
iter 3660: loss 0.9152, time 11.82ms
iter 3670: loss 0.9166, time 11.59ms
iter 3680: loss 0.8973, time 12.42ms
iter 3690: loss 0.9065, time 14.90ms
iter 3700: loss 0.9132, time 13.43ms
iter 3710: loss 0.8974, time 13.00ms
iter 3720: loss 0.9021, time 12.26ms
iter 3730: loss 0.8659, time 13.34ms
iter 3740: loss 0.8990, time 13.20ms
step 3750: train loss 0.7317, val loss 1.6027
iter 3750: loss 0.9035, time 4314.36ms
iter 3760: loss 0.8957, time 15.61ms
iter 3770: loss 0.9061, time 12.30ms
iter 3780: loss 0.9076, time 14.24ms
iter 3790: loss 0.8931, time 12.82ms
iter 3800: loss 0.8856, time 12.90ms
iter 3810: loss 0.8897, time 13.63ms
iter 3820: loss 0.8923, time 13.24ms
iter 3830: loss 0.8806, time 13.30ms
iter 3840: loss 0.8674, time 13.41ms
iter 3850: loss 0.9072, time 10.80ms
iter 3860: loss 0.9163, time 11.97ms
iter 3870: loss 0.8701, time 14.17ms
iter 3880: loss 0.8983, time 12.04ms
iter 3890: loss 0.8866, time 12.57ms
iter 3900: loss 0.8721, time 11.78ms
iter 3910: loss 0.8688, time 11.49ms
iter 3920: loss 0.8894, time 13.17ms
iter 3930: loss 0.8771, time 14.15ms
iter 3940: loss 0.8673, time 11.94ms
iter 3950: loss 0.8884, time 11.67ms
iter 3960: loss 0.8765, time 11.85ms
iter 3970: loss 0.8675, time 13.05ms
iter 3980: loss 0.8802, time 11.26ms
iter 3990: loss 0.9003, time 14.75ms
step 4000: train loss 0.6985, val loss 1.6247
iter 4000: loss 0.9056, time 4107.02ms
iter 4010: loss 0.8558, time 12.37ms
iter 4020: loss 0.8631, time 13.62ms
iter 4030: loss 0.8505, time 12.46ms
iter 4040: loss 0.8721, time 13.05ms
iter 4050: loss 0.8770, time 12.60ms
iter 4060: loss 0.8739, time 13.29ms
iter 4070: loss 0.8834, time 14.23ms
iter 4080: loss 0.8618, time 12.66ms
iter 4090: loss 0.8665, time 13.50ms
iter 4100: loss 0.8620, time 13.67ms
iter 4110: loss 0.8620, time 12.69ms
iter 4120: loss 0.8919, time 11.87ms
iter 4130: loss 0.8587, time 12.99ms
iter 4140: loss 0.8727, time 13.37ms
iter 4150: loss 0.8512, time 12.09ms
iter 4160: loss 0.8490, time 13.48ms
iter 4170: loss 0.8543, time 13.02ms
iter 4180: loss 0.8555, time 11.53ms
iter 4190: loss 0.8496, time 15.95ms
iter 4200: loss 0.8650, time 12.14ms
iter 4210: loss 0.8407, time 11.98ms
iter 4220: loss 0.8589, time 11.99ms
iter 4230: loss 0.8495, time 14.75ms
iter 4240: loss 0.8812, time 17.84ms
step 4250: train loss 0.6686, val loss 1.6502
iter 4250: loss 0.8628, time 4510.70ms
iter 4260: loss 0.8309, time 13.56ms
iter 4270: loss 0.8588, time 14.55ms
iter 4280: loss 0.8486, time 15.46ms
iter 4290: loss 0.8642, time 17.83ms
iter 4300: loss 0.8459, time 11.82ms
iter 4310: loss 0.8349, time 13.06ms
iter 4320: loss 0.8541, time 14.27ms
iter 4330: loss 0.8602, time 12.55ms
iter 4340: loss 0.8491, time 12.35ms
iter 4350: loss 0.8609, time 11.47ms
iter 4360: loss 0.8330, time 14.02ms
iter 4370: loss 0.8323, time 12.97ms
iter 4380: loss 0.8496, time 13.11ms
iter 4390: loss 0.8443, time 11.83ms
iter 4400: loss 0.8476, time 16.93ms
iter 4410: loss 0.8576, time 17.29ms
iter 4420: loss 0.8222, time 10.43ms
iter 4430: loss 0.8464, time 15.19ms
iter 4440: loss 0.8351, time 15.50ms
iter 4450: loss 0.8507, time 11.55ms
iter 4460: loss 0.8493, time 15.72ms
iter 4470: loss 0.8279, time 12.79ms
iter 4480: loss 0.8503, time 12.50ms
iter 4490: loss 0.8085, time 12.53ms
step 4500: train loss 0.6468, val loss 1.6638
iter 4500: loss 0.8362, time 4537.72ms
iter 4510: loss 0.8330, time 14.87ms
iter 4520: loss 0.8413, time 14.49ms
iter 4530: loss 0.8235, time 12.20ms
iter 4540: loss 0.8371, time 14.36ms
iter 4550: loss 0.8215, time 12.26ms
iter 4560: loss 0.8275, time 13.79ms
iter 4570: loss 0.8264, time 13.91ms
iter 4580: loss 0.8559, time 12.56ms
iter 4590: loss 0.8136, time 14.20ms
iter 4600: loss 0.8260, time 15.98ms
iter 4610: loss 0.8309, time 11.94ms
iter 4620: loss 0.8395, time 12.81ms
iter 4630: loss 0.8255, time 12.75ms
iter 4640: loss 0.8212, time 13.74ms
iter 4650: loss 0.8367, time 12.23ms
iter 4660: loss 0.8414, time 11.95ms
iter 4670: loss 0.8163, time 12.62ms
iter 4680: loss 0.8520, time 13.00ms
iter 4690: loss 0.8093, time 15.35ms
iter 4700: loss 0.8338, time 13.55ms
iter 4710: loss 0.8471, time 12.41ms
iter 4720: loss 0.8295, time 12.47ms
iter 4730: loss 0.8440, time 11.83ms
iter 4740: loss 0.8356, time 11.55ms
step 4750: train loss 0.6256, val loss 1.6780
iter 4750: loss 0.8392, time 4319.46ms
iter 4760: loss 0.8341, time 14.92ms
iter 4770: loss 0.8224, time 12.17ms
iter 4780: loss 0.8039, time 12.41ms
iter 4790: loss 0.8198, time 12.56ms
iter 4800: loss 0.8022, time 13.00ms
iter 4810: loss 0.8349, time 12.41ms
iter 4820: loss 0.8084, time 13.71ms
iter 4830: loss 0.8080, time 13.68ms
iter 4840: loss 0.8362, time 13.42ms
iter 4850: loss 0.8133, time 13.48ms
iter 4860: loss 0.8200, time 12.66ms
iter 4870: loss 0.8152, time 12.02ms
iter 4880: loss 0.8194, time 12.24ms
iter 4890: loss 0.8343, time 11.81ms
iter 4900: loss 0.8179, time 13.01ms
iter 4910: loss 0.8107, time 11.41ms
iter 4920: loss 0.8140, time 10.69ms
iter 4930: loss 0.8143, time 10.54ms
iter 4940: loss 0.7860, time 13.32ms
iter 4950: loss 0.8189, time 14.83ms
iter 4960: loss 0.7996, time 12.21ms
iter 4970: loss 0.8134, time 11.51ms
iter 4980: loss 0.7920, time 17.04ms
iter 4990: loss 0.8073, time 39.77ms
step 5000: train loss 0.6104, val loss 1.6935
iter 5000: loss 0.8265, time 4158.61ms
training done
Best validation loss: 1.464621901512146
Total train time: 2.69 mins
Loading meta from ../../data/shakespeare_char/meta.pkl...
Sample 1:
 the contraction
That do not fear: the beetle hurt in the state
And follow him, he would not return for his time;
For he was in worth presence where he speaks,
We'll keep him grace: the very best and call'd
The same leanness of our friends and to meet him ere
Because his necess that will have touch'd.

LEONTES:
What doth he the bear?

PAULINA:
Not to be seen to be shortly conceived
Where ladies shall do it: 'tis as you say,
That they have often as 'twere not pity,
But to crave them as your house:
Inference time: 1.86 seconds
Tokens per second: 269.36
---------------
Sample 2:
 away with me.

POMPEY:
Why, no; I will prove the sister of the world
will be gone; for this wronged will to't the bawdy and
the thing is all as if it were, in proofs.

POMPEY:
Truly, in troth, the sun no with you; if it be
tailors the present piece of yourself to care the worst,
you must be loathsome, show your good faces have
delivered, droop'd to you all.

MISTRESS OVERDONE:
Your poverty, sir, have patience; 'tis more
than you have warrant them, but that they have patience.

MISTRESS OVERDONE:
Inference time: 1.85 seconds
Tokens per second: 270.42
---------------
Sample 3:
 of love,
The consent of the winter's tenderness
Of the searcherds of my son's head, and
The trembling of their vices, being prevented
With that pestilence of my nature through
Should prove me with this intelligence, perform
The honour of the worship of recomfort and shake
Your honour husband's lands. But, lords, I pray you,
We have sent to the boar by your voices:
Come hither, and on the contract of you
To be your bent of this action, that you shall find
No better than than you.

BRUTUS:
What's 
Inference time: 1.87 seconds
Tokens per second: 267.70
---------------
Sample 4:
 king, as from heaven so bright as thou art,
And to me in safety to my hope,
And give me like a glass throne. Then relish thee
To crave my soul, I'll not prophesy:
A most interent virtue gave me my sweet love!
And to my ceased night for such need presence
As moveable as my prayers I might undertake
For my death the empty have made me fair,
Or I will not put and perform it to dispose,
Where I am nor uncle York possess;
But to reply the crown to that seeks into his light,
And here the right way of 
Inference time: 1.85 seconds
Tokens per second: 269.96
---------------
Sample 5:
 this, the tongueless shoes
Are current to be with his nets; and, in haste,
That thou shouldst die for being quarrels
That which thou art not, made thy brother stands
Ne'er see thy person a man to thee.
But to make an earth through this did never feel:
So shall I receive thee so much to me:
I never saw the like.

PETRUCHIO:
Are you a jewel or children?

GREMIO:
That's the while: and if you'll call it not.

GRUMIO:
Nor I.

HORTENSIO:
Why, that's a word of maid like you, Pitizen:
You know our time 
Inference time: 1.87 seconds
Tokens per second: 267.15
---------------
Sample 6:
 you, consider to a person.

First Citizen:
You are good to pardon him in: he are he
died for Volsces, and being of all intered.

Second Citizen:
This matters of the constable's fellow, what
he has been stronged alike, and that he would have it sounded.

First Citizen:
Nay, it is: and the wind the worst comes to be our fearful day.

First Citizen:
It is a gentleman of the people; which I do refuse it
you, think our general is much unholy roof in justice,
patience, and true to be executed, and go 
Inference time: 1.89 seconds
Tokens per second: 264.55
---------------
Sample 7:
 the goose to pursuivant,
Which some sparks upon my father's side.

GLOUCESTER:
My lord, what you say, my Lord of Surrey?

YORK:
I'll keep that old Oxford, my lord and me.

YORK:
I will not for this deep were lodged at once.

EXETER:
I warrant you, cousin, I must give my hands.

YORK:
My gracious lord, I have heard the worst of the court
My brook out with bowels to the ground them of my heart.

KING HENRY VI:
O, when I was an instrument bosom, but not they
The princess that they both can do what 
Inference time: 1.85 seconds
Tokens per second: 270.71
---------------
Sample 8:
 and puny the air of your blood
Hath not come to a cup of curses; the tenor
of yours, whose sakes men broils with a pack-sack?
What answer made your father was, they are come.

SICINIUS:
Pray you, let's away. Go to the city flatter.

BRUTUS:
Go you to to you.

MENENIUS:
What would you have done?

CORIOLANUS:
The matter?

COMINIUS:
I do beseech you, then we shall bear, we'll
My worthier than comfort that which they will command:
Their own deserts report my part will not hear it,
Which men were the
Inference time: 1.87 seconds
Tokens per second: 266.94
---------------
Sample 9:
 and from thy father's head;
And then in the seeming prince, let me say,
Yet I see thy husband's lands and I dream on.

NORTHUMBERLAND:
My lord, your company I have pursued;
Had I infer your voices seen me well,
And make you the basilisk.

DUKE OF YORK:
Call me the majesty.

HENRY PERCY:
Then be the precious tomb.

KING RICHARD II:
In God's name, shall I be young, if you late?

DUCHESS OF YORK:
Why, then better groan in my knee I should not be.

KING RICHARD III:
Ay, look to his chair, and show h
Inference time: 1.86 seconds
Tokens per second: 268.12
---------------
Sample 10:
 fled by a flaw,
To save thy heart a fortune with thy hand;
And where thou shalt reign name to move thee,
The lists of thy tears and wild do good night.

GLOUCESTER:
What, thrive wench, then and weeping eyes of it.

BUCKINGHAM:
It was; and he respects thee for his country,
As thou art as honest as hot a just as fast.

GLOUCESTER:
Then be it as you would be so, I hear it as lost.

LADY ANNE:
No, sir, I had it the matter; and I am out of justice
Of a purpose tradition.
Being in a coming, I am littl
Inference time: 1.85 seconds
Tokens per second: 270.04
---------------
Average tokens per second: 268.49
tokens per iteration will be: 8,192
found vocab_size = 205 (inside ../../data/enwik8/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.71M
num decayed parameter tensors: 26, with 10,793,856 parameters
num non-decayed parameter tensors: 31, with 14,220 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 5.3878, val loss 5.3884
iter 0: loss 5.3846, time 45138.27ms
iter 100: loss 2.7371, time 9.94ms
iter 200: loss 2.5744, time 22.58ms
iter 300: loss 2.4935, time 8.59ms
iter 400: loss 2.3736, time 10.22ms
iter 500: loss 2.2968, time 9.87ms
iter 600: loss 2.2604, time 10.05ms
iter 700: loss 2.1488, time 10.12ms
iter 800: loss 2.0732, time 9.92ms
iter 900: loss 2.0425, time 12.74ms
step 1000: train loss 1.8369, val loss 1.8384
iter 1000: loss 1.8859, time 4529.95ms
iter 1100: loss 1.8465, time 15.31ms
iter 1200: loss 1.8418, time 24.17ms
iter 1300: loss 1.7411, time 15.12ms
iter 1400: loss 1.7352, time 10.42ms
iter 1500: loss 1.7139, time 9.91ms
iter 1600: loss 1.7135, time 14.91ms
iter 1700: loss 1.6246, time 27.28ms
iter 1800: loss 1.5077, time 18.66ms
iter 1900: loss 1.5410, time 10.86ms
step 2000: train loss 1.4571, val loss 1.4646
iter 2000: loss 1.6156, time 2958.74ms
iter 2100: loss 1.5628, time 10.00ms
iter 2200: loss 1.5240, time 10.83ms
iter 2300: loss 1.5176, time 9.93ms
iter 2400: loss 1.4692, time 10.39ms
iter 2500: loss 1.4717, time 9.63ms
iter 2600: loss 1.3806, time 9.87ms
iter 2700: loss 1.4915, time 13.81ms
iter 2800: loss 1.3479, time 15.13ms
iter 2900: loss 1.4777, time 25.04ms
step 3000: train loss 1.3538, val loss 1.3625
iter 3000: loss 1.4482, time 3607.75ms
iter 3100: loss 1.3380, time 15.46ms
iter 3200: loss 1.4369, time 9.93ms
iter 3300: loss 1.4231, time 10.68ms
iter 3400: loss 1.3742, time 10.01ms
iter 3500: loss 1.4816, time 10.67ms
iter 3600: loss 1.3416, time 10.62ms
iter 3700: loss 1.4283, time 18.33ms
iter 3800: loss 1.4166, time 14.33ms
iter 3900: loss 1.4021, time 11.06ms
step 4000: train loss 1.2915, val loss 1.3052
iter 4000: loss 1.3301, time 3371.56ms
iter 4100: loss 1.3106, time 9.90ms
iter 4200: loss 1.3155, time 9.85ms
iter 4300: loss 1.4256, time 9.94ms
iter 4400: loss 1.3200, time 12.65ms
iter 4500: loss 1.3447, time 20.27ms
iter 4600: loss 1.3410, time 10.00ms
iter 4700: loss 1.4012, time 9.98ms
iter 4800: loss 1.3068, time 9.94ms
iter 4900: loss 1.2904, time 9.63ms
step 5000: train loss 1.2603, val loss 1.2638
iter 5000: loss 1.2702, time 2750.76ms
iter 5100: loss 1.2893, time 9.54ms
iter 5200: loss 1.3564, time 10.57ms
iter 5300: loss 1.2978, time 12.68ms
iter 5400: loss 1.3143, time 9.78ms
iter 5500: loss 1.3019, time 10.38ms
iter 5600: loss 1.2309, time 10.19ms
iter 5700: loss 1.3038, time 10.88ms
iter 5800: loss 1.3445, time 9.64ms
iter 5900: loss 1.2672, time 9.89ms
step 6000: train loss 1.2327, val loss 1.2505
iter 6000: loss 1.3279, time 2645.60ms
iter 6100: loss 1.2341, time 10.01ms
iter 6200: loss 1.2730, time 10.57ms
iter 6300: loss 1.3930, time 9.65ms
iter 6400: loss 1.3129, time 11.74ms
iter 6500: loss 1.3905, time 11.23ms
iter 6600: loss 1.3083, time 9.97ms
iter 6700: loss 1.2922, time 10.48ms
iter 6800: loss 1.3195, time 10.95ms
iter 6900: loss 1.2760, time 9.90ms
step 7000: train loss 1.2156, val loss 1.2314
iter 7000: loss 1.3216, time 2532.28ms
iter 7100: loss 1.2846, time 9.93ms
iter 7200: loss 1.3391, time 9.95ms
iter 7300: loss 1.3072, time 10.90ms
iter 7400: loss 1.2209, time 10.17ms
iter 7500: loss 1.2897, time 9.68ms
iter 7600: loss 1.3251, time 10.39ms
iter 7700: loss 1.2302, time 9.20ms
iter 7800: loss 1.2581, time 9.55ms
iter 7900: loss 1.3049, time 10.47ms
step 8000: train loss 1.1973, val loss 1.2116
iter 8000: loss 1.1515, time 2591.82ms
iter 8100: loss 1.1809, time 10.32ms
iter 8200: loss 1.2576, time 9.59ms
iter 8300: loss 1.2785, time 11.28ms
iter 8400: loss 1.3058, time 9.64ms
iter 8500: loss 1.2512, time 12.36ms
iter 8600: loss 1.3207, time 10.20ms
iter 8700: loss 1.2644, time 9.98ms
iter 8800: loss 1.2854, time 11.64ms
iter 8900: loss 1.2523, time 10.12ms
step 9000: train loss 1.1949, val loss 1.2014
iter 9000: loss 1.2164, time 2784.71ms
iter 9100: loss 1.3413, time 10.72ms
iter 9200: loss 1.2444, time 9.76ms
iter 9300: loss 1.2452, time 10.15ms
iter 9400: loss 1.2350, time 10.24ms
iter 9500: loss 1.2369, time 10.20ms
iter 9600: loss 1.2666, time 11.01ms
iter 9700: loss 1.1808, time 9.70ms
iter 9800: loss 1.2645, time 9.84ms
iter 9900: loss 1.2119, time 9.62ms
step 10000: train loss 1.1708, val loss 1.1881
iter 10000: loss 1.1550, time 3161.80ms
iter 10100: loss 1.2408, time 13.05ms
iter 10200: loss 1.3364, time 10.09ms
iter 10300: loss 1.2149, time 30.37ms
iter 10400: loss 1.2368, time 23.67ms
iter 10500: loss 1.2889, time 15.67ms
iter 10600: loss 1.2477, time 14.05ms
iter 10700: loss 1.2089, time 13.83ms
iter 10800: loss 1.2242, time 15.12ms
iter 10900: loss 1.2992, time 14.23ms
step 11000: train loss 1.1691, val loss 1.1837
iter 11000: loss 1.2531, time 3171.44ms
iter 11100: loss 1.1926, time 26.63ms
iter 11200: loss 1.2731, time 9.88ms
iter 11300: loss 1.2351, time 10.57ms
iter 11400: loss 1.1933, time 9.78ms
iter 11500: loss 1.2509, time 10.18ms
iter 11600: loss 1.2853, time 9.89ms
iter 11700: loss 1.2671, time 11.47ms
iter 11800: loss 1.2505, time 13.28ms
iter 11900: loss 1.2428, time 9.78ms
step 12000: train loss 1.1559, val loss 1.1706
iter 12000: loss 1.2081, time 2659.80ms
iter 12100: loss 1.2840, time 9.73ms
iter 12200: loss 1.2938, time 9.77ms
iter 12300: loss 1.1703, time 9.85ms
iter 12400: loss 1.2800, time 10.03ms
iter 12500: loss 1.2607, time 10.46ms
iter 12600: loss 1.2635, time 10.10ms
iter 12700: loss 1.1925, time 9.94ms
iter 12800: loss 1.2112, time 10.30ms
iter 12900: loss 1.2252, time 9.97ms
step 13000: train loss 1.1556, val loss 1.1643
iter 13000: loss 1.1182, time 2678.43ms
iter 13100: loss 1.2588, time 10.23ms
iter 13200: loss 1.1375, time 10.98ms
iter 13300: loss 1.2119, time 9.68ms
iter 13400: loss 1.2977, time 9.98ms
iter 13500: loss 1.1756, time 10.02ms
iter 13600: loss 1.2175, time 10.06ms
iter 13700: loss 1.1429, time 10.19ms
iter 13800: loss 1.1928, time 10.35ms
iter 13900: loss 1.1593, time 9.97ms
step 14000: train loss 1.1465, val loss 1.1639
iter 14000: loss 1.2382, time 2947.62ms
iter 14100: loss 1.1866, time 10.37ms
iter 14200: loss 1.1926, time 11.73ms
iter 14300: loss 1.1909, time 12.28ms
iter 14400: loss 1.2251, time 9.79ms
iter 14500: loss 1.1960, time 10.22ms
iter 14600: loss 1.1812, time 9.68ms
iter 14700: loss 1.2784, time 10.35ms
iter 14800: loss 1.1360, time 9.63ms
iter 14900: loss 1.1784, time 10.82ms
step 15000: train loss 1.1412, val loss 1.1582
iter 15000: loss 1.1398, time 2564.34ms
iter 15100: loss 1.2436, time 9.59ms
iter 15200: loss 1.1231, time 10.05ms
iter 15300: loss 1.1679, time 10.53ms
iter 15400: loss 1.1678, time 11.09ms
iter 15500: loss 1.2265, time 11.01ms
iter 15600: loss 1.1717, time 10.40ms
iter 15700: loss 1.1549, time 10.80ms
iter 15800: loss 1.0985, time 10.01ms
iter 15900: loss 1.2029, time 11.00ms
step 16000: train loss 1.1326, val loss 1.1544
iter 16000: loss 1.1389, time 3133.49ms
iter 16100: loss 1.2029, time 10.36ms
iter 16200: loss 1.2193, time 10.34ms
iter 16300: loss 1.1613, time 14.73ms
iter 16400: loss 1.1440, time 10.20ms
iter 16500: loss 1.1550, time 13.11ms
iter 16600: loss 1.1963, time 11.17ms
iter 16700: loss 1.1784, time 16.33ms
iter 16800: loss 1.1582, time 10.37ms
iter 16900: loss 1.1167, time 11.06ms
step 17000: train loss 1.1294, val loss 1.1476
iter 17000: loss 1.2634, time 2972.66ms
iter 17100: loss 1.2135, time 16.18ms
iter 17200: loss 1.1650, time 12.43ms
iter 17300: loss 1.1133, time 10.74ms
iter 17400: loss 1.1953, time 10.02ms
iter 17500: loss 1.1865, time 9.76ms
iter 17600: loss 1.2220, time 10.47ms
iter 17700: loss 1.1409, time 12.45ms
iter 17800: loss 1.2236, time 11.03ms
iter 17900: loss 1.1477, time 9.85ms
step 18000: train loss 1.1220, val loss 1.1346
iter 18000: loss 1.1655, time 2753.90ms
iter 18100: loss 1.1627, time 9.58ms
iter 18200: loss 1.2213, time 9.56ms
iter 18300: loss 1.2119, time 10.33ms
iter 18400: loss 1.2236, time 11.82ms
iter 18500: loss 1.1395, time 10.20ms
iter 18600: loss 1.1523, time 10.09ms
iter 18700: loss 1.2184, time 10.21ms
iter 18800: loss 1.1351, time 9.95ms
iter 18900: loss 1.1346, time 10.42ms
step 19000: train loss 1.1180, val loss 1.1396
iter 19000: loss 1.2295, time 2567.76ms
iter 19100: loss 1.1918, time 10.63ms
iter 19200: loss 1.1475, time 10.11ms
iter 19300: loss 1.1185, time 9.64ms
iter 19400: loss 1.2621, time 9.61ms
iter 19500: loss 1.3083, time 9.99ms
iter 19600: loss 1.2073, time 9.49ms
iter 19700: loss 1.1807, time 10.02ms
iter 19800: loss 1.1057, time 9.98ms
iter 19900: loss 1.1881, time 10.72ms
step 20000: train loss 1.1112, val loss 1.1363
iter 20000: loss 1.1948, time 2481.24ms
iter 20100: loss 1.1794, time 9.78ms
iter 20200: loss 1.1229, time 9.84ms
iter 20300: loss 1.1948, time 10.10ms
iter 20400: loss 1.2040, time 10.31ms
iter 20500: loss 1.1846, time 10.35ms
iter 20600: loss 1.2130, time 9.87ms
iter 20700: loss 1.1927, time 9.93ms
iter 20800: loss 1.2161, time 9.78ms
iter 20900: loss 1.1276, time 12.67ms
step 21000: train loss 1.1108, val loss 1.1335
iter 21000: loss 1.2258, time 2518.43ms
iter 21100: loss 1.1934, time 10.20ms
iter 21200: loss 1.2146, time 10.34ms
iter 21300: loss 1.2216, time 10.21ms
iter 21400: loss 1.2252, time 10.04ms
iter 21500: loss 1.1386, time 9.64ms
iter 21600: loss 1.1711, time 10.21ms
iter 21700: loss 1.1072, time 9.67ms
iter 21800: loss 1.2088, time 17.96ms
iter 21900: loss 1.1949, time 20.10ms
step 22000: train loss 1.1049, val loss 1.1237
iter 22000: loss 1.0631, time 6437.01ms
iter 22100: loss 1.2288, time 10.13ms
iter 22200: loss 1.2883, time 9.99ms
iter 22300: loss 1.2271, time 10.96ms
iter 22400: loss 1.1373, time 10.72ms
iter 22500: loss 1.1636, time 9.99ms
iter 22600: loss 1.1823, time 10.27ms
iter 22700: loss 1.1660, time 10.92ms
iter 22800: loss 1.1379, time 9.65ms
iter 22900: loss 1.1405, time 10.04ms
step 23000: train loss 1.1000, val loss 1.1226
iter 23000: loss 1.1033, time 2698.34ms
iter 23100: loss 1.1581, time 9.76ms
iter 23200: loss 1.2037, time 10.26ms
iter 23300: loss 1.1738, time 10.90ms
iter 23400: loss 1.1985, time 10.24ms
iter 23500: loss 1.1738, time 9.92ms
iter 23600: loss 1.2085, time 10.27ms
iter 23700: loss 1.1795, time 9.97ms
iter 23800: loss 1.2019, time 14.67ms
iter 23900: loss 1.1446, time 13.36ms
step 24000: train loss 1.0970, val loss 1.1143
iter 24000: loss 1.1978, time 2755.82ms
iter 24100: loss 1.0661, time 17.94ms
iter 24200: loss 1.0839, time 9.82ms
iter 24300: loss 1.1298, time 10.10ms
iter 24400: loss 1.1840, time 10.21ms
iter 24500: loss 1.1465, time 10.17ms
iter 24600: loss 1.1719, time 10.04ms
iter 24700: loss 1.1138, time 10.01ms
iter 24800: loss 1.1780, time 10.54ms
iter 24900: loss 1.1440, time 10.86ms
step 25000: train loss 1.0863, val loss 1.1127
iter 25000: loss 1.2243, time 2660.36ms
iter 25100: loss 1.2714, time 10.49ms
iter 25200: loss 1.1129, time 15.01ms
iter 25300: loss 1.1066, time 10.30ms
iter 25400: loss 1.1770, time 10.14ms
iter 25500: loss 1.1845, time 11.36ms
iter 25600: loss 1.0287, time 11.11ms
iter 25700: loss 1.0458, time 12.00ms
iter 25800: loss 1.1657, time 9.73ms
iter 25900: loss 1.0949, time 10.04ms
step 26000: train loss 1.0887, val loss 1.1168
iter 26000: loss 1.1614, time 2561.90ms
iter 26100: loss 1.1843, time 10.08ms
iter 26200: loss 1.1346, time 11.64ms
iter 26300: loss 1.1294, time 10.40ms
iter 26400: loss 1.1458, time 10.42ms
iter 26500: loss 1.2205, time 10.46ms
iter 26600: loss 1.1117, time 11.99ms
iter 26700: loss 1.1235, time 10.75ms
iter 26800: loss 1.1822, time 10.06ms
iter 26900: loss 1.1638, time 10.19ms
step 27000: train loss 1.0916, val loss 1.1170
iter 27000: loss 1.1436, time 2605.26ms
iter 27100: loss 1.1227, time 10.19ms
iter 27200: loss 1.1497, time 9.91ms
iter 27300: loss 1.1630, time 10.64ms
iter 27400: loss 1.1422, time 10.20ms
iter 27500: loss 1.1130, time 10.77ms
iter 27600: loss 1.2055, time 11.96ms
iter 27700: loss 1.1849, time 9.47ms
iter 27800: loss 1.1823, time 10.40ms
iter 27900: loss 1.1055, time 10.39ms
step 28000: train loss 1.0867, val loss 1.1121
iter 28000: loss 1.1120, time 2459.20ms
iter 28100: loss 1.1669, time 9.95ms
iter 28200: loss 1.0854, time 10.09ms
iter 28300: loss 1.1836, time 10.15ms
iter 28400: loss 1.1358, time 9.71ms
iter 28500: loss 1.1701, time 9.84ms
iter 28600: loss 1.1354, time 10.42ms
iter 28700: loss 1.0358, time 9.69ms
iter 28800: loss 1.1492, time 11.18ms
iter 28900: loss 1.2503, time 10.04ms
step 29000: train loss 1.0896, val loss 1.1021
iter 29000: loss 1.1688, time 2637.17ms
iter 29100: loss 1.0880, time 10.85ms
iter 29200: loss 1.1675, time 9.79ms
iter 29300: loss 1.2402, time 10.73ms
iter 29400: loss 1.1862, time 9.93ms
iter 29500: loss 1.1429, time 10.17ms
iter 29600: loss 1.1551, time 10.24ms
iter 29700: loss 1.2481, time 10.04ms
iter 29800: loss 1.1773, time 10.16ms
iter 29900: loss 1.0957, time 9.55ms
step 30000: train loss 1.0831, val loss 1.1020
iter 30000: loss 1.1243, time 2640.30ms
iter 30100: loss 1.0346, time 10.17ms
iter 30200: loss 1.0859, time 9.98ms
iter 30300: loss 1.1017, time 9.92ms
iter 30400: loss 1.1029, time 9.90ms
iter 30500: loss 1.0263, time 13.05ms
iter 30600: loss 1.1791, time 10.31ms
iter 30700: loss 1.1572, time 11.23ms
iter 30800: loss 1.0650, time 10.06ms
iter 30900: loss 1.1191, time 11.90ms
step 31000: train loss 1.0740, val loss 1.1019
iter 31000: loss 1.1087, time 2676.07ms
iter 31100: loss 1.0962, time 10.63ms
iter 31200: loss 1.0926, time 10.57ms
iter 31300: loss 1.0305, time 11.07ms
iter 31400: loss 1.1664, time 10.08ms
iter 31500: loss 1.0889, time 11.52ms
iter 31600: loss 1.1862, time 9.95ms
iter 31700: loss 1.0923, time 9.95ms
iter 31800: loss 1.1162, time 10.20ms
iter 31900: loss 1.0379, time 10.61ms
step 32000: train loss 1.0769, val loss 1.0987
iter 32000: loss 1.1566, time 2619.45ms
iter 32100: loss 1.1359, time 10.76ms
iter 32200: loss 1.0922, time 10.05ms
iter 32300: loss 1.2051, time 11.75ms
iter 32400: loss 1.0519, time 9.86ms
iter 32500: loss 1.1260, time 10.09ms
iter 32600: loss 1.1296, time 10.42ms
iter 32700: loss 1.1402, time 9.90ms
iter 32800: loss 1.1973, time 12.15ms
iter 32900: loss 1.1311, time 11.83ms
step 33000: train loss 1.0752, val loss 1.0951
iter 33000: loss 1.1138, time 2610.42ms
iter 33100: loss 1.2048, time 10.76ms
iter 33200: loss 1.1667, time 10.16ms
iter 33300: loss 1.0705, time 10.94ms
iter 33400: loss 1.1892, time 10.52ms
iter 33500: loss 1.2229, time 10.16ms
iter 33600: loss 1.0998, time 10.80ms
iter 33700: loss 1.0783, time 9.92ms
iter 33800: loss 1.1487, time 9.61ms
iter 33900: loss 1.1650, time 10.05ms
step 34000: train loss 1.0791, val loss 1.0932
iter 34000: loss 1.1177, time 2606.33ms
iter 34100: loss 1.0990, time 15.51ms
iter 34200: loss 1.1099, time 10.48ms
iter 34300: loss 1.1617, time 10.34ms
iter 34400: loss 1.1186, time 10.57ms
iter 34500: loss 1.0194, time 10.07ms
iter 34600: loss 1.1278, time 9.59ms
iter 34700: loss 1.1458, time 10.14ms
iter 34800: loss 1.0698, time 12.67ms
iter 34900: loss 1.1133, time 9.84ms
step 35000: train loss 1.0696, val loss 1.0917
iter 35000: loss 1.1297, time 2657.18ms
iter 35100: loss 1.1390, time 10.89ms
iter 35200: loss 1.0950, time 9.99ms
iter 35300: loss 1.0549, time 10.57ms
iter 35400: loss 1.1833, time 9.85ms
iter 35500: loss 1.1422, time 9.81ms
iter 35600: loss 1.1061, time 10.69ms
iter 35700: loss 1.1403, time 10.54ms
iter 35800: loss 1.0638, time 10.03ms
iter 35900: loss 1.0906, time 10.33ms
step 36000: train loss 1.0608, val loss 1.0898
iter 36000: loss 1.1609, time 2690.50ms
iter 36100: loss 1.1008, time 10.70ms
iter 36200: loss 1.2025, time 10.34ms
iter 36300: loss 1.1509, time 10.82ms
iter 36400: loss 1.0374, time 9.91ms
iter 36500: loss 1.0743, time 10.43ms
iter 36600: loss 1.1226, time 10.65ms
iter 36700: loss 1.1265, time 9.81ms
iter 36800: loss 1.1375, time 10.07ms
iter 36900: loss 1.2445, time 10.61ms
step 37000: train loss 1.0609, val loss 1.0901
iter 37000: loss 1.1166, time 2657.97ms
iter 37100: loss 1.1475, time 9.94ms
iter 37200: loss 1.1391, time 9.45ms
iter 37300: loss 1.1285, time 10.60ms
iter 37400: loss 1.0852, time 9.85ms
iter 37500: loss 1.1549, time 18.70ms
iter 37600: loss 1.1610, time 22.51ms
iter 37700: loss 1.1813, time 16.15ms
iter 37800: loss 1.2090, time 9.92ms
iter 37900: loss 1.1264, time 9.84ms
step 38000: train loss 1.0630, val loss 1.0844
iter 38000: loss 1.1630, time 2706.86ms
iter 38100: loss 1.1551, time 11.90ms
iter 38200: loss 1.0933, time 9.95ms
iter 38300: loss 1.0903, time 10.25ms
iter 38400: loss 1.2097, time 10.42ms
iter 38500: loss 1.1774, time 12.12ms
iter 38600: loss 1.0555, time 11.67ms
iter 38700: loss 1.2203, time 10.10ms
iter 38800: loss 1.1303, time 10.54ms
iter 38900: loss 1.0994, time 10.73ms
step 39000: train loss 1.0669, val loss 1.0860
iter 39000: loss 1.0902, time 2607.47ms
iter 39100: loss 1.1053, time 10.55ms
iter 39200: loss 1.0579, time 10.18ms
iter 39300: loss 1.1107, time 10.68ms
iter 39400: loss 1.1566, time 9.85ms
iter 39500: loss 1.1402, time 10.50ms
iter 39600: loss 1.0762, time 10.33ms
iter 39700: loss 1.0925, time 10.71ms
iter 39800: loss 1.1695, time 10.10ms
iter 39900: loss 1.1301, time 9.83ms
step 40000: train loss 1.0586, val loss 1.0790
iter 40000: loss 1.0614, time 2597.52ms
iter 40100: loss 1.0998, time 11.19ms
iter 40200: loss 1.1393, time 10.45ms
iter 40300: loss 1.1586, time 10.02ms
iter 40400: loss 1.1717, time 10.47ms
iter 40500: loss 1.1116, time 10.16ms
iter 40600: loss 1.1760, time 9.66ms
iter 40700: loss 1.0834, time 9.89ms
iter 40800: loss 1.1500, time 10.21ms
iter 40900: loss 1.1892, time 9.97ms
step 41000: train loss 1.0576, val loss 1.0783
iter 41000: loss 1.0838, time 2559.32ms
iter 41100: loss 1.1362, time 9.85ms
iter 41200: loss 1.0430, time 9.57ms
iter 41300: loss 1.1317, time 10.01ms
iter 41400: loss 1.1269, time 10.01ms
iter 41500: loss 1.1348, time 10.13ms
iter 41600: loss 1.1393, time 10.34ms
iter 41700: loss 1.1566, time 10.51ms
iter 41800: loss 1.0540, time 10.29ms
iter 41900: loss 1.1075, time 11.44ms
step 42000: train loss 1.0554, val loss 1.0880
iter 42000: loss 1.1714, time 2610.25ms
iter 42100: loss 0.9981, time 10.01ms
iter 42200: loss 1.0539, time 10.41ms
iter 42300: loss 1.1024, time 9.63ms
iter 42400: loss 1.2043, time 10.39ms
iter 42500: loss 1.1683, time 9.99ms
iter 42600: loss 1.0908, time 9.98ms
iter 42700: loss 1.1156, time 10.35ms
iter 42800: loss 1.1076, time 9.66ms
iter 42900: loss 1.0325, time 11.03ms
step 43000: train loss 1.0493, val loss 1.0757
iter 43000: loss 1.0963, time 2668.60ms
iter 43100: loss 1.1007, time 10.69ms
iter 43200: loss 1.1594, time 13.80ms
iter 43300: loss 1.1106, time 12.53ms
iter 43400: loss 1.0759, time 10.11ms
iter 43500: loss 1.1616, time 11.32ms
iter 43600: loss 1.1419, time 10.21ms
iter 43700: loss 1.1293, time 13.67ms
iter 43800: loss 1.1123, time 10.11ms
iter 43900: loss 1.0934, time 9.83ms
step 44000: train loss 1.0455, val loss 1.0754
iter 44000: loss 1.0857, time 2708.95ms
iter 44100: loss 1.1010, time 10.30ms
iter 44200: loss 1.1661, time 11.44ms
iter 44300: loss 1.1773, time 10.56ms
iter 44400: loss 1.1648, time 9.60ms
iter 44500: loss 1.1075, time 9.80ms
iter 44600: loss 1.1458, time 13.47ms
iter 44700: loss 1.1267, time 10.39ms
iter 44800: loss 1.1912, time 10.13ms
iter 44900: loss 1.1427, time 10.18ms
step 45000: train loss 1.0550, val loss 1.0755
iter 45000: loss 1.0505, time 2694.80ms
iter 45100: loss 1.0815, time 16.99ms
iter 45200: loss 1.1414, time 11.89ms
iter 45300: loss 1.1250, time 10.65ms
iter 45400: loss 1.1026, time 10.01ms
iter 45500: loss 1.1428, time 12.50ms
iter 45600: loss 1.2320, time 10.42ms
iter 45700: loss 1.1257, time 9.64ms
iter 45800: loss 1.0128, time 9.94ms
iter 45900: loss 1.0836, time 10.53ms
step 46000: train loss 1.0417, val loss 1.0747
iter 46000: loss 1.0456, time 2888.88ms
iter 46100: loss 1.1119, time 10.82ms
iter 46200: loss 1.0835, time 13.00ms
iter 46300: loss 0.9890, time 9.76ms
iter 46400: loss 1.1651, time 10.08ms
iter 46500: loss 1.0417, time 9.89ms
iter 46600: loss 1.0935, time 9.71ms
iter 46700: loss 1.1896, time 10.03ms
iter 46800: loss 1.0196, time 12.06ms
iter 46900: loss 1.1153, time 9.81ms
step 47000: train loss 1.0412, val loss 1.0718
iter 47000: loss 1.0599, time 2693.76ms
iter 47100: loss 1.1547, time 11.98ms
iter 47200: loss 1.1187, time 10.03ms
iter 47300: loss 1.1048, time 10.44ms
iter 47400: loss 1.1126, time 10.10ms
iter 47500: loss 1.1318, time 11.49ms
iter 47600: loss 1.0485, time 10.56ms
iter 47700: loss 1.1696, time 10.08ms
iter 47800: loss 1.0202, time 9.80ms
iter 47900: loss 1.1478, time 9.62ms
step 48000: train loss 1.0385, val loss 1.0715
iter 48000: loss 1.1300, time 2653.02ms
iter 48100: loss 1.1355, time 10.42ms
iter 48200: loss 1.0703, time 10.23ms
iter 48300: loss 1.1033, time 11.79ms
iter 48400: loss 1.0393, time 9.99ms
iter 48500: loss 1.0481, time 10.15ms
iter 48600: loss 1.1091, time 10.14ms
iter 48700: loss 1.0981, time 10.25ms
iter 48800: loss 1.1766, time 12.34ms
iter 48900: loss 1.1452, time 9.96ms
step 49000: train loss 1.0347, val loss 1.0572
iter 49000: loss 1.0935, time 2612.33ms
iter 49100: loss 1.0156, time 10.06ms
iter 49200: loss 1.1502, time 9.96ms
iter 49300: loss 1.0651, time 10.22ms
iter 49400: loss 1.0022, time 10.84ms
iter 49500: loss 1.0548, time 9.65ms
iter 49600: loss 1.0661, time 10.51ms
iter 49700: loss 1.1188, time 10.18ms
iter 49800: loss 1.0506, time 10.54ms
iter 49900: loss 1.0974, time 9.78ms
step 50000: train loss 1.0347, val loss 1.0633
iter 50000: loss 1.0578, time 2607.12ms
iter 50100: loss 1.1271, time 10.00ms
iter 50200: loss 1.1319, time 9.89ms
iter 50300: loss 1.0791, time 10.55ms
iter 50400: loss 1.1490, time 10.11ms
iter 50500: loss 1.1177, time 9.71ms
iter 50600: loss 1.0693, time 9.79ms
iter 50700: loss 1.1028, time 9.78ms
iter 50800: loss 1.1256, time 13.48ms
iter 50900: loss 1.0531, time 12.77ms
step 51000: train loss 1.0371, val loss 1.0608
iter 51000: loss 1.0566, time 2648.35ms
iter 51100: loss 1.0941, time 10.40ms
iter 51200: loss 1.0858, time 9.92ms
iter 51300: loss 1.0901, time 9.78ms
iter 51400: loss 1.0954, time 10.62ms
iter 51500: loss 1.0577, time 11.30ms
iter 51600: loss 1.1469, time 9.91ms
iter 51700: loss 1.0640, time 10.92ms
iter 51800: loss 1.0652, time 12.64ms
iter 51900: loss 1.0964, time 11.11ms
step 52000: train loss 1.0365, val loss 1.0633
iter 52000: loss 1.1261, time 2649.48ms
iter 52100: loss 1.1766, time 11.39ms
iter 52200: loss 1.0894, time 11.25ms
iter 52300: loss 1.0479, time 9.83ms
iter 52400: loss 1.0786, time 10.76ms
iter 52500: loss 1.0141, time 11.07ms
iter 52600: loss 1.0550, time 9.96ms
iter 52700: loss 1.1169, time 10.05ms
iter 52800: loss 1.2087, time 10.34ms
iter 52900: loss 1.0884, time 9.69ms
step 53000: train loss 1.0324, val loss 1.0599
iter 53000: loss 1.1373, time 2669.47ms
iter 53100: loss 1.0841, time 10.93ms
iter 53200: loss 1.0223, time 10.02ms
iter 53300: loss 1.0510, time 15.31ms
iter 53400: loss 1.0827, time 10.13ms
iter 53500: loss 1.0295, time 9.63ms
iter 53600: loss 1.0581, time 9.96ms
iter 53700: loss 1.0996, time 10.14ms
iter 53800: loss 1.1683, time 11.26ms
iter 53900: loss 1.0714, time 10.05ms
step 54000: train loss 1.0279, val loss 1.0590
iter 54000: loss 1.0357, time 2598.40ms
iter 54100: loss 1.0482, time 10.40ms
iter 54200: loss 1.0401, time 10.21ms
iter 54300: loss 1.0612, time 10.42ms
iter 54400: loss 1.1080, time 11.64ms
iter 54500: loss 1.0543, time 10.53ms
iter 54600: loss 1.0916, time 10.39ms
iter 54700: loss 1.0014, time 10.10ms
iter 54800: loss 1.1267, time 10.55ms
iter 54900: loss 1.1423, time 9.61ms
step 55000: train loss 1.0300, val loss 1.0595
iter 55000: loss 0.9947, time 2697.65ms
iter 55100: loss 1.1216, time 10.12ms
iter 55200: loss 1.0603, time 10.18ms
iter 55300: loss 1.0576, time 9.61ms
iter 55400: loss 0.9643, time 10.36ms
iter 55500: loss 1.0776, time 10.07ms
iter 55600: loss 1.0265, time 10.30ms
iter 55700: loss 1.0722, time 9.47ms
iter 55800: loss 1.0477, time 10.00ms
iter 55900: loss 1.1455, time 10.28ms
step 56000: train loss 1.0251, val loss 1.0542
iter 56000: loss 1.0603, time 2784.93ms
iter 56100: loss 1.1334, time 11.28ms
iter 56200: loss 1.0833, time 11.48ms
iter 56300: loss 1.0850, time 10.03ms
iter 56400: loss 1.0412, time 10.16ms
iter 56500: loss 0.9957, time 9.84ms
iter 56600: loss 1.0829, time 10.11ms
iter 56700: loss 1.0546, time 11.10ms
iter 56800: loss 1.0727, time 11.49ms
iter 56900: loss 1.1027, time 9.67ms
step 57000: train loss 1.0248, val loss 1.0547
iter 57000: loss 1.1541, time 2686.61ms
iter 57100: loss 1.0301, time 35.91ms
iter 57200: loss 1.0653, time 11.29ms
iter 57300: loss 1.0548, time 11.21ms
iter 57400: loss 1.1376, time 10.24ms
iter 57500: loss 1.0616, time 11.92ms
iter 57600: loss 1.1080, time 9.52ms
iter 57700: loss 1.0525, time 10.02ms
iter 57800: loss 1.0546, time 15.12ms
iter 57900: loss 1.0289, time 9.81ms
step 58000: train loss 1.0235, val loss 1.0534
iter 58000: loss 1.0770, time 2517.18ms
iter 58100: loss 1.0371, time 9.98ms
iter 58200: loss 1.0162, time 9.63ms
iter 58300: loss 1.0734, time 10.58ms
iter 58400: loss 1.0388, time 10.39ms
iter 58500: loss 1.0567, time 10.14ms
iter 58600: loss 1.1010, time 11.08ms
iter 58700: loss 1.0476, time 10.52ms
iter 58800: loss 1.0933, time 9.94ms
iter 58900: loss 1.0507, time 11.59ms
step 59000: train loss 1.0150, val loss 1.0506
iter 59000: loss 1.0653, time 2583.24ms
iter 59100: loss 1.0636, time 10.30ms
iter 59200: loss 1.0701, time 10.56ms
iter 59300: loss 1.1136, time 9.95ms
iter 59400: loss 1.1114, time 9.64ms
iter 59500: loss 1.1212, time 17.60ms
iter 59600: loss 1.0779, time 10.14ms
iter 59700: loss 1.1237, time 22.36ms
iter 59800: loss 1.1048, time 10.83ms
iter 59900: loss 1.0956, time 9.53ms
step 60000: train loss 1.0153, val loss 1.0476
iter 60000: loss 0.9878, time 2652.75ms
iter 60100: loss 1.0395, time 10.19ms
iter 60200: loss 1.0484, time 10.90ms
iter 60300: loss 1.0887, time 10.11ms
iter 60400: loss 1.0751, time 10.78ms
iter 60500: loss 1.0565, time 9.83ms
iter 60600: loss 1.1010, time 10.04ms
iter 60700: loss 1.1314, time 10.09ms
iter 60800: loss 1.1278, time 10.55ms
iter 60900: loss 1.0546, time 12.02ms
step 61000: train loss 1.0213, val loss 1.0513
iter 61000: loss 1.1060, time 2479.12ms
iter 61100: loss 1.0508, time 10.09ms
iter 61200: loss 1.0278, time 10.68ms
iter 61300: loss 1.0484, time 10.47ms
iter 61400: loss 1.1186, time 10.78ms
iter 61500: loss 1.0369, time 9.72ms
iter 61600: loss 1.0741, time 9.89ms
iter 61700: loss 1.0142, time 10.90ms
iter 61800: loss 1.0214, time 9.77ms
iter 61900: loss 1.0761, time 9.74ms
step 62000: train loss 1.0140, val loss 1.0455
iter 62000: loss 1.0281, time 2519.14ms
iter 62100: loss 1.0630, time 10.12ms
iter 62200: loss 0.9917, time 9.97ms
iter 62300: loss 0.9828, time 10.21ms
iter 62400: loss 1.1054, time 10.12ms
iter 62500: loss 1.1592, time 9.90ms
iter 62600: loss 1.1728, time 9.90ms
iter 62700: loss 1.0598, time 10.09ms
iter 62800: loss 1.0699, time 10.43ms
iter 62900: loss 1.0882, time 9.86ms
step 63000: train loss 1.0125, val loss 1.0434
iter 63000: loss 1.1061, time 2557.71ms
iter 63100: loss 1.0933, time 23.22ms
iter 63200: loss 1.1311, time 11.51ms
iter 63300: loss 1.0815, time 10.42ms
iter 63400: loss 1.0565, time 9.74ms
iter 63500: loss 1.0060, time 9.87ms
iter 63600: loss 1.1700, time 9.92ms
iter 63700: loss 1.0504, time 9.68ms
iter 63800: loss 1.1094, time 10.39ms
iter 63900: loss 1.1130, time 10.13ms
step 64000: train loss 1.0147, val loss 1.0463
iter 64000: loss 0.9861, time 2570.79ms
iter 64100: loss 1.0074, time 10.11ms
iter 64200: loss 1.0099, time 9.88ms
iter 64300: loss 1.0487, time 9.60ms
iter 64400: loss 1.0177, time 10.91ms
iter 64500: loss 1.0333, time 11.07ms
iter 64600: loss 1.1012, time 9.85ms
iter 64700: loss 1.1038, time 10.53ms
iter 64800: loss 1.0746, time 9.59ms
iter 64900: loss 1.1150, time 9.67ms
step 65000: train loss 1.0094, val loss 1.0375
iter 65000: loss 1.1231, time 2494.65ms
iter 65100: loss 1.0731, time 10.51ms
iter 65200: loss 1.0394, time 9.90ms
iter 65300: loss 1.1127, time 10.08ms
iter 65400: loss 1.0529, time 9.88ms
iter 65500: loss 1.1622, time 9.58ms
iter 65600: loss 0.9953, time 9.52ms
iter 65700: loss 1.0145, time 9.98ms
iter 65800: loss 1.0807, time 9.72ms
iter 65900: loss 1.1075, time 10.31ms
step 66000: train loss 1.0055, val loss 1.0405
iter 66000: loss 1.0710, time 2494.54ms
iter 66100: loss 1.0627, time 9.67ms
iter 66200: loss 1.0839, time 10.60ms
iter 66300: loss 1.0367, time 10.20ms
iter 66400: loss 1.1038, time 10.10ms
iter 66500: loss 1.0578, time 9.58ms
iter 66600: loss 1.0430, time 10.09ms
iter 66700: loss 1.0500, time 9.81ms
iter 66800: loss 1.1046, time 10.34ms
iter 66900: loss 1.1058, time 9.64ms
step 67000: train loss 1.0058, val loss 1.0364
iter 67000: loss 1.0884, time 2660.79ms
iter 67100: loss 1.0320, time 10.15ms
iter 67200: loss 1.0095, time 10.06ms
iter 67300: loss 1.0973, time 11.19ms
iter 67400: loss 1.0441, time 10.26ms
iter 67500: loss 1.0294, time 9.62ms
iter 67600: loss 1.0691, time 10.00ms
iter 67700: loss 1.0451, time 10.11ms
iter 67800: loss 1.0430, time 9.87ms
iter 67900: loss 1.0746, time 9.66ms
step 68000: train loss 1.0117, val loss 1.0413
iter 68000: loss 1.0640, time 2492.32ms
iter 68100: loss 1.0396, time 9.76ms
iter 68200: loss 1.1074, time 9.86ms
iter 68300: loss 1.0914, time 10.61ms
iter 68400: loss 1.0761, time 9.87ms
iter 68500: loss 1.0760, time 13.16ms
iter 68600: loss 1.0707, time 9.64ms
iter 68700: loss 1.0787, time 10.28ms
iter 68800: loss 1.0970, time 10.18ms
iter 68900: loss 1.0489, time 11.25ms
step 69000: train loss 1.0002, val loss 1.0339
iter 69000: loss 1.0721, time 2554.61ms
iter 69100: loss 1.0189, time 10.05ms
iter 69200: loss 1.0544, time 9.94ms
iter 69300: loss 1.0999, time 10.40ms
iter 69400: loss 1.0428, time 9.83ms
iter 69500: loss 1.0326, time 10.06ms
iter 69600: loss 1.0465, time 10.01ms
iter 69700: loss 1.0161, time 9.82ms
iter 69800: loss 0.9682, time 9.82ms
iter 69900: loss 0.9956, time 9.72ms
step 70000: train loss 1.0079, val loss 1.0344
iter 70000: loss 1.1119, time 2606.05ms
iter 70100: loss 1.0746, time 11.47ms
iter 70200: loss 0.9922, time 11.94ms
iter 70300: loss 1.0279, time 10.43ms
iter 70400: loss 1.0547, time 10.35ms
iter 70500: loss 1.0687, time 9.53ms
iter 70600: loss 1.0618, time 9.92ms
iter 70700: loss 1.0442, time 10.08ms
iter 70800: loss 1.0415, time 9.65ms
iter 70900: loss 0.9768, time 12.15ms
step 71000: train loss 1.0005, val loss 1.0351
iter 71000: loss 1.0531, time 3880.32ms
iter 71100: loss 0.9756, time 10.62ms
iter 71200: loss 1.0518, time 10.11ms
iter 71300: loss 0.9302, time 10.69ms
iter 71400: loss 1.0946, time 10.38ms
iter 71500: loss 1.0835, time 10.00ms
iter 71600: loss 1.0480, time 11.12ms
iter 71700: loss 1.0586, time 10.78ms
iter 71800: loss 1.0319, time 10.59ms
iter 71900: loss 0.9876, time 9.73ms
step 72000: train loss 1.0014, val loss 1.0266
iter 72000: loss 1.0707, time 2793.95ms
iter 72100: loss 1.0296, time 12.60ms
iter 72200: loss 1.0950, time 10.10ms
iter 72300: loss 1.0782, time 11.90ms
iter 72400: loss 1.0993, time 10.19ms
iter 72500: loss 1.0080, time 10.02ms
iter 72600: loss 1.0178, time 11.62ms
iter 72700: loss 1.0333, time 10.32ms
iter 72800: loss 1.0563, time 10.11ms
iter 72900: loss 1.1053, time 10.05ms
step 73000: train loss 0.9976, val loss 1.0316
iter 73000: loss 0.9927, time 2894.55ms
iter 73100: loss 1.0367, time 9.92ms
iter 73200: loss 1.0042, time 9.85ms
iter 73300: loss 0.9936, time 11.40ms
iter 73400: loss 1.0351, time 9.98ms
iter 73500: loss 1.0369, time 9.92ms
iter 73600: loss 0.9700, time 10.19ms
iter 73700: loss 1.0525, time 11.02ms
iter 73800: loss 1.0653, time 10.10ms
iter 73900: loss 1.0303, time 10.43ms
step 74000: train loss 0.9947, val loss 1.0268
iter 74000: loss 1.0512, time 2651.83ms
iter 74100: loss 1.1195, time 9.80ms
iter 74200: loss 1.0100, time 11.09ms
iter 74300: loss 0.9902, time 10.32ms
iter 74400: loss 1.0694, time 10.47ms
iter 74500: loss 1.0379, time 10.35ms
iter 74600: loss 1.1179, time 9.98ms
iter 74700: loss 1.0741, time 9.61ms
iter 74800: loss 1.0882, time 9.87ms
iter 74900: loss 1.0951, time 9.73ms
step 75000: train loss 0.9919, val loss 1.0249
iter 75000: loss 1.0411, time 2591.95ms
iter 75100: loss 1.0675, time 9.74ms
iter 75200: loss 1.0416, time 9.77ms
iter 75300: loss 1.0489, time 10.56ms
iter 75400: loss 1.0638, time 10.20ms
iter 75500: loss 1.0632, time 13.77ms
iter 75600: loss 1.0923, time 13.66ms
iter 75700: loss 1.0698, time 9.92ms
iter 75800: loss 0.9759, time 11.41ms
iter 75900: loss 1.0677, time 10.72ms
step 76000: train loss 0.9940, val loss 1.0250
iter 76000: loss 0.9689, time 2616.24ms
iter 76100: loss 0.9841, time 9.67ms
iter 76200: loss 1.0221, time 9.88ms
iter 76300: loss 0.9784, time 9.85ms
iter 76400: loss 1.0907, time 10.14ms
iter 76500: loss 1.0457, time 10.20ms
iter 76600: loss 1.1082, time 9.60ms
iter 76700: loss 1.0105, time 9.82ms
iter 76800: loss 1.1214, time 10.03ms
iter 76900: loss 1.0499, time 9.77ms
step 77000: train loss 0.9930, val loss 1.0212
iter 77000: loss 1.0444, time 2618.72ms
iter 77100: loss 1.0469, time 9.99ms
iter 77200: loss 1.0534, time 10.52ms
iter 77300: loss 1.0770, time 9.97ms
iter 77400: loss 1.0732, time 9.87ms
iter 77500: loss 0.9584, time 11.47ms
iter 77600: loss 1.1094, time 9.63ms
iter 77700: loss 1.0812, time 10.38ms
iter 77800: loss 1.0247, time 10.06ms
iter 77900: loss 1.0735, time 9.79ms
step 78000: train loss 0.9856, val loss 1.0195
iter 78000: loss 1.0326, time 2637.62ms
iter 78100: loss 1.0697, time 10.41ms
iter 78200: loss 1.1281, time 10.38ms
iter 78300: loss 1.0085, time 10.12ms
iter 78400: loss 1.0352, time 11.03ms
iter 78500: loss 1.1016, time 9.67ms
iter 78600: loss 1.0330, time 11.04ms
iter 78700: loss 1.0518, time 10.99ms
iter 78800: loss 1.0737, time 9.85ms
iter 78900: loss 1.0548, time 9.99ms
step 79000: train loss 0.9920, val loss 1.0263
iter 79000: loss 1.1177, time 2493.02ms
iter 79100: loss 1.0420, time 9.68ms
iter 79200: loss 1.0433, time 11.37ms
iter 79300: loss 1.0433, time 10.65ms
iter 79400: loss 1.0632, time 10.02ms
iter 79500: loss 0.9970, time 15.93ms
iter 79600: loss 0.9841, time 14.52ms
iter 79700: loss 1.0964, time 15.97ms
iter 79800: loss 1.0592, time 11.04ms
iter 79900: loss 1.1183, time 10.76ms
step 80000: train loss 0.9825, val loss 1.0217
iter 80000: loss 1.0756, time 2616.46ms
iter 80100: loss 1.0343, time 10.15ms
iter 80200: loss 1.0600, time 10.07ms
iter 80300: loss 1.1130, time 9.97ms
iter 80400: loss 1.0607, time 10.03ms
iter 80500: loss 1.0171, time 10.17ms
iter 80600: loss 1.1393, time 11.64ms
iter 80700: loss 1.0336, time 9.78ms
iter 80800: loss 1.0503, time 11.32ms
iter 80900: loss 0.9956, time 16.58ms
step 81000: train loss 0.9808, val loss 1.0215
iter 81000: loss 1.0066, time 2666.61ms
iter 81100: loss 1.0510, time 9.87ms
iter 81200: loss 1.0077, time 10.14ms
iter 81300: loss 1.0533, time 10.16ms
iter 81400: loss 0.9005, time 10.89ms
iter 81500: loss 1.0922, time 10.41ms
iter 81600: loss 1.0154, time 10.51ms
iter 81700: loss 0.9619, time 10.37ms
iter 81800: loss 1.0726, time 9.92ms
iter 81900: loss 1.0121, time 10.02ms
step 82000: train loss 0.9810, val loss 1.0239
iter 82000: loss 1.1121, time 2679.89ms
iter 82100: loss 1.0767, time 12.67ms
iter 82200: loss 0.9981, time 13.26ms
iter 82300: loss 1.1056, time 9.81ms
iter 82400: loss 1.0054, time 9.77ms
iter 82500: loss 1.0254, time 9.96ms
iter 82600: loss 1.0191, time 10.02ms
iter 82700: loss 1.0892, time 10.05ms
iter 82800: loss 1.0289, time 10.33ms
iter 82900: loss 0.9835, time 11.36ms
step 83000: train loss 0.9814, val loss 1.0179
iter 83000: loss 1.0457, time 2607.03ms
iter 83100: loss 1.0467, time 10.25ms
iter 83200: loss 1.0881, time 9.69ms
iter 83300: loss 1.1168, time 11.83ms
iter 83400: loss 1.0088, time 10.51ms
iter 83500: loss 1.0817, time 9.92ms
iter 83600: loss 1.0632, time 16.42ms
iter 83700: loss 1.0980, time 9.81ms
iter 83800: loss 1.0462, time 10.06ms
iter 83900: loss 1.0478, time 12.65ms
step 84000: train loss 0.9758, val loss 1.0253
iter 84000: loss 1.0523, time 2615.64ms
iter 84100: loss 1.0349, time 17.36ms
iter 84200: loss 1.0832, time 9.94ms
iter 84300: loss 1.0824, time 10.25ms
iter 84400: loss 0.9829, time 10.36ms
iter 84500: loss 1.0596, time 9.85ms
iter 84600: loss 1.1024, time 9.76ms
iter 84700: loss 1.0355, time 16.49ms
iter 84800: loss 1.0138, time 10.03ms
iter 84900: loss 0.9818, time 10.29ms
step 85000: train loss 0.9814, val loss 1.0140
iter 85000: loss 1.0306, time 2636.08ms
iter 85100: loss 1.0793, time 9.90ms
iter 85200: loss 0.9438, time 11.57ms
iter 85300: loss 0.9109, time 9.89ms
iter 85400: loss 0.9891, time 10.04ms
iter 85500: loss 1.1539, time 9.89ms
iter 85600: loss 0.9768, time 9.95ms
iter 85700: loss 0.9719, time 10.67ms
iter 85800: loss 0.9659, time 10.74ms
iter 85900: loss 1.0350, time 10.21ms
step 86000: train loss 0.9811, val loss 1.0127
iter 86000: loss 0.9913, time 2616.25ms
iter 86100: loss 1.0055, time 10.20ms
iter 86200: loss 1.0113, time 10.51ms
iter 86300: loss 1.0215, time 9.75ms
iter 86400: loss 1.0403, time 10.37ms
iter 86500: loss 1.0639, time 10.62ms
iter 86600: loss 1.0303, time 9.98ms
iter 86700: loss 1.0881, time 9.70ms
iter 86800: loss 1.0299, time 9.95ms
iter 86900: loss 1.0151, time 9.85ms
step 87000: train loss 0.9748, val loss 1.0109
iter 87000: loss 0.9908, time 2482.30ms
iter 87100: loss 0.9456, time 10.92ms
iter 87200: loss 1.0084, time 10.20ms
iter 87300: loss 0.9902, time 10.17ms
iter 87400: loss 0.8887, time 10.57ms
iter 87500: loss 1.0471, time 9.81ms
iter 87600: loss 1.0595, time 10.35ms
iter 87700: loss 0.9829, time 9.94ms
iter 87800: loss 1.0262, time 10.86ms
iter 87900: loss 0.9811, time 10.25ms
step 88000: train loss 0.9717, val loss 1.0075
iter 88000: loss 1.0486, time 2533.54ms
iter 88100: loss 1.0114, time 10.53ms
iter 88200: loss 1.0573, time 9.96ms
iter 88300: loss 0.9883, time 9.67ms
iter 88400: loss 1.0277, time 9.65ms
iter 88500: loss 1.0344, time 10.04ms
iter 88600: loss 1.0459, time 10.60ms
iter 88700: loss 1.1199, time 9.96ms
iter 88800: loss 0.9818, time 9.88ms
iter 88900: loss 1.0231, time 10.59ms
step 89000: train loss 0.9700, val loss 1.0113
iter 89000: loss 0.9995, time 2590.73ms
iter 89100: loss 1.0501, time 10.72ms
iter 89200: loss 0.9781, time 10.06ms
iter 89300: loss 1.0452, time 10.54ms
iter 89400: loss 1.0217, time 10.41ms
iter 89500: loss 1.0541, time 9.76ms
iter 89600: loss 0.9778, time 11.68ms
iter 89700: loss 0.9933, time 10.42ms
iter 89800: loss 1.0688, time 9.92ms
iter 89900: loss 0.9281, time 10.30ms
step 90000: train loss 0.9777, val loss 1.0141
iter 90000: loss 0.9895, time 2544.16ms
iter 90100: loss 0.9960, time 10.25ms
iter 90200: loss 1.0703, time 9.70ms
iter 90300: loss 0.9738, time 9.72ms
iter 90400: loss 1.0165, time 14.11ms
iter 90500: loss 1.0683, time 10.04ms
iter 90600: loss 0.9930, time 10.26ms
iter 90700: loss 1.0544, time 10.25ms
iter 90800: loss 1.0491, time 10.12ms
iter 90900: loss 1.0580, time 10.15ms
step 91000: train loss 0.9701, val loss 1.0129
iter 91000: loss 0.9762, time 2702.16ms
iter 91100: loss 1.0523, time 10.49ms
iter 91200: loss 1.0628, time 9.54ms
iter 91300: loss 1.0295, time 9.80ms
iter 91400: loss 1.0948, time 10.97ms
iter 91500: loss 1.0105, time 10.06ms
iter 91600: loss 1.0221, time 13.21ms
iter 91700: loss 1.0125, time 21.19ms
iter 91800: loss 1.1108, time 10.20ms
iter 91900: loss 1.0069, time 10.12ms
step 92000: train loss 0.9688, val loss 1.0095
iter 92000: loss 0.9981, time 2607.60ms
iter 92100: loss 1.0506, time 10.30ms
iter 92200: loss 1.1513, time 10.27ms
iter 92300: loss 1.1073, time 10.01ms
iter 92400: loss 1.0832, time 9.89ms
iter 92500: loss 1.0165, time 12.90ms
iter 92600: loss 1.0971, time 10.14ms
iter 92700: loss 1.1091, time 10.24ms
iter 92800: loss 1.0793, time 9.80ms
iter 92900: loss 1.0526, time 11.09ms
step 93000: train loss 0.9719, val loss 1.0118
iter 93000: loss 1.0089, time 2600.74ms
iter 93100: loss 1.0423, time 11.57ms
iter 93200: loss 1.0119, time 10.57ms
iter 93300: loss 1.0905, time 16.31ms
iter 93400: loss 1.0266, time 11.32ms
iter 93500: loss 1.0515, time 12.93ms
iter 93600: loss 0.9962, time 9.74ms
iter 93700: loss 1.1337, time 10.50ms
iter 93800: loss 1.0681, time 9.88ms
iter 93900: loss 1.0783, time 9.90ms
step 94000: train loss 0.9664, val loss 1.0055
iter 94000: loss 1.0286, time 2687.42ms
iter 94100: loss 1.0720, time 10.13ms
iter 94200: loss 0.9771, time 10.55ms
iter 94300: loss 1.0319, time 9.81ms
iter 94400: loss 1.0225, time 9.68ms
iter 94500: loss 0.9962, time 13.16ms
iter 94600: loss 0.9286, time 10.61ms
iter 94700: loss 0.9929, time 10.81ms
iter 94800: loss 1.0396, time 10.63ms
iter 94900: loss 0.9585, time 10.07ms
step 95000: train loss 0.9759, val loss 1.0059
iter 95000: loss 1.0742, time 2844.72ms
iter 95100: loss 0.9901, time 10.92ms
iter 95200: loss 0.9956, time 9.68ms
iter 95300: loss 1.0379, time 10.24ms
iter 95400: loss 1.1169, time 10.46ms
iter 95500: loss 0.9980, time 12.38ms
iter 95600: loss 1.0845, time 10.74ms
iter 95700: loss 1.0453, time 10.57ms
iter 95800: loss 1.0612, time 9.75ms
iter 95900: loss 1.0222, time 10.45ms
step 96000: train loss 0.9682, val loss 1.0064
iter 96000: loss 1.0005, time 2624.72ms
iter 96100: loss 1.0153, time 10.51ms
iter 96200: loss 0.9990, time 11.06ms
iter 96300: loss 1.0060, time 9.93ms
iter 96400: loss 1.0990, time 9.93ms
iter 96500: loss 1.0377, time 10.16ms
iter 96600: loss 1.0761, time 9.77ms
iter 96700: loss 1.0349, time 10.14ms
iter 96800: loss 0.9668, time 10.02ms
iter 96900: loss 0.9806, time 9.87ms
step 97000: train loss 0.9659, val loss 1.0059
iter 97000: loss 1.0470, time 2782.77ms
iter 97100: loss 0.9554, time 11.54ms
iter 97200: loss 1.0111, time 10.15ms
iter 97300: loss 1.0192, time 9.92ms
iter 97400: loss 0.9280, time 10.20ms
iter 97500: loss 1.0325, time 10.60ms
iter 97600: loss 1.0076, time 9.92ms
iter 97700: loss 1.0230, time 9.65ms
iter 97800: loss 1.1240, time 10.20ms
iter 97900: loss 0.9647, time 9.95ms
step 98000: train loss 0.9718, val loss 1.0075
iter 98000: loss 1.0760, time 2521.27ms
iter 98100: loss 1.0112, time 9.64ms
iter 98200: loss 0.9933, time 10.36ms
iter 98300: loss 0.9659, time 11.74ms
iter 98400: loss 1.0179, time 11.20ms
iter 98500: loss 1.0111, time 11.23ms
iter 98600: loss 1.0238, time 9.52ms
iter 98700: loss 0.9951, time 9.77ms
iter 98800: loss 1.0394, time 9.87ms
iter 98900: loss 0.9260, time 9.64ms
step 99000: train loss 0.9658, val loss 1.0007
iter 99000: loss 1.0723, time 2639.86ms
iter 99100: loss 1.0368, time 10.33ms
iter 99200: loss 1.0007, time 10.09ms
iter 99300: loss 0.9991, time 9.85ms
iter 99400: loss 1.1069, time 9.94ms
iter 99500: loss 1.0193, time 9.61ms
iter 99600: loss 0.9742, time 9.86ms
iter 99700: loss 1.0709, time 9.88ms
iter 99800: loss 1.0630, time 9.65ms
iter 99900: loss 1.0650, time 10.26ms
step 100000: train loss 0.9675, val loss 1.0033
iter 100000: loss 1.0000, time 2803.57ms
training done
Best validation loss: 1.0006557703018188
Total train time: 23.31 mins
Loading meta from ../../data/enwik8/meta.pkl...
Sample 1:
 [[DAM operating system]]s were found by provisions of [[home-country system|home to systems]] and [[home-country system]]s such as [[BTU]], [[Amiga Program]], [[API]], [[Apple Corporation]], [[Domestic Corporation]], and [[Dynamic aircraft corporation|DCC]].

== Home companies ==
* [[Central African Airlines]]
* [[Central African Airlines]]
* [[Central African Airlines]]
* [[Centralised Airlines]]

== Environmental infrastructure ==
* [[Central African Airline Corporation]]
* [[Contraception Air
Inference time: 1.88 seconds
Tokens per second: 265.73
---------------
Sample 2:
 southwestern Cape Town and the Central Indian city of [[Taoisia]].

==Northern Cape Towns==
[[Image:Cape Town Coast of the Cape Town.jpg|thumb|[[Atlantic Coast of the Cape Town]]

'''Cape Town''' is the [[Cape Township, Cape Town|Cape Town]] in the [[United States]]. It is a [[United States|USA]] government and is divided into [[London]], and the [[Sun]] in the [[South South South South South South Asia and area]] is commonly used as [[Arabic language|Arabic]]. The [[European Courier for Ancient
Inference time: 1.90 seconds
Tokens per second: 263.68
---------------
Sample 3:
 to old society and cultural religion of the concept of [[philosophy]]. Despite the fact that this disagreement was fulfilled with the [[philosophy|philosophical]] tradition of [[Persephone Northern]], the state being that the concept of debate and changes were about the first purposes of and absolutely applied to the philosophical structure of the [[philosophical study]], and a few years later disabled by a single names of the work, but it is now contested at the age of the [[Saxon University|Sa
Inference time: 1.90 seconds
Tokens per second: 262.66
---------------
Sample 4:
 the [[Basque peoples of Basque Country|Basque Country]] and amassed by the [[Basque Country]] as a colony in the [[Basque Country]], and the [[Basque Country]]. The borders of Basque Country affect the [[California Republic]] and the [[California Republic]]. In Germany, the state is not a profit in the country, but the country is a national or state in the country in which the [[Albania]] country was a separate [[landscape]] southern Italy the [[Ruby area]]. The population is populated nearly al
Inference time: 1.86 seconds
Tokens per second: 268.85
---------------
Sample 5:
 trainers in a line of protection far from the increased comparative of Organizations with other supporters and both the two of the Congo-Lords.

==Attitudes==

Most documents of the congo are often replaced with violations of the theory at the [[Maritime League]].  Note that congo are all driven with a part of the congo document or of political attitudes of education, resulting in a congo career within a man and a sometimes measured university.  After the Scottish congo about large time in Engla
Inference time: 1.89 seconds
Tokens per second: 264.62
---------------
Sample 6:
 to form the most important part of Christians allow whom at him for self-time being an incomponent poison that goes into self-time in which a command is about the last &quot;self-time&quot; in any of the most important philosophical concepts, such as [[John Stanley]] and [[Bob Walton]].

/home/huang717/CS673-AI-Scientist/templates/fold_and_cut_nanoGPT/experiment.py:594: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
On [[January 20]], [[2005]], the company was reorganized by the [[Czech Republic|Czech Republic]] and [[United States|American]] residents.  The Czech Republic of the Czech Republic was established in [[July 27]
Inference time: 1.88 seconds
Tokens per second: 265.73
---------------
Sample 7:
 this problem, and although it was also established. Writing on the sole cultural and philosophical writing was probably dangerous that God came to have &quot;escaped the leader from fear as so dangerous or uncertain. The reason for God's sole and relatively successful results was &quot;given to reason in the table of society, and some God's souls that were based on the leader of God's beginning of natural life and philosophy&quot;. For example, his love did not avoid the plural of the belief tha
Inference time: 1.89 seconds
Tokens per second: 264.89
---------------
Sample 8:
 they received an insulting technology in the corporate communities of the [[Herbert Schaffer Trust]] under the [[Jewish Magic Society]] and the [[human empire]] in politics and its more traded role-place political wars.  Herbert Schaffer is in extensive strategic and early proposals of the [[20th century]] and is made in part by the beginnings of the [[19th century]] and [[19th century]] to provide a creation system for the access of the profits in the world. He has been a policy that asserts th
Inference time: 1.96 seconds
Tokens per second: 254.83
---------------
Sample 9:
 all literary descendants of Jesus Christ of Latter-day Saints. This evolution of Antiquity is commonly accepted by the Jesus Christ of Latter-day Saints (in September 1204). This concept of several such theologian enjoys the interpretation of what certain churches distinguish themselves from the evolution of man who can fulfil by the happiness of the Osterichies of [[John the Balkans]] (who call them or the Balkans &amp;mdash; concept of [[feudalism]], [[state]]) or in their own contemporary sys
Inference time: 1.88 seconds
Tokens per second: 265.60
---------------
Sample 10:
 among the early [[1860s]] and [[1900s]].

In [[1902]] his success was suplanted to [[Frynnov]] and the [[Samoa]] army in [[Britons]] once became a [[Great Speaker]] during the [[1910s]], in which he was released in [[1900s]] in a [[Great Speaker|Speaker]] which she said he also that &quot;the englishment of [[Moorman]] exiles in [[South Korea]] was able to find our respiratory during his [[1930s]] and [[1930s]].&quot; [http://www.epinephroad.com/articles/0,641798,00.htm]  Roosevelt has come to l
Inference time: 1.87 seconds
Tokens per second: 267.90
---------------
Average tokens per second: 264.45
tokens per iteration will be: 8,192
found vocab_size = 27 (inside ../../data/text8/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.64M
num decayed parameter tensors: 26, with 10,725,504 parameters
num non-decayed parameter tensors: 31, with 14,220 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 3.4943, val loss 3.4903
iter 0: loss 3.4681, time 38686.17ms
iter 100: loss 2.4050, time 12.33ms
iter 200: loss 2.3634, time 8.96ms
iter 300: loss 2.3311, time 9.54ms
iter 400: loss 2.2078, time 10.66ms
iter 500: loss 1.9879, time 10.08ms
iter 600: loss 1.9178, time 10.05ms
iter 700: loss 1.7772, time 15.91ms
iter 800: loss 1.7711, time 10.12ms
iter 900: loss 1.7301, time 10.00ms
step 1000: train loss 1.6088, val loss 1.5867
iter 1000: loss 1.6916, time 2739.27ms
iter 1100: loss 1.6187, time 12.02ms
iter 1200: loss 1.5395, time 10.30ms
iter 1300: loss 1.5142, time 9.76ms
iter 1400: loss 1.5164, time 11.29ms
iter 1500: loss 1.5012, time 10.05ms
iter 1600: loss 1.5364, time 9.87ms
iter 1700: loss 1.4660, time 11.54ms
iter 1800: loss 1.4449, time 17.70ms
iter 1900: loss 1.4119, time 9.75ms
step 2000: train loss 1.3571, val loss 1.3438
iter 2000: loss 1.3960, time 2711.39ms
iter 2100: loss 1.3867, time 9.91ms
iter 2200: loss 1.3644, time 9.64ms
iter 2300: loss 1.3589, time 10.15ms
iter 2400: loss 1.3347, time 13.05ms
iter 2500: loss 1.3439, time 9.92ms
iter 2600: loss 1.3299, time 10.12ms
iter 2700: loss 1.3948, time 9.99ms
iter 2800: loss 1.3178, time 12.84ms
iter 2900: loss 1.3506, time 11.27ms
step 3000: train loss 1.2770, val loss 1.2613
iter 3000: loss 1.4191, time 2691.57ms
iter 3100: loss 1.3133, time 10.20ms
iter 3200: loss 1.2937, time 10.48ms
iter 3300: loss 1.3345, time 10.31ms
iter 3400: loss 1.2984, time 10.72ms
iter 3500: loss 1.2868, time 9.55ms
iter 3600: loss 1.2600, time 10.15ms
iter 3700: loss 1.2898, time 10.29ms
iter 3800: loss 1.3133, time 9.85ms
iter 3900: loss 1.2820, time 12.65ms
step 4000: train loss 1.2370, val loss 1.2241
iter 4000: loss 1.3254, time 2717.31ms
iter 4100: loss 1.2746, time 10.08ms
iter 4200: loss 1.3030, time 9.80ms
iter 4300: loss 1.1977, time 10.75ms
iter 4400: loss 1.2910, time 9.80ms
iter 4500: loss 1.2911, time 10.15ms
iter 4600: loss 1.2523, time 10.76ms
iter 4700: loss 1.3182, time 9.66ms
iter 4800: loss 1.2641, time 9.73ms
iter 4900: loss 1.2938, time 14.65ms
step 5000: train loss 1.2180, val loss 1.2025
iter 5000: loss 1.2990, time 2599.86ms
iter 5100: loss 1.2913, time 9.86ms
iter 5200: loss 1.2185, time 10.25ms
iter 5300: loss 1.2274, time 9.58ms
iter 5400: loss 1.2553, time 9.88ms
iter 5500: loss 1.2617, time 16.20ms
iter 5600: loss 1.2788, time 9.59ms
iter 5700: loss 1.2343, time 9.75ms
iter 5800: loss 1.2239, time 9.82ms
iter 5900: loss 1.2671, time 9.92ms
step 6000: train loss 1.1980, val loss 1.1768
iter 6000: loss 1.2487, time 2729.66ms
iter 6100: loss 1.2304, time 10.07ms
iter 6200: loss 1.2341, time 9.72ms
iter 6300: loss 1.2448, time 9.87ms
iter 6400: loss 1.3107, time 9.95ms
iter 6500: loss 1.2373, time 11.83ms
iter 6600: loss 1.2253, time 10.74ms
iter 6700: loss 1.2507, time 10.27ms
iter 6800: loss 1.2622, time 9.87ms
iter 6900: loss 1.2824, time 11.05ms
step 7000: train loss 1.1847, val loss 1.1702
iter 7000: loss 1.2358, time 2768.96ms
iter 7100: loss 1.2691, time 9.92ms
iter 7200: loss 1.2706, time 9.81ms
iter 7300: loss 1.2049, time 10.76ms
iter 7400: loss 1.1528, time 11.21ms
iter 7500: loss 1.2058, time 9.61ms
iter 7600: loss 1.2199, time 10.24ms
iter 7700: loss 1.2657, time 9.87ms
iter 7800: loss 1.1699, time 10.79ms
iter 7900: loss 1.2549, time 10.11ms
step 8000: train loss 1.1706, val loss 1.1522
iter 8000: loss 1.1914, time 2586.69ms
iter 8100: loss 1.2309, time 9.97ms
iter 8200: loss 1.2387, time 9.90ms
iter 8300: loss 1.2070, time 10.15ms
iter 8400: loss 1.2391, time 10.04ms
iter 8500: loss 1.1822, time 9.92ms
iter 8600: loss 1.2366, time 9.93ms
iter 8700: loss 1.2247, time 9.62ms
iter 8800: loss 1.2052, time 10.20ms
iter 8900: loss 1.1546, time 9.95ms
step 9000: train loss 1.1623, val loss 1.1458
iter 9000: loss 1.2559, time 2660.11ms
iter 9100: loss 1.2056, time 9.39ms
iter 9200: loss 1.2278, time 10.54ms
iter 9300: loss 1.1885, time 10.67ms
iter 9400: loss 1.2254, time 10.17ms
iter 9500: loss 1.2328, time 12.17ms
iter 9600: loss 1.2298, time 9.68ms
iter 9700: loss 1.2345, time 11.17ms
iter 9800: loss 1.1957, time 9.92ms
iter 9900: loss 1.1534, time 9.77ms
step 10000: train loss 1.1520, val loss 1.1434
iter 10000: loss 1.2109, time 2607.06ms
iter 10100: loss 1.2163, time 10.07ms
iter 10200: loss 1.1565, time 9.50ms
iter 10300: loss 1.1676, time 9.71ms
iter 10400: loss 1.2132, time 9.84ms
iter 10500: loss 1.1693, time 11.38ms
iter 10600: loss 1.2567, time 11.08ms
iter 10700: loss 1.1892, time 10.43ms
iter 10800: loss 1.2041, time 9.91ms
iter 10900: loss 1.2269, time 9.91ms
step 11000: train loss 1.1502, val loss 1.1312
iter 11000: loss 1.2070, time 2696.69ms
iter 11100: loss 1.2123, time 12.44ms
iter 11200: loss 1.2183, time 10.73ms
iter 11300: loss 1.1936, time 10.61ms
iter 11400: loss 1.1421, time 15.12ms
iter 11500: loss 1.1746, time 12.71ms
iter 11600: loss 1.2093, time 42.25ms
iter 11700: loss 1.1759, time 9.87ms
iter 11800: loss 1.1392, time 10.66ms
iter 11900: loss 1.1794, time 9.97ms
step 12000: train loss 1.1423, val loss 1.1272
iter 12000: loss 1.1610, time 3769.60ms
iter 12100: loss 1.1851, time 9.99ms
iter 12200: loss 1.1957, time 10.39ms
iter 12300: loss 1.1899, time 10.50ms
iter 12400: loss 1.1996, time 10.23ms
iter 12500: loss 1.1939, time 9.85ms
iter 12600: loss 1.1976, time 12.80ms
iter 12700: loss 1.1877, time 9.85ms
iter 12800: loss 1.1481, time 9.97ms
iter 12900: loss 1.1559, time 9.61ms
step 13000: train loss 1.1349, val loss 1.1185
iter 13000: loss 1.1712, time 2692.38ms
iter 13100: loss 1.1685, time 11.06ms
iter 13200: loss 1.1815, time 9.46ms
iter 13300: loss 1.1543, time 10.59ms
iter 13400: loss 1.1602, time 10.22ms
iter 13500: loss 1.1923, time 12.35ms
iter 13600: loss 1.1774, time 9.77ms
iter 13700: loss 1.1492, time 10.52ms
iter 13800: loss 1.2026, time 10.73ms
iter 13900: loss 1.1467, time 10.08ms
step 14000: train loss 1.1364, val loss 1.1165
iter 14000: loss 1.2504, time 2714.56ms
iter 14100: loss 1.1922, time 9.63ms
iter 14200: loss 1.1777, time 10.24ms
iter 14300: loss 1.1880, time 9.56ms
iter 14400: loss 1.1317, time 10.13ms
iter 14500: loss 1.1931, time 10.10ms
iter 14600: loss 1.1707, time 10.08ms
iter 14700: loss 1.2317, time 11.05ms
iter 14800: loss 1.1607, time 9.75ms
iter 14900: loss 1.1985, time 9.67ms
step 15000: train loss 1.1234, val loss 1.1096
iter 15000: loss 1.1201, time 2630.98ms
iter 15100: loss 1.1560, time 10.77ms
iter 15200: loss 1.2388, time 11.61ms
iter 15300: loss 1.1542, time 10.75ms
iter 15400: loss 1.1758, time 9.99ms
iter 15500: loss 1.1734, time 13.32ms
iter 15600: loss 1.1545, time 10.19ms
iter 15700: loss 1.1461, time 10.10ms
iter 15800: loss 1.1304, time 10.68ms
iter 15900: loss 1.1701, time 10.17ms
step 16000: train loss 1.1218, val loss 1.1091
iter 16000: loss 1.1754, time 2720.14ms
iter 16100: loss 1.1838, time 11.16ms
iter 16200: loss 1.1466, time 10.14ms
iter 16300: loss 1.1167, time 9.69ms
iter 16400: loss 1.1471, time 10.07ms
iter 16500: loss 1.2112, time 10.40ms
iter 16600: loss 1.2262, time 15.70ms
iter 16700: loss 1.1633, time 11.75ms
iter 16800: loss 1.1467, time 10.11ms
iter 16900: loss 1.1840, time 9.61ms
step 17000: train loss 1.1154, val loss 1.1018
iter 17000: loss 1.1651, time 2936.48ms
iter 17100: loss 1.1328, time 9.79ms
iter 17200: loss 1.1496, time 10.55ms
iter 17300: loss 1.1524, time 10.31ms
iter 17400: loss 1.1549, time 9.99ms
iter 17500: loss 1.1620, time 10.01ms
iter 17600: loss 1.1210, time 10.11ms
iter 17700: loss 1.1583, time 15.08ms
iter 17800: loss 1.1549, time 13.08ms
iter 17900: loss 1.1670, time 15.39ms
step 18000: train loss 1.1138, val loss 1.1008
iter 18000: loss 1.1918, time 4266.68ms
iter 18100: loss 1.1482, time 15.39ms
iter 18200: loss 1.1317, time 13.30ms
iter 18300: loss 1.1131, time 17.77ms
iter 18400: loss 1.1927, time 16.76ms
iter 18500: loss 1.1595, time 13.43ms
iter 18600: loss 1.1766, time 13.06ms
iter 18700: loss 1.1778, time 14.82ms
iter 18800: loss 1.1496, time 11.59ms
iter 18900: loss 1.1595, time 15.39ms
step 19000: train loss 1.1131, val loss 1.0951
iter 19000: loss 1.1536, time 3658.78ms
iter 19100: loss 1.1628, time 14.26ms
iter 19200: loss 1.1031, time 11.52ms
iter 19300: loss 1.1702, time 17.23ms
iter 19400: loss 1.1422, time 19.77ms
iter 19500: loss 1.1715, time 18.92ms
iter 19600: loss 1.1423, time 13.90ms
iter 19700: loss 1.2250, time 15.46ms
iter 19800: loss 1.1763, time 13.17ms
iter 19900: loss 1.1942, time 13.71ms
step 20000: train loss 1.1121, val loss 1.0942
iter 20000: loss 1.1673, time 3927.17ms
iter 20100: loss 1.1712, time 13.63ms
iter 20200: loss 1.1355, time 16.92ms
iter 20300: loss 1.1765, time 14.14ms
iter 20400: loss 1.1577, time 9.93ms
iter 20500: loss 1.1265, time 14.81ms
iter 20600: loss 1.1341, time 14.18ms
iter 20700: loss 1.1061, time 17.12ms
iter 20800: loss 1.1633, time 10.43ms
iter 20900: loss 1.1253, time 19.76ms
step 21000: train loss 1.1046, val loss 1.0902
iter 21000: loss 1.1319, time 3763.89ms
iter 21100: loss 1.1278, time 15.45ms
iter 21200: loss 1.0860, time 14.05ms
iter 21300: loss 1.1606, time 14.93ms
iter 21400: loss 1.1137, time 14.53ms
iter 21500: loss 1.1014, time 21.78ms
iter 21600: loss 1.1187, time 12.85ms
iter 21700: loss 1.1687, time 14.56ms
iter 21800: loss 1.1170, time 13.61ms
iter 21900: loss 1.1486, time 17.99ms
step 22000: train loss 1.0960, val loss 1.0836
iter 22000: loss 1.1057, time 3702.77ms
iter 22100: loss 1.1492, time 10.01ms
iter 22200: loss 1.1554, time 17.00ms
iter 22300: loss 1.1571, time 14.05ms
iter 22400: loss 1.1349, time 13.87ms
iter 22500: loss 1.1175, time 41.78ms
iter 22600: loss 1.2064, time 20.87ms
iter 22700: loss 1.1210, time 14.40ms
iter 22800: loss 1.1138, time 14.05ms
iter 22900: loss 1.1274, time 15.14ms
step 23000: train loss 1.0975, val loss 1.0818
iter 23000: loss 1.1318, time 3909.67ms
iter 23100: loss 1.0532, time 12.64ms
iter 23200: loss 1.1400, time 15.33ms
iter 23300: loss 1.1780, time 14.63ms
iter 23400: loss 1.1651, time 55.55ms
iter 23500: loss 1.0986, time 12.76ms
iter 23600: loss 1.1526, time 13.37ms
iter 23700: loss 1.1964, time 12.57ms
iter 23800: loss 1.1043, time 16.57ms
iter 23900: loss 1.1336, time 16.50ms
step 24000: train loss 1.0899, val loss 1.0775
iter 24000: loss 1.1159, time 3683.42ms
iter 24100: loss 1.1452, time 13.16ms
iter 24200: loss 1.1478, time 13.93ms
iter 24300: loss 1.1616, time 13.67ms
iter 24400: loss 1.1090, time 13.60ms
iter 24500: loss 1.1409, time 12.43ms
iter 24600: loss 1.0925, time 17.44ms
iter 24700: loss 1.1290, time 12.91ms
iter 24800: loss 1.0959, time 13.79ms
iter 24900: loss 1.1268, time 12.74ms
step 25000: train loss 1.0890, val loss 1.0788
iter 25000: loss 1.1325, time 3827.44ms
iter 25100: loss 1.1064, time 15.28ms
iter 25200: loss 1.1602, time 14.78ms
iter 25300: loss 1.1075, time 14.33ms
iter 25400: loss 1.1688, time 9.75ms
iter 25500: loss 1.1245, time 13.83ms
iter 25600: loss 1.0707, time 12.46ms
iter 25700: loss 1.1359, time 16.99ms
iter 25800: loss 1.1046, time 15.33ms
iter 25900: loss 1.1280, time 13.88ms
step 26000: train loss 1.0907, val loss 1.0741
iter 26000: loss 1.1167, time 3518.38ms
iter 26100: loss 1.1111, time 19.14ms
iter 26200: loss 1.1079, time 14.12ms
iter 26300: loss 1.1020, time 20.77ms
iter 26400: loss 1.1299, time 12.93ms
iter 26500: loss 1.1234, time 13.21ms
iter 26600: loss 1.1757, time 24.01ms
iter 26700: loss 1.0945, time 13.89ms
iter 26800: loss 1.1702, time 10.96ms
iter 26900: loss 1.1945, time 13.01ms
step 27000: train loss 1.0880, val loss 1.0667
iter 27000: loss 1.0877, time 3680.65ms
iter 27100: loss 1.1050, time 13.23ms
iter 27200: loss 1.1182, time 14.21ms
iter 27300: loss 1.2093, time 13.17ms
iter 27400: loss 1.1380, time 16.09ms
iter 27500: loss 1.0964, time 12.22ms
iter 27600: loss 1.1518, time 15.38ms
iter 27700: loss 1.1192, time 14.36ms
iter 27800: loss 1.1389, time 11.26ms
iter 27900: loss 1.1882, time 20.25ms
step 28000: train loss 1.0832, val loss 1.0684
iter 28000: loss 1.1765, time 4282.04ms
iter 28100: loss 1.0970, time 14.49ms
iter 28200: loss 1.1450, time 13.76ms
iter 28300: loss 1.0811, time 13.34ms
iter 28400: loss 1.1234, time 20.70ms
iter 28500: loss 1.0877, time 16.14ms
iter 28600: loss 1.1090, time 14.14ms
iter 28700: loss 1.1364, time 14.82ms
iter 28800: loss 1.1624, time 15.64ms
iter 28900: loss 1.1038, time 17.82ms
step 29000: train loss 1.0850, val loss 1.0687
iter 29000: loss 1.1413, time 3701.21ms
iter 29100: loss 1.1233, time 12.76ms
iter 29200: loss 1.1084, time 12.06ms
iter 29300: loss 1.1278, time 15.46ms
iter 29400: loss 1.0867, time 13.79ms
iter 29500: loss 1.1561, time 16.86ms
iter 29600: loss 1.0621, time 14.67ms
iter 29700: loss 1.1408, time 13.46ms
iter 29800: loss 1.1222, time 13.93ms
iter 29900: loss 1.0752, time 13.29ms
step 30000: train loss 1.0803, val loss 1.0723
iter 30000: loss 1.0926, time 3581.96ms
iter 30100: loss 1.0820, time 15.90ms
iter 30200: loss 1.1302, time 13.57ms
iter 30300: loss 1.1723, time 9.64ms
iter 30400: loss 1.1448, time 10.59ms
iter 30500: loss 1.1385, time 10.93ms
iter 30600: loss 1.1237, time 10.14ms
iter 30700: loss 1.0465, time 10.44ms
iter 30800: loss 1.1054, time 9.85ms
iter 30900: loss 1.0947, time 9.93ms
step 31000: train loss 1.0781, val loss 1.0637
iter 31000: loss 1.1409, time 2649.12ms
iter 31100: loss 1.2257, time 9.89ms
iter 31200: loss 1.1726, time 10.58ms
iter 31300: loss 1.1525, time 9.95ms
iter 31400: loss 1.0910, time 10.07ms
iter 31500: loss 1.1701, time 9.66ms
iter 31600: loss 1.0930, time 11.26ms
iter 31700: loss 1.0983, time 9.80ms
iter 31800: loss 1.1429, time 9.79ms
iter 31900: loss 1.0791, time 10.24ms
step 32000: train loss 1.0733, val loss 1.0623
iter 32000: loss 1.0879, time 2659.11ms
iter 32100: loss 1.1174, time 9.96ms
iter 32200: loss 1.0550, time 9.95ms
iter 32300: loss 1.1179, time 11.48ms
iter 32400: loss 1.0906, time 10.51ms
iter 32500: loss 1.1403, time 10.27ms
iter 32600: loss 1.1172, time 9.89ms
iter 32700: loss 1.1424, time 10.27ms
iter 32800: loss 1.1572, time 13.92ms
iter 32900: loss 1.0711, time 10.96ms
step 33000: train loss 1.0754, val loss 1.0629
iter 33000: loss 1.1046, time 2605.79ms
iter 33100: loss 1.0965, time 10.26ms
iter 33200: loss 1.1290, time 10.69ms
iter 33300: loss 1.1197, time 10.11ms
iter 33400: loss 1.0900, time 10.10ms
iter 33500: loss 1.1204, time 9.87ms
iter 33600: loss 1.0881, time 9.69ms
iter 33700: loss 1.0941, time 12.43ms
iter 33800: loss 1.0996, time 11.18ms
iter 33900: loss 1.1402, time 10.16ms
step 34000: train loss 1.0706, val loss 1.0582
iter 34000: loss 1.1425, time 2763.54ms
iter 34100: loss 1.1075, time 9.76ms
iter 34200: loss 1.1263, time 9.84ms
iter 34300: loss 1.1068, time 10.19ms
iter 34400: loss 1.0798, time 10.10ms
iter 34500: loss 1.0876, time 9.91ms
iter 34600: loss 1.1004, time 9.84ms
iter 34700: loss 1.0807, time 10.44ms
iter 34800: loss 1.0884, time 10.04ms
iter 34900: loss 1.1037, time 10.21ms
step 35000: train loss 1.0682, val loss 1.0561
iter 35000: loss 1.0297, time 2842.92ms
iter 35100: loss 1.0957, time 10.88ms
iter 35200: loss 1.0516, time 10.43ms
iter 35300: loss 1.1324, time 9.77ms
iter 35400: loss 1.0987, time 10.23ms
iter 35500: loss 1.0847, time 10.31ms
iter 35600: loss 1.0598, time 9.93ms
iter 35700: loss 1.1060, time 10.20ms
iter 35800: loss 1.0807, time 10.02ms
iter 35900: loss 1.0208, time 9.76ms
step 36000: train loss 1.0660, val loss 1.0514
iter 36000: loss 1.1140, time 2680.48ms
iter 36100: loss 1.1328, time 11.73ms
iter 36200: loss 1.1417, time 10.07ms
iter 36300: loss 1.1288, time 10.29ms
iter 36400: loss 1.1259, time 10.18ms
iter 36500: loss 1.1202, time 10.33ms
iter 36600: loss 1.0621, time 10.34ms
iter 36700: loss 1.0844, time 9.83ms
iter 36800: loss 1.1581, time 10.06ms
iter 36900: loss 1.1174, time 9.87ms
step 37000: train loss 1.0674, val loss 1.0500
iter 37000: loss 1.1678, time 2754.14ms
iter 37100: loss 1.1329, time 13.40ms
iter 37200: loss 1.0917, time 9.82ms
iter 37300: loss 1.1125, time 10.98ms
iter 37400: loss 1.0558, time 10.65ms
iter 37500: loss 1.0811, time 10.15ms
iter 37600: loss 1.0946, time 9.90ms
iter 37700: loss 1.0645, time 9.96ms
iter 37800: loss 1.0671, time 10.04ms
iter 37900: loss 1.1404, time 9.45ms
step 38000: train loss 1.0643, val loss 1.0503
iter 38000: loss 1.1047, time 2667.90ms
iter 38100: loss 1.1294, time 10.24ms
iter 38200: loss 1.0948, time 12.32ms
iter 38300: loss 1.1484, time 9.87ms
iter 38400: loss 1.0639, time 10.08ms
iter 38500: loss 1.1400, time 10.90ms
iter 38600: loss 1.0652, time 9.82ms
iter 38700: loss 1.1301, time 10.24ms
iter 38800: loss 1.0787, time 10.82ms
iter 38900: loss 1.0511, time 10.01ms
step 39000: train loss 1.0617, val loss 1.0535
iter 39000: loss 1.1024, time 2839.19ms
iter 39100: loss 1.0849, time 12.79ms
iter 39200: loss 1.1023, time 9.64ms
iter 39300: loss 1.1153, time 10.55ms
iter 39400: loss 1.0970, time 10.64ms
iter 39500: loss 1.0831, time 14.70ms
iter 39600: loss 1.1426, time 9.99ms
iter 39700: loss 1.1409, time 9.99ms
iter 39800: loss 1.1024, time 10.64ms
iter 39900: loss 1.0974, time 11.19ms
step 40000: train loss 1.0611, val loss 1.0451
iter 40000: loss 1.0993, time 3371.14ms
iter 40100: loss 1.0617, time 10.87ms
iter 40200: loss 1.0882, time 10.18ms
iter 40300: loss 1.1080, time 10.50ms
iter 40400: loss 1.0924, time 11.84ms
iter 40500: loss 1.1524, time 9.65ms
iter 40600: loss 1.1040, time 10.03ms
iter 40700: loss 1.0644, time 10.06ms
iter 40800: loss 1.1186, time 10.13ms
iter 40900: loss 1.0986, time 13.40ms
step 41000: train loss 1.0584, val loss 1.0457
iter 41000: loss 1.0873, time 2592.43ms
iter 41100: loss 1.1395, time 10.01ms
iter 41200: loss 1.1015, time 10.05ms
iter 41300: loss 1.1317, time 9.74ms
iter 41400: loss 1.0938, time 10.12ms
iter 41500: loss 1.1217, time 10.89ms
iter 41600: loss 1.0731, time 12.37ms
iter 41700: loss 1.1256, time 10.39ms
iter 41800: loss 1.1389, time 9.89ms
iter 41900: loss 1.0255, time 10.05ms
step 42000: train loss 1.0523, val loss 1.0426
iter 42000: loss 1.0967, time 2591.83ms
iter 42100: loss 1.1386, time 10.13ms
iter 42200: loss 1.0711, time 9.98ms
iter 42300: loss 1.0776, time 11.93ms
iter 42400: loss 1.0901, time 10.03ms
iter 42500: loss 1.0483, time 9.94ms
iter 42600: loss 1.0997, time 10.75ms
iter 42700: loss 1.1051, time 10.13ms
iter 42800: loss 1.1039, time 10.11ms
iter 42900: loss 1.0741, time 10.60ms
step 43000: train loss 1.0595, val loss 1.0413
iter 43000: loss 1.0663, time 2653.66ms
iter 43100: loss 1.1431, time 9.78ms
iter 43200: loss 1.0987, time 9.48ms
iter 43300: loss 1.1297, time 9.68ms
iter 43400: loss 1.0794, time 9.45ms
iter 43500: loss 1.1006, time 9.59ms
iter 43600: loss 1.1125, time 9.90ms
iter 43700: loss 1.0789, time 10.87ms
iter 43800: loss 1.0967, time 10.44ms
iter 43900: loss 1.0583, time 10.17ms
step 44000: train loss 1.0513, val loss 1.0393
iter 44000: loss 1.1205, time 2730.88ms
iter 44100: loss 1.0939, time 10.24ms
iter 44200: loss 1.0557, time 9.67ms
iter 44300: loss 1.0638, time 10.96ms
iter 44400: loss 1.1101, time 10.42ms
iter 44500: loss 1.0729, time 10.26ms
iter 44600: loss 1.1149, time 10.79ms
iter 44700: loss 1.0883, time 11.39ms
iter 44800: loss 1.0475, time 10.07ms
iter 44900: loss 1.0966, time 10.11ms
step 45000: train loss 1.0502, val loss 1.0365
iter 45000: loss 1.0683, time 2688.22ms
iter 45100: loss 1.1055, time 12.07ms
iter 45200: loss 1.0750, time 10.11ms
iter 45300: loss 1.1210, time 10.47ms
iter 45400: loss 1.1046, time 9.87ms
iter 45500: loss 1.0805, time 9.82ms
iter 45600: loss 1.1196, time 11.48ms
iter 45700: loss 1.0872, time 10.23ms
iter 45800: loss 1.1268, time 9.56ms
iter 45900: loss 1.1107, time 10.77ms
step 46000: train loss 1.0477, val loss 1.0408
iter 46000: loss 1.0561, time 4232.51ms
iter 46100: loss 1.0725, time 19.63ms
iter 46200: loss 1.0818, time 25.12ms
iter 46300: loss 1.1319, time 10.34ms
iter 46400: loss 1.0720, time 10.29ms
iter 46500: loss 1.0941, time 10.17ms
iter 46600: loss 1.0832, time 11.59ms
iter 46700: loss 1.1057, time 15.36ms
iter 46800: loss 1.0426, time 16.56ms
iter 46900: loss 1.1328, time 19.67ms
step 47000: train loss 1.0465, val loss 1.0337
iter 47000: loss 1.1048, time 3134.64ms
iter 47100: loss 1.0733, time 10.97ms
iter 47200: loss 1.0420, time 10.67ms
iter 47300: loss 1.0453, time 9.97ms
iter 47400: loss 1.0921, time 10.41ms
iter 47500: loss 1.0512, time 12.48ms
iter 47600: loss 1.0884, time 10.84ms
iter 47700: loss 1.0513, time 11.07ms
iter 47800: loss 1.0762, time 9.91ms
iter 47900: loss 1.1243, time 10.49ms
step 48000: train loss 1.0455, val loss 1.0338
iter 48000: loss 1.0422, time 2945.23ms
iter 48100: loss 1.0349, time 11.22ms
iter 48200: loss 1.0685, time 12.88ms
iter 48300: loss 1.1099, time 10.85ms
iter 48400: loss 1.1519, time 11.46ms
iter 48500: loss 1.1143, time 10.24ms
iter 48600: loss 1.0771, time 10.11ms
iter 48700: loss 1.0882, time 9.72ms
iter 48800: loss 1.1312, time 11.04ms
iter 48900: loss 1.1154, time 10.44ms
step 49000: train loss 1.0465, val loss 1.0295
iter 49000: loss 1.0935, time 2682.56ms
iter 49100: loss 1.0614, time 9.93ms
iter 49200: loss 1.0811, time 10.79ms
iter 49300: loss 1.1218, time 10.27ms
iter 49400: loss 1.0940, time 10.17ms
iter 49500: loss 1.1044, time 11.17ms
iter 49600: loss 1.0850, time 9.89ms
iter 49700: loss 1.1055, time 9.89ms
iter 49800: loss 1.1417, time 10.37ms
iter 49900: loss 1.0943, time 10.24ms
step 50000: train loss 1.0409, val loss 1.0235
iter 50000: loss 1.0566, time 2623.62ms
iter 50100: loss 1.0623, time 10.80ms
iter 50200: loss 1.0770, time 10.22ms
iter 50300: loss 1.0817, time 9.98ms
iter 50400: loss 1.0455, time 10.23ms
iter 50500: loss 1.1036, time 9.88ms
iter 50600: loss 1.1004, time 10.31ms
iter 50700: loss 1.1329, time 10.08ms
iter 50800: loss 1.0679, time 10.13ms
iter 50900: loss 1.0525, time 12.11ms
step 51000: train loss 1.0453, val loss 1.0308
iter 51000: loss 1.1186, time 2677.13ms
iter 51100: loss 1.0611, time 10.11ms
iter 51200: loss 1.0821, time 11.39ms
iter 51300: loss 1.0923, time 12.47ms
iter 51400: loss 1.0359, time 10.19ms
iter 51500: loss 1.0485, time 10.75ms
iter 51600: loss 1.1043, time 10.79ms
iter 51700: loss 1.0969, time 10.11ms
iter 51800: loss 1.1233, time 10.47ms
iter 51900: loss 1.1249, time 10.05ms
step 52000: train loss 1.0409, val loss 1.0264
iter 52000: loss 1.0783, time 2637.32ms
iter 52100: loss 1.0922, time 10.23ms
iter 52200: loss 1.0918, time 10.42ms
iter 52300: loss 1.0635, time 10.36ms
iter 52400: loss 1.0759, time 9.61ms
iter 52500: loss 1.0680, time 9.59ms
iter 52600: loss 1.1283, time 10.18ms
iter 52700: loss 1.0458, time 9.97ms
iter 52800: loss 1.0896, time 10.26ms
iter 52900: loss 1.0821, time 11.61ms
step 53000: train loss 1.0432, val loss 1.0259
iter 53000: loss 1.0769, time 2848.44ms
iter 53100: loss 1.0470, time 9.56ms
iter 53200: loss 1.0558, time 9.86ms
iter 53300: loss 1.0498, time 9.99ms
iter 53400: loss 1.0598, time 9.61ms
iter 53500: loss 1.0631, time 10.26ms
iter 53600: loss 1.1327, time 9.59ms
iter 53700: loss 1.0880, time 10.13ms
iter 53800: loss 1.1223, time 10.67ms
iter 53900: loss 1.0844, time 9.89ms
step 54000: train loss 1.0384, val loss 1.0252
iter 54000: loss 1.1139, time 4052.39ms
iter 54100: loss 1.0695, time 10.56ms
iter 54200: loss 1.0969, time 9.79ms
iter 54300: loss 1.0933, time 9.83ms
iter 54400: loss 1.0862, time 17.88ms
iter 54500: loss 1.0572, time 9.59ms
iter 54600: loss 1.0780, time 10.00ms
iter 54700: loss 1.0715, time 10.05ms
iter 54800: loss 1.1064, time 10.23ms
iter 54900: loss 1.1225, time 12.21ms
step 55000: train loss 1.0361, val loss 1.0218
iter 55000: loss 1.0893, time 2662.35ms
iter 55100: loss 1.0895, time 10.61ms
iter 55200: loss 1.0312, time 15.28ms
iter 55300: loss 1.0607, time 10.47ms
iter 55400: loss 1.0955, time 10.45ms
iter 55500: loss 1.0526, time 9.75ms
iter 55600: loss 1.1343, time 10.11ms
iter 55700: loss 1.0936, time 10.04ms
iter 55800: loss 1.0870, time 9.52ms
iter 55900: loss 1.0084, time 10.42ms
step 56000: train loss 1.0356, val loss 1.0218
iter 56000: loss 1.0466, time 2624.70ms
iter 56100: loss 1.1142, time 9.97ms
iter 56200: loss 1.0517, time 11.05ms
iter 56300: loss 1.0572, time 10.27ms
iter 56400: loss 1.0840, time 9.87ms
iter 56500: loss 1.1253, time 10.26ms
iter 56600: loss 1.0216, time 18.77ms
iter 56700: loss 1.0240, time 14.58ms
iter 56800: loss 1.0508, time 10.05ms
iter 56900: loss 1.0913, time 10.43ms
step 57000: train loss 1.0360, val loss 1.0212
iter 57000: loss 1.1209, time 2682.86ms
iter 57100: loss 1.0103, time 10.57ms
iter 57200: loss 1.1034, time 10.39ms
iter 57300: loss 1.0933, time 10.11ms
iter 57400: loss 1.0471, time 10.20ms
iter 57500: loss 1.1008, time 9.93ms
iter 57600: loss 1.0983, time 10.21ms
iter 57700: loss 1.0444, time 10.48ms
iter 57800: loss 1.1141, time 10.84ms
iter 57900: loss 1.0785, time 10.72ms
step 58000: train loss 1.0272, val loss 1.0175
iter 58000: loss 1.0937, time 2692.86ms
iter 58100: loss 1.0910, time 10.10ms
iter 58200: loss 1.0792, time 10.20ms
iter 58300: loss 1.1442, time 10.34ms
iter 58400: loss 1.0256, time 9.90ms
iter 58500: loss 1.0768, time 10.24ms
iter 58600: loss 1.0505, time 10.31ms
iter 58700: loss 1.0597, time 9.70ms
iter 58800: loss 1.1026, time 10.26ms
iter 58900: loss 1.1571, time 10.43ms
step 59000: train loss 1.0295, val loss 1.0130
iter 59000: loss 1.0524, time 2980.70ms
iter 59100: loss 1.0438, time 9.82ms
iter 59200: loss 1.0761, time 18.11ms
iter 59300: loss 1.0321, time 12.35ms
iter 59400: loss 1.0647, time 9.78ms
iter 59500: loss 1.0955, time 9.71ms
iter 59600: loss 1.1008, time 10.45ms
iter 59700: loss 1.0481, time 10.10ms
iter 59800: loss 1.0317, time 9.90ms
iter 59900: loss 1.0187, time 9.91ms
step 60000: train loss 1.0270, val loss 1.0156
iter 60000: loss 1.0273, time 2548.05ms
iter 60100: loss 1.0507, time 12.75ms
iter 60200: loss 1.0507, time 10.08ms
iter 60300: loss 1.1111, time 10.10ms
iter 60400: loss 1.1089, time 10.24ms
iter 60500: loss 1.0490, time 9.67ms
iter 60600: loss 1.1013, time 10.45ms
iter 60700: loss 1.0738, time 14.56ms
iter 60800: loss 1.1102, time 9.82ms
iter 60900: loss 1.0887, time 10.14ms
step 61000: train loss 1.0282, val loss 1.0186
iter 61000: loss 1.0610, time 2702.00ms
iter 61100: loss 1.0713, time 10.15ms
iter 61200: loss 1.0381, time 12.08ms
iter 61300: loss 1.0545, time 9.68ms
iter 61400: loss 1.0251, time 10.97ms
iter 61500: loss 1.0309, time 10.05ms
iter 61600: loss 1.0874, time 10.37ms
iter 61700: loss 1.0745, time 9.97ms
iter 61800: loss 1.0502, time 9.54ms
iter 61900: loss 1.0628, time 9.84ms
step 62000: train loss 1.0239, val loss 1.0136
iter 62000: loss 1.1023, time 2941.65ms
iter 62100: loss 1.0935, time 10.30ms
iter 62200: loss 1.0799, time 9.76ms
iter 62300: loss 0.9881, time 31.21ms
iter 62400: loss 1.0513, time 11.36ms
iter 62500: loss 1.0283, time 10.21ms
iter 62600: loss 1.0370, time 12.36ms
iter 62700: loss 0.9788, time 10.01ms
iter 62800: loss 1.0636, time 10.20ms
iter 62900: loss 1.0491, time 10.49ms
step 63000: train loss 1.0220, val loss 1.0076
iter 63000: loss 1.0094, time 2877.40ms
iter 63100: loss 1.0808, time 10.65ms
iter 63200: loss 1.0479, time 10.00ms
iter 63300: loss 1.0103, time 14.30ms
iter 63400: loss 1.0946, time 10.31ms
iter 63500: loss 1.0479, time 10.04ms
iter 63600: loss 1.0550, time 10.57ms
iter 63700: loss 1.0115, time 9.86ms
iter 63800: loss 1.0711, time 13.30ms
iter 63900: loss 1.0354, time 10.98ms
step 64000: train loss 1.0189, val loss 1.0038
iter 64000: loss 1.0459, time 2698.63ms
iter 64100: loss 1.0755, time 10.34ms
iter 64200: loss 1.0351, time 10.35ms
iter 64300: loss 1.0909, time 11.46ms
iter 64400: loss 1.0492, time 10.26ms
iter 64500: loss 1.0904, time 9.98ms
iter 64600: loss 1.0581, time 12.49ms
iter 64700: loss 1.0689, time 10.40ms
iter 64800: loss 1.0487, time 10.07ms
iter 64900: loss 1.0384, time 10.36ms
step 65000: train loss 1.0232, val loss 1.0066
iter 65000: loss 1.0260, time 2785.25ms
iter 65100: loss 1.0338, time 9.81ms
iter 65200: loss 1.0531, time 10.28ms
iter 65300: loss 1.0298, time 10.52ms
iter 65400: loss 1.0880, time 10.10ms
iter 65500: loss 1.0739, time 10.85ms
iter 65600: loss 1.0989, time 9.83ms
iter 65700: loss 1.1176, time 9.84ms
iter 65800: loss 1.0385, time 9.98ms
iter 65900: loss 1.0632, time 9.84ms
step 66000: train loss 1.0202, val loss 1.0097
iter 66000: loss 1.0972, time 2534.50ms
iter 66100: loss 1.0608, time 9.43ms
iter 66200: loss 1.0432, time 9.88ms
iter 66300: loss 1.0362, time 11.94ms
iter 66400: loss 1.0624, time 10.18ms
iter 66500: loss 1.0517, time 13.74ms
iter 66600: loss 1.1207, time 9.73ms
iter 66700: loss 1.1060, time 13.67ms
iter 66800: loss 1.1141, time 10.89ms
iter 66900: loss 1.0260, time 10.29ms
step 67000: train loss 1.0197, val loss 1.0061
iter 67000: loss 1.0648, time 2719.93ms
iter 67100: loss 1.0459, time 9.97ms
iter 67200: loss 1.0885, time 10.27ms
iter 67300: loss 1.0777, time 10.79ms
iter 67400: loss 0.9987, time 10.10ms
iter 67500: loss 1.0373, time 10.58ms
iter 67600: loss 1.0456, time 9.48ms
iter 67700: loss 1.0588, time 10.01ms
iter 67800: loss 1.0507, time 10.20ms
iter 67900: loss 1.0465, time 9.73ms
step 68000: train loss 1.0212, val loss 1.0055
iter 68000: loss 1.0947, time 2759.68ms
iter 68100: loss 1.0617, time 10.12ms
iter 68200: loss 1.0286, time 9.80ms
iter 68300: loss 1.0317, time 9.77ms
iter 68400: loss 1.0567, time 9.75ms
iter 68500: loss 1.0416, time 10.58ms
iter 68600: loss 1.0350, time 18.33ms
iter 68700: loss 1.1045, time 11.19ms
iter 68800: loss 1.0315, time 9.98ms
iter 68900: loss 1.1161, time 9.87ms
step 69000: train loss 1.0145, val loss 0.9967
iter 69000: loss 1.1187, time 2757.96ms
iter 69100: loss 1.0878, time 10.44ms
iter 69200: loss 1.0132, time 10.07ms
iter 69300: loss 1.0827, time 22.68ms
iter 69400: loss 1.0827, time 10.20ms
iter 69500: loss 1.0380, time 9.93ms
iter 69600: loss 0.9940, time 11.17ms
iter 69700: loss 1.0564, time 9.68ms
iter 69800: loss 1.0868, time 10.21ms
iter 69900: loss 1.0341, time 9.70ms
step 70000: train loss 1.0138, val loss 1.0014
iter 70000: loss 1.0318, time 2677.77ms
iter 70100: loss 1.0448, time 10.13ms
iter 70200: loss 1.0628, time 9.87ms
iter 70300: loss 1.0589, time 10.33ms
iter 70400: loss 1.0517, time 9.88ms
iter 70500: loss 1.0769, time 9.83ms
iter 70600: loss 0.9918, time 12.00ms
iter 70700: loss 1.0255, time 9.75ms
iter 70800: loss 1.1118, time 10.29ms
iter 70900: loss 0.9894, time 9.74ms
step 71000: train loss 1.0122, val loss 1.0017
iter 71000: loss 1.0303, time 2658.49ms
iter 71100: loss 1.0651, time 10.32ms
iter 71200: loss 0.9995, time 10.96ms
iter 71300: loss 1.0876, time 12.27ms
iter 71400: loss 1.0467, time 10.28ms
iter 71500: loss 1.0178, time 10.20ms
iter 71600: loss 1.0968, time 10.36ms
iter 71700: loss 1.0201, time 10.33ms
iter 71800: loss 1.0927, time 10.59ms
iter 71900: loss 1.0641, time 10.41ms
step 72000: train loss 1.0104, val loss 0.9960
iter 72000: loss 1.0508, time 2723.45ms
iter 72100: loss 1.0472, time 10.49ms
iter 72200: loss 1.0781, time 13.26ms
iter 72300: loss 1.0210, time 10.48ms
iter 72400: loss 1.0498, time 18.28ms
iter 72500: loss 1.0564, time 38.29ms
iter 72600: loss 1.0127, time 10.46ms
iter 72700: loss 1.0224, time 11.09ms
iter 72800: loss 1.0488, time 11.17ms
iter 72900: loss 1.0002, time 11.60ms
step 73000: train loss 1.0148, val loss 1.0011
iter 73000: loss 1.0371, time 3040.28ms
iter 73100: loss 1.0521, time 11.02ms
iter 73200: loss 1.0894, time 10.12ms
iter 73300: loss 1.0223, time 12.13ms
iter 73400: loss 1.0489, time 10.27ms
iter 73500: loss 1.0537, time 10.45ms
iter 73600: loss 1.0424, time 10.06ms
iter 73700: loss 1.0112, time 10.99ms
iter 73800: loss 1.0719, time 12.14ms
iter 73900: loss 1.0151, time 10.19ms
step 74000: train loss 1.0100, val loss 0.9972
iter 74000: loss 1.0548, time 3564.11ms
iter 74100: loss 1.0202, time 10.63ms
iter 74200: loss 1.0790, time 10.67ms
iter 74300: loss 1.0640, time 10.61ms
iter 74400: loss 1.0002, time 15.85ms
iter 74500: loss 1.0818, time 10.29ms
iter 74600: loss 1.0820, time 10.15ms
iter 74700: loss 1.0854, time 10.43ms
iter 74800: loss 1.0292, time 11.98ms
iter 74900: loss 1.0782, time 10.43ms
step 75000: train loss 1.0116, val loss 0.9934
iter 75000: loss 1.0760, time 3956.05ms
iter 75100: loss 1.0337, time 10.28ms
iter 75200: loss 1.0519, time 10.46ms
iter 75300: loss 1.0529, time 10.81ms
iter 75400: loss 1.0224, time 10.93ms
iter 75500: loss 0.9978, time 10.68ms
iter 75600: loss 1.0366, time 10.70ms
iter 75700: loss 1.0474, time 10.44ms
iter 75800: loss 1.0262, time 10.70ms
iter 75900: loss 1.0299, time 11.45ms
step 76000: train loss 1.0090, val loss 0.9937
iter 76000: loss 1.0403, time 3189.61ms
iter 76100: loss 1.0657, time 13.29ms
iter 76200: loss 1.0654, time 10.73ms
iter 76300: loss 1.0925, time 12.38ms
iter 76400: loss 1.0654, time 10.29ms
iter 76500: loss 1.0799, time 10.77ms
iter 76600: loss 1.0501, time 11.35ms
iter 76700: loss 1.0851, time 10.68ms
iter 76800: loss 0.9854, time 13.33ms
iter 76900: loss 1.0384, time 10.75ms
step 77000: train loss 1.0069, val loss 0.9957
iter 77000: loss 1.0642, time 3403.27ms
iter 77100: loss 1.1356, time 10.37ms
iter 77200: loss 1.0712, time 10.38ms
iter 77300: loss 1.0718, time 10.44ms
iter 77400: loss 1.1130, time 11.60ms
iter 77500: loss 1.0567, time 10.83ms
iter 77600: loss 1.0762, time 13.85ms
iter 77700: loss 0.9896, time 11.28ms
iter 77800: loss 1.1061, time 16.45ms
iter 77900: loss 1.0348, time 10.22ms
step 78000: train loss 1.0053, val loss 0.9922
iter 78000: loss 1.0748, time 4167.00ms
iter 78100: loss 1.0302, time 10.54ms
iter 78200: loss 1.0763, time 13.37ms
iter 78300: loss 1.0406, time 10.02ms
iter 78400: loss 1.0602, time 10.50ms
iter 78500: loss 1.0903, time 37.63ms
iter 78600: loss 1.0013, time 13.51ms
iter 78700: loss 1.0918, time 10.28ms
iter 78800: loss 1.0951, time 11.19ms
iter 78900: loss 1.0988, time 9.59ms
step 79000: train loss 1.0031, val loss 0.9893
iter 79000: loss 1.0677, time 4480.04ms
iter 79100: loss 1.0303, time 9.83ms
iter 79200: loss 1.0099, time 11.22ms
iter 79300: loss 1.0594, time 10.05ms
iter 79400: loss 0.9821, time 16.47ms
iter 79500: loss 1.0293, time 10.44ms
iter 79600: loss 1.0559, time 11.53ms
iter 79700: loss 1.0330, time 12.45ms
iter 79800: loss 1.0608, time 40.27ms
iter 79900: loss 1.0376, time 24.95ms
step 80000: train loss 1.0047, val loss 0.9948
iter 80000: loss 1.0478, time 3225.05ms
iter 80100: loss 1.0518, time 9.99ms
iter 80200: loss 0.9516, time 10.75ms
iter 80300: loss 1.0151, time 10.22ms
iter 80400: loss 1.0666, time 10.09ms
iter 80500: loss 1.0836, time 10.23ms
iter 80600: loss 1.1059, time 11.49ms
iter 80700: loss 1.0608, time 10.42ms
iter 80800: loss 0.9698, time 9.81ms
iter 80900: loss 1.0185, time 10.56ms
step 81000: train loss 1.0017, val loss 0.9895
iter 81000: loss 1.0829, time 3055.62ms
iter 81100: loss 1.0260, time 10.05ms
iter 81200: loss 1.0171, time 10.41ms
iter 81300: loss 1.0777, time 9.92ms
iter 81400: loss 1.0393, time 9.82ms
iter 81500: loss 1.0266, time 9.47ms
iter 81600: loss 1.1137, time 10.31ms
iter 81700: loss 1.0183, time 10.23ms
iter 81800: loss 1.0472, time 11.42ms
iter 81900: loss 1.0584, time 10.22ms
step 82000: train loss 1.0008, val loss 0.9914
iter 82000: loss 1.0377, time 2858.79ms
iter 82100: loss 1.0620, time 9.87ms
iter 82200: loss 1.0916, time 9.91ms
iter 82300: loss 1.0084, time 10.41ms
iter 82400: loss 1.0288, time 9.83ms
iter 82500: loss 1.0244, time 11.05ms
iter 82600: loss 1.0409, time 10.07ms
iter 82700: loss 1.0721, time 11.52ms
iter 82800: loss 1.0865, time 10.24ms
iter 82900: loss 0.9528, time 10.37ms
step 83000: train loss 0.9993, val loss 0.9886
iter 83000: loss 1.0074, time 3145.64ms
iter 83100: loss 1.0021, time 13.72ms
iter 83200: loss 1.0651, time 11.20ms
iter 83300: loss 1.0863, time 10.90ms
iter 83400: loss 1.0762, time 9.94ms
iter 83500: loss 1.0773, time 10.50ms
iter 83600: loss 0.9992, time 10.50ms
iter 83700: loss 1.0015, time 11.22ms
iter 83800: loss 1.0970, time 10.30ms
iter 83900: loss 1.0010, time 9.89ms
step 84000: train loss 0.9991, val loss 0.9878
iter 84000: loss 1.0003, time 2710.75ms
iter 84100: loss 1.0790, time 9.75ms
iter 84200: loss 1.0369, time 17.11ms
iter 84300: loss 1.0723, time 10.09ms
iter 84400: loss 1.0552, time 9.81ms
iter 84500: loss 1.0898, time 10.06ms
iter 84600: loss 0.9948, time 10.60ms
iter 84700: loss 1.0389, time 16.44ms
iter 84800: loss 0.9783, time 10.04ms
iter 84900: loss 1.0664, time 9.92ms
step 85000: train loss 0.9972, val loss 0.9866
iter 85000: loss 0.9925, time 2878.17ms
iter 85100: loss 1.0821, time 9.82ms
iter 85200: loss 1.0374, time 11.21ms
iter 85300: loss 1.0271, time 12.64ms
iter 85400: loss 1.0462, time 10.87ms
iter 85500: loss 1.1537, time 10.02ms
iter 85600: loss 1.0738, time 10.31ms
iter 85700: loss 1.0305, time 9.82ms
iter 85800: loss 1.0193, time 10.05ms
iter 85900: loss 0.9944, time 9.70ms
step 86000: train loss 0.9971, val loss 0.9906
iter 86000: loss 1.0203, time 2749.83ms
iter 86100: loss 1.0207, time 9.94ms
iter 86200: loss 1.0328, time 10.45ms
iter 86300: loss 1.0747, time 10.02ms
iter 86400: loss 1.0559, time 10.03ms
iter 86500: loss 1.0096, time 9.70ms
iter 86600: loss 1.0680, time 10.16ms
iter 86700: loss 1.0388, time 9.81ms
iter 86800: loss 1.0536, time 10.48ms
iter 86900: loss 1.0406, time 10.03ms
step 87000: train loss 0.9944, val loss 0.9868
iter 87000: loss 0.9847, time 2737.10ms
iter 87100: loss 0.9915, time 12.29ms
iter 87200: loss 1.0306, time 9.83ms
iter 87300: loss 1.0697, time 10.57ms
iter 87400: loss 1.0661, time 9.96ms
iter 87500: loss 1.0301, time 10.29ms
iter 87600: loss 1.0302, time 10.26ms
iter 87700: loss 1.0662, time 10.02ms
iter 87800: loss 1.0592, time 12.51ms
iter 87900: loss 0.9832, time 10.21ms
step 88000: train loss 0.9930, val loss 0.9825
iter 88000: loss 1.0591, time 2678.63ms
iter 88100: loss 0.9908, time 11.23ms
iter 88200: loss 1.0016, time 11.63ms
iter 88300: loss 1.0099, time 10.38ms
iter 88400: loss 0.9978, time 10.17ms
iter 88500: loss 1.0507, time 9.80ms
iter 88600: loss 0.9670, time 10.54ms
iter 88700: loss 1.0351, time 9.79ms
iter 88800: loss 1.0336, time 10.29ms
iter 88900: loss 1.0091, time 10.61ms
step 89000: train loss 0.9915, val loss 0.9850
iter 89000: loss 1.0124, time 2637.80ms
iter 89100: loss 1.0652, time 11.53ms
iter 89200: loss 1.0548, time 10.22ms
iter 89300: loss 1.0223, time 10.04ms
iter 89400: loss 1.0233, time 11.72ms
iter 89500: loss 0.9779, time 9.73ms
iter 89600: loss 1.0128, time 10.53ms
iter 89700: loss 1.0309, time 10.11ms
iter 89800: loss 1.0243, time 11.67ms
iter 89900: loss 0.9946, time 9.93ms
step 90000: train loss 0.9919, val loss 0.9789
iter 90000: loss 1.0199, time 2667.78ms
iter 90100: loss 1.0497, time 11.81ms
iter 90200: loss 1.0881, time 10.30ms
iter 90300: loss 1.0506, time 9.50ms
iter 90400: loss 0.9815, time 10.50ms
iter 90500: loss 1.0760, time 10.07ms
iter 90600: loss 1.0107, time 9.57ms
iter 90700: loss 1.0372, time 10.40ms
iter 90800: loss 1.0495, time 10.12ms
iter 90900: loss 1.0801, time 10.02ms
step 91000: train loss 0.9909, val loss 0.9789
iter 91000: loss 1.0197, time 2740.60ms
iter 91100: loss 1.0849, time 10.50ms
iter 91200: loss 1.0675, time 9.80ms
iter 91300: loss 1.0167, time 10.20ms
iter 91400: loss 1.0730, time 10.08ms
iter 91500: loss 1.0436, time 9.89ms
iter 91600: loss 1.0097, time 10.51ms
iter 91700: loss 1.0452, time 10.06ms
iter 91800: loss 1.0850, time 10.30ms
iter 91900: loss 1.0689, time 9.64ms
step 92000: train loss 0.9884, val loss 0.9805
iter 92000: loss 1.0229, time 2866.66ms
iter 92100: loss 1.0489, time 10.68ms
iter 92200: loss 1.0430, time 10.14ms
iter 92300: loss 1.0036, time 9.67ms
iter 92400: loss 1.0632, time 11.15ms
iter 92500: loss 0.9952, time 10.15ms
iter 92600: loss 0.9606, time 10.87ms
iter 92700: loss 0.9838, time 9.98ms
iter 92800: loss 1.0338, time 11.42ms
iter 92900: loss 1.0066, time 11.24ms
step 93000: train loss 0.9941, val loss 0.9801
iter 93000: loss 1.0141, time 2749.47ms
iter 93100: loss 1.0531, time 9.49ms
iter 93200: loss 1.0244, time 10.23ms
iter 93300: loss 1.0222, time 10.13ms
iter 93400: loss 1.0292, time 9.94ms
iter 93500: loss 1.0554, time 9.51ms
iter 93600: loss 1.0870, time 9.84ms
iter 93700: loss 0.9924, time 10.49ms
iter 93800: loss 1.0228, time 9.62ms
iter 93900: loss 1.0549, time 10.48ms
step 94000: train loss 0.9907, val loss 0.9756
iter 94000: loss 1.0116, time 2892.76ms
iter 94100: loss 1.0464, time 9.92ms
iter 94200: loss 1.0606, time 9.74ms
iter 94300: loss 1.0859, time 14.30ms
iter 94400: loss 1.0577, time 9.92ms
iter 94500: loss 1.0377, time 10.05ms
iter 94600: loss 1.0171, time 10.49ms
iter 94700: loss 1.0632, time 10.33ms
iter 94800: loss 1.0062, time 10.23ms
iter 94900: loss 1.0434, time 9.75ms
step 95000: train loss 0.9914, val loss 0.9817
iter 95000: loss 1.0438, time 2668.26ms
iter 95100: loss 0.9764, time 9.98ms
iter 95200: loss 1.0168, time 10.91ms
iter 95300: loss 0.9973, time 10.25ms
iter 95400: loss 1.0102, time 10.17ms
iter 95500: loss 1.0559, time 10.14ms
iter 95600: loss 0.9885, time 10.30ms
iter 95700: loss 1.0292, time 9.86ms
iter 95800: loss 1.0115, time 9.61ms
iter 95900: loss 1.0666, time 10.50ms
step 96000: train loss 0.9892, val loss 0.9790
iter 96000: loss 1.0468, time 3799.97ms
iter 96100: loss 1.0220, time 33.19ms
iter 96200: loss 1.0054, time 14.62ms
iter 96300: loss 1.0576, time 10.27ms
iter 96400: loss 1.0603, time 10.13ms
iter 96500: loss 1.0919, time 10.06ms
iter 96600: loss 1.0331, time 10.63ms
iter 96700: loss 1.0166, time 10.67ms
iter 96800: loss 0.9930, time 10.35ms
iter 96900: loss 1.0426, time 10.11ms
step 97000: train loss 0.9899, val loss 0.9828
iter 97000: loss 1.0245, time 2710.66ms
iter 97100: loss 1.0010, time 17.12ms
iter 97200: loss 1.0345, time 9.87ms
iter 97300: loss 0.9535, time 10.48ms
iter 97400: loss 1.0328, time 10.63ms
iter 97500: loss 1.0262, time 9.88ms
iter 97600: loss 1.0343, time 10.57ms
iter 97700: loss 0.9983, time 17.07ms
iter 97800: loss 1.0520, time 12.09ms
iter 97900: loss 1.0487, time 13.62ms
step 98000: train loss 0.9885, val loss 0.9832
iter 98000: loss 1.0576, time 2653.15ms
iter 98100: loss 1.0134, time 12.24ms
iter 98200: loss 1.0171, time 11.21ms
iter 98300: loss 0.9797, time 10.14ms
iter 98400: loss 1.0440, time 10.36ms
iter 98500: loss 1.0313, time 9.71ms
iter 98600: loss 1.0693, time 9.87ms
iter 98700: loss 1.0288, time 10.10ms
iter 98800: loss 1.0366, time 10.20ms
iter 98900: loss 1.0600, time 10.81ms
step 99000: train loss 0.9873, val loss 0.9739
iter 99000: loss 1.0134, time 2543.75ms
iter 99100: loss 1.0385, time 9.75ms
iter 99200: loss 1.0586, time 14.59ms
iter 99300: loss 1.0304, time 9.93ms
iter 99400: loss 1.0574, time 10.02ms
iter 99500: loss 1.0121, time 11.82ms
iter 99600: loss 1.0716, time 11.25ms
iter 99700: loss 1.0559, time 9.60ms
iter 99800: loss 0.9922, time 10.51ms
iter 99900: loss 0.9868, time 9.98ms
step 100000: train loss 0.9905, val loss 0.9783
iter 100000: loss 1.0336, time 2729.21ms
training done
Best validation loss: 0.9738883376121521
Total train time: 24.86 mins
Loading meta from ../../data/text8/meta.pkl...
Sample 1:
 the most popular in the united states in the united states is the southern coast of england of the country the basque population and the area since one nine seven three and one nine eight zero the export maintains that while divided into three countries is considered a controlled nation of the flora and the economy of the region is the private military council of military military office and legislative military office president george w bush born october two four one nine four one is a member o
Inference time: 1.87 seconds
Tokens per second: 266.75
---------------
Sample 2:
 the rings were in fact recently the individual forces for example and the institution of democracy commembers of the democratic republic the republic of mexico is elected president of the queen d ivoire on december three one eight nine two march one nine nine five the election of vice president and the president of the united nations general election of one nine three nine one nine three nine the board of states was the president of the united states government of the nation s united nations org
Inference time: 1.87 seconds
Tokens per second: 267.04
---------------
Sample 3:
 level debate on a substantial law of among free programmes see list of results of insurers exchange rates compared to the history of logic include among more integrated scriptures and debates in integrating verbs and not to have formal free programs for the public association to explain the historical program see the library of logic in the form of logic in common with among others which is created on the character from the formal non programming languages of the logic in a programming language 
Inference time: 1.92 seconds
Tokens per second: 260.71
---------------
Sample 4:
 onto its successors epoch prohibition is present in the work of the phantom pink pepper and power political benefits on the personal contract such as inspiration of the government s prohibition and institutions of his own suffocals and eggs the political party of europe has an important community in the end of the secretary general jonathan iii to encourage the government s name to prohibit russia and mission and to a series of candidates in the u s policies in the national assembly elections an
Inference time: 1.87 seconds
Tokens per second: 267.95
---------------
Sample 5:
 one nine nine six market slowly separated from the red wing of the barbarian courts and the second barbarian court the people s republic of china is seen as a result of the trade office bases in many cases the province is only in some cases the province of law most lawyers are removed from the president of the court and also the september one two zero zero five maintains a particular vote to complete the organization from the one nine eight zero s an international collection of economic progress
Inference time: 1.87 seconds
Tokens per second: 267.58
---------------
Sample 6:
 he is very measured in russia he was probably a revival of charitable reality and political assistance he was inspired by the amannius christian scholars admiralty milthew could not lead to the strip with the same form of grand duchy though castiglian was later presented in the reality of the presidential candidate which argued that atoustic self described terms were in common with the term american recognized prohibitions of the collection of the rest of the seventy years the relationship betwe
Inference time: 1.88 seconds
Tokens per second: 266.09
---------------
Sample 7:
 eight nine under the united kingdom house of representatives nicknamed daniel and greenwich germany heights four one nine nine five the united kingdom nine four one nine nine six supreme court has since been developed by antigonic or fishing exchange rate in the u s supreme court history supreme court history and court of the crime of states consists of two seven nine zero zero zero zero zero one nine nine six est male speech documents two three two eight zero zero zero zero zero zero two zero z
Inference time: 1.86 seconds
Tokens per second: 268.89
---------------
Sample 8:
 and many other more complex powerful manufacturers than gesture many other manufacturers including easy advantage of modern manufacturers executed leibniz s guide to mainstream events publishers encyclopedia of computing news com guide to international assembly manufacturers found in addition to modern entries as early as one four four nine archive of the computational computer and instruments in the applications some text within the so called international assembly are constructed on land of th
Inference time: 1.89 seconds
Tokens per second: 264.62
---------------
Sample 9:
 last history of the united states one nine six six isbn zero five two zero five six five one three three four three john argus marlin two zero zero five isbn zero seven eight nine two seven zero three three six zero five harper john argues that corporations are appropriate for the basic techniques and foundations of marlin university of oregon including peter fran ois and c and oslo bach college in de la volta in cadilla university of california university of michigan and takes conservative pres
Inference time: 1.87 seconds
Tokens per second: 266.88
---------------
Sample 10:
 reference to the establishment of the early two zero th century with the new tessarium the compactification of early early two zero th century periods of time were split into the similarities and activities such as air and air from the other patents the following year and the period was also shaped advanced to early one nine th century patent profitable and the soviet union in one nine four eight it was nevertheless increasingly helped to confidence with its design and entered the development of
Inference time: 1.89 seconds
Tokens per second: 264.24
---------------
Average tokens per second: 266.07
